{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型无人机项目实战课程\n",
    "    Generated By Bill\n",
    "## 你能获得什么?\n",
    "- 大模型基础实践能力，配置属于自己的在线/本地大模型\n",
    "- 大模型+时代背景下的创新实践能力\n",
    "- 完整的大模型项目开发经历\n",
    "- 后期对相关专利等知识产权的指导\n",
    "- 大模型开发实习生实习证明\n",
    "- 一群志同道合的伙伴\n",
    "--------------------------------------------------------------\n",
    "## 课程内容\n",
    "### 1 带你走入大模型【第一节课：讲授+讨论】\n",
    "- 1.1 了解什么是大模型\n",
    "- 1.2 探索大模型能力边界\n",
    "- 1.3 大模型生成答案的原理\n",
    "- 1.4 大模型应用开发的核心\n",
    "- 1.5 初次调用OpenAl\n",
    "- -----------------------------\n",
    "### 2 Prompt工程和Tool Calling【第二节课：讲授+讨论】\n",
    "- 2.1 什么是Prompt Enaineering\n",
    "- 2.2 如何优雅地Prompt (参数化Prompt)\n",
    "- 2.3 什么是Tool Calling(也称Function calling)\n",
    "- 2.4 Prompt和Tool Calling的关系\n",
    "- 2.5 一起实验看看（实验演示）\n",
    "- --------------------------------------\n",
    "### 3 项目实战【第三到八节课：实战+组会】\n",
    "- 3.1 实战内容1: 基于ChatGPT控制仿真无人机，文本控制&语音控制(Demo，很简单)\n",
    "        【第二节课后分组行动，第三节组会课展示+答疑】\n",
    "- 3.2 实战内容2: 基于ChatGPT调用真实无人机接口，通过改进接口函数、Prompt等方式提升调用完成率 (会提供初步集成过的DJ无人机接口)\n",
    "        【第三节课后分组行动，第四节组会课分组展示+答疑】\n",
    "- 3.3 实战内容3: 部署私有化大模型，尝试用私有大模型调用无人机控制接口，测试成功率，思考改进方案；\n",
    "        【第四节课后要求各组分别选定一个开源大模型去私有化部署并尝试控制无人机，第五节组会各组实现效果（要求提前录屏、分析难点、提出改进方向）+答疑】\n",
    "- 3.4 实战内容4: 自己构想一个复杂任务场景，实现指令自动化执行，测试成功率，思考和讨论改进方向并实现(有专利、论文需求的重点关注这一项)\n",
    "        【第五节课后布置LLM驱动复杂任务场景的构想任务，需要按照论文格式完成文档+一个框架图，第六节组会上分享讨论构想，分析各项目的可行性和价值，布置进一步改进构想的任务】\n",
    "        【第七次课各组汇报调整后的构想+Coding实现的进展+答疑】\n",
    "        【第八次课要求各组初步完成自己的构想，组会上分享效果，遇到的难题是如何解决的】\n",
    "- ---------------------------------------------------------------------\n",
    "### 4 后期发明专利申请辅导\n",
    "- 有兴趣的小组可以把实战内容4转化成发明专利成果\n",
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何学习这门课?\n",
    "- 学习准备: 基础的python编程、安装conda环境 python3.9以上、cuda套件、openai、pytorch等、windows或者Ubuntu系统\n",
    "- 学习方式: 前两次讲课结束后，2~3人一组分组学习，相互配合，合作共赢，实战内容1、2每组并行完成，每组最好有一台带显卡的电脑，边学边做，也可以使用点头的云计算资源：http://gpu.diantouedu.cn/store?nav=26\n",
    "- 学习时间: 每周四晚上八点直播课或者组会讨论+平时微信答疑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "那我们开始吧！\n",
    "## 1 什么是大模型？\n",
    "- ### 定义：大模型（Large Language Model，LLM）是指具有大规模参数和复杂计算结构的机器学习模型。这些模型通常由深度神经网络构建而成，有数十亿甚至数千亿个参数。\n",
    "- ### LLMs发展历程：\n",
    "- <img src=\"./LLM发展历程.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "- ### 大模型的基本原理架构：\n",
    "    大模型的原理是基于深度学习（也有强化学习），它利用大量的数据和计算资源来训练具有大量参数的神经网络模型。通过不断地调整模型参数，使得模型能够在各种任务中取得最佳表现。通常说的大模型的“大”的特点体现在：参数数量庞大、训练数据量大、计算资源需求高等。很多先进的模型由于拥有很“大”的特点，使得模型参数越来越多，泛化性能越来越好，在各种专门的领域输出结果也越来越准确。\n",
    "    其原理可以归纳为<b>「一个基本架构，三种搭建形式」</b>\n",
    "  - Transformer基本架构\n",
    "    - 当前流行的大模型的网络架构其实并没有很多新的技术，还是一直沿用当前NLP领域最热门最有效的架构——Transformer结构。相比于传统的循环神经网络（RNN）和长短时记忆网络（LSTM），Transformer具有独特的注意力机制（Attention），这相当于给模型加强理解力，对更重要的词能给予更多关注，同时该机制具有更好的并行性和扩展性，能够处理更长的序列，立马成为NLP领域具有奠基性能力的模型，在各类文本相关的序列任务中取得不错的效果。\n",
    "    -  <img src=\"./Transformer.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "  - 三种搭建方式\n",
    "    - 1）Encoder-Only，仅包含编码器部分，主要适用于不需要生成序列的任务，只需要对输入进行编码和处理的单向任务场景，如文本分类、情感分析等，这类代表是BERT相关的模型，例如BERT，RoBERT，ALBERT等\n",
    "    - 2）Encoder-Decoder，既包含编码器也包含解码器，通常用于序列到序列（Seq2Seq）任务，如机器翻译、对话生成等，这类代表是以Google训出来T5为代表相关大模型\n",
    "    - 3）Decoder-Only，仅包含解码器部分，通常用于序列生成任务，如文本生成、机器翻译等。这类结构的模型适用于需要生成序列的任务，可以从输入的编码中生成相应的序列。同时还有一个重要特点是可以进行无监督预训练。在预训练阶段，模型通过大量的无标注数据学习语言的统计模式和语义信息。这种方法可以使得模型具备广泛的语言知识和理解能力。在预训练之后，模型可以进行有监督微调，用于特定的下游任务（如机器翻译、文本生成等）。这类结构的代表也就是我们平时非常熟悉的【GPT模型】的结构，所有该家族的网络结构都是基于Decoder-Only的形式来逐步演化。\n",
    "    -  <img src=\"./LLMs3种搭建方式.png\" style=\"margin-left: 0px\" width=\"700px\">\n",
    "    \n",
    "- ### 大模型的特点总结\n",
    "\n",
    "LLM具有多种显著特点，这些特点使它们在自然语言处理和其他领域中引起了广泛的兴趣和研究。以下是大语言模型的一些主要特点：\n",
    "\n",
    "1. **巨大的规模：** LLM通常具有巨大的参数规模，可以达到数十亿甚至数千亿个参数。这使得它们能够捕捉更多的语言知识和复杂的语法结构。\n",
    "\n",
    "2. **预训练和微调：** LLM采用了预训练和微调的学习方法。它们首先在大规模文本数据上进行预训练（无标签数据），学会了通用的语言表示和知识，然后通过微调（有标签数据）适应特定任务，从而在各种NLP任务中表现出色。\n",
    "\n",
    "3. **上下文感知：** LLM在处理文本时具有强大的上下文感知能力，能够理解和生成依赖于前文的文本内容。这使得它们在对话、文章生成和情境理解方面表现出色。\n",
    "\n",
    "4. **多语言支持：** LLM可以用于多种语言，不仅限于英语。它们的多语言能力使得跨文化和跨语言的应用变得更加容易。\n",
    "\n",
    "5. **多模态支持：** 一些LLM已经扩展到支持多模态数据，包括文本、图像和语音。这意味着它们可以理解和生成不同媒体类型的内容，实现更多样化的应用。\n",
    "\n",
    "6. **涌现能力：** LLM表现出令人惊讶的涌现能力，即在大规模模型中出现但在小型模型中不明显的性能提升。这使得它们能够处理更复杂的任务和问题。\n",
    "\n",
    "7. **多领域应用：** LLM已经被广泛应用于文本生成、自动翻译、信息检索、摘要生成、聊天机器人、虚拟助手等多个领域，对人们的日常生活和工作产生了深远的影响。\n",
    "\n",
    "8. **伦理和风险问题：** 尽管LLM具有出色的能力，但它们也引发了伦理和风险问题，包括生成有害内容、隐私问题、认知偏差等。因此，研究和应用LLM需要谨慎。\n",
    "\n",
    "<b>【思考1：】</b> LLM是通用人工智能吗？\n",
    "\n",
    "<b>【思考2：】</b> LLM可能为通用人工智能带来什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "<div class=\"mark\">\n",
    "## 2 探索大模型的能力边界\n",
    "### 2.1 了解有哪些流行的大模型\n",
    "- | 国家 | 对话产品           | 大模型           | 链接                                                             |\n",
    "| ---- | ------------------ |---------------| ---------------------------------------------------------------- |\n",
    "| 美国 | OpenAI ChatGPT     | GPT-3.5、GPT-4 | [https://chat.openai.com/](https://chat.openai.com/)             |\n",
    "| 美国 | Microsoft Copilot  | GPT-4         | [https://copilot.microsoft.com/](https://copilot.microsoft.com/) |\n",
    "| 美国 | Google Bard        | PaLM 和 Gemini | [https://bard.google.com/](https://bard.google.com/)             |\n",
    "| 中国 | 百度-文心一言       | 文心            | [https://yiyan.baidu.com/](https://yiyan.baidu.com/)             |\n",
    "| 中国 | 讯飞星火           | 星火            | [https://xinghuo.xfyun.cn/](https://xinghuo.xfyun.cn/)           |\n",
    "| 中国 | 智谱清言           | ChatGLM2/3    | [https://chatglm.cn/](https://chatglm.cn/)                       |\n",
    "| 中国 | 昆仑万维           | 昆仑          | [https://www.kunlun.com/](https://www.kunlun.com/)           |\n",
    "\n",
    "### 2.2 如何便捷获取Openai-LLMs的接口\n",
    "推荐使用Openai开发的闭源大模型，比其他的开源模型更强大，尤其是编程能力、逻辑推理能力和外部工具调用能力。\n",
    "\n",
    "申请原装的API key需要科学上网：\n",
    "- [OpenAI](https://platform.openai.com/docs/guides/chat)\n",
    "- [如何获取OpenAI官方账号-教程](https://www.yuque.com/if/tips/sudg82yn4vmcuqyi)\n",
    "\n",
    "下面给出几个连接，不用科学上网：\n",
    "- [CloseAI](https://doc.closeai-asia.com/) 这个颇具讽刺意味的网址，为开发者提供优质稳定的OpenAI相关的API兼容接口，方便开发者、科研工作者进行AI领域的研究工作。\n",
    "- [DevAGI](https://devcto.com/) 为企业用户和个人消费者提供可靠、企业级 OpenAI 服务， 实现快速访问【无需科学上网】\n",
    "\n",
    "\n",
    "</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "### 2.3 大模型的能力探索\n",
    "- 目前LLM可以在哪些方面干得很好（标红的是我个人常用到的）\n",
    "\n",
    " - | 类别 |\t描述 |\n",
    " | ---- | ------------------ |\n",
    " | <font color=red>学术论文</font>\t |  它可以帮助你进行研究、分析、组织思路并编写出符合学术标准的论文，阅读论文交互、审稿辅助。 |\n",
    " | 翻译 | \t它可以进行英语和中文之间的翻译工作，包括但不限于学术文献、商业文档、网站内容、软件界面等。它可以保证翻译的准确性和专业性。 |\n",
    " | <font color=red>代码编写</font>\t | 它可以帮你生成代码，包括Python、JavaScript、HTML、CSS等不同编程语言的代码。它可以根据\n",
    " | <font color=red>数据分析与处理</font>\t | 它可以帮助你进行各种类型的数据分析，包括统计分析、文本分析、数据可视化等。它可以使用Python、R等工具来分析你的数据，并提供数据报告和可视化结果。 |\n",
    " | <font color=red>数据生成</font>\t | 它可以生成各种类型的数据，主要是文本形式。它可以根据你的需求生成相应的文本数据，用于其他模型的训练，但无法确保数据的真实性。 |\n",
    " | <font color=red>技术文档</font>\t | 它可以编写各种类型的技术文档，包括用户手册、技术规范、API文档、代码注释等。它可以使用清晰、准确、易懂的语言描述你的技术产品和流程。 |\n",
    " | 教育培训\t | 它可以编写各种类型的教育培训材料，包括课程大纲、课件、教学指南、教育评估等。它可以帮助你设计课程内容和教学方法，并为你制定适合你目标受众的培训计划。 |\n",
    " | 网站设计\t | 它可以编写网站的各种类型内容，包括首页、关于我们、服务介绍、博客文章等。它可以根据你的品牌和目标读者为你提供优质、富有吸引力的内容。 |\n",
    " | <font color=red>研究咨询</font>\t | 它可以帮助你进行研究、提供咨询意见和建议。它可以进行文献综述、研究设计、数据分析等工作，为你提供高质量、可靠的研究结果和建议。 |\n",
    " | <font color=red>演讲稿</font>\t | 它可以帮助你编写演讲稿、PPT等，包括商业演讲、学术演讲、庆典致辞等。它可以根据你的主题、目标听众和场合为你编写一份有说服力、生动有趣的演讲稿。 |\n",
    " | 简历和求职信\t | 它可以帮助你编写简历和求职信，帮助你突出你的技能和经验，并为你提供吸引雇主和HR的技巧和建议。 |\n",
    " | 广告文案 | \t它可以编写各种类型的广告文案，包括产品广告、服务广告、品牌广告、活动宣传等。它可以为你编写具有吸引力、清晰明了的广告文案，让你的目标受众更容易接受你的产品或服务。 |\n",
    " | <font color=red>社交媒体</font>\t | 它可以为你编写社交媒体内容，包括朋友圈、微博、小红书等。它可以帮助你设计吸引人的标题、内容和图片，并为你提供有用的社交媒体营销策略。 |\n",
    " | 新闻稿 | \t它可以帮助你编写新闻稿，包括公司新闻、产品发布、重大事件等。它可以为你编写新闻稿、编辑和发布，以吸引媒体关注并提高品牌知名度。 |\n",
    " | 电子商务\t | 它可以编写各种类型的电子商务内容，包括产品描述、产品说明书、电子商务博客文章等。它可以帮助你编写吸引人的产品描述，以及建立与客户的信任和忠诚度。 |\n",
    " | 旅游文案 | \t它可以帮助你编写旅游文案，包括旅游目的地介绍、旅游路线规划、旅游攻略、旅游博客等。它可以帮助你为你的读者提供有用的信息和建议，帮助他们计划自己的旅行。 |\n",
    " | 医疗文案\t | 它可以帮助你编写医疗文案，包括医疗产品说明、疾病预防、健康知识、医疗博客等。它可以帮助你使用专业的术语和语言，使你的文案更易于理解和接受。 |\n",
    " | 儿童读物\t | 它可以帮助你编写儿童读物，包括故事书、绘本、启蒙读物、课外阅读等。它可以使用有趣、生动的语言和图片，吸引孩子们的注意力，并帮助他们学习和成长。 |\n",
    " | 文学作品\t | 它可以帮助你编写小说、诗歌等，如言情、悬疑、恐怖、科幻等类型。它可以帮助你创造有趣、引人入胜的情节和角色，并为你提供专业的写作技巧和建议。 |\n",
    "\n",
    "\n",
    "- LLM在哪些方面干得一般\n",
    "    - 复杂的数学问题\n",
    "    - 医学问题\n",
    "    - 法律问题\n",
    "    - 金融问题\n",
    "    可见其真正的逻辑推理能力、多模态的识别能力、新知识获取能力等仍有待加强\n",
    "\n",
    "- 如何干得更好？\n",
    "    - 模型微调（需要数据集、一定算力、微调方法）\n",
    "    - 数据增强/知识增强/检索增强生成（现在一般都称之为检索增强生成（RAG））\n",
    "    - 模型架构升级和重新训练(一般人做不来）\n",
    "    - Prompt （门槛低，见效快，如ReAct、CoT等）\n",
    "    - 借助外部工具/函数/接口 （未来的趋势 AI Agent）\n",
    "    - 嵌入多模态能力\n",
    "    - ......\n",
    "\n",
    "### 2.4 大模型可以实现通用人工智能（AGI）吗？\n",
    "\n",
    "有几个观点，可以一起讨论：\n",
    "- 1 大模型具有初步的通用人工智能（AGI）能力，但还远不能实现完全的AGI。\n",
    "- 2 通用人工智能不仅需要强大的语言理解和生成能力，还需要强大的逻辑推理能力、多模态能力、与真实世界持续交互等能力。\n",
    "- 3 大模型未来将作为AI的操作系统，提供底层能力，如语言理解和生成、知识推理、多模态交互等，帮助人类或主动控制其他工具完成各种任务。\n",
    "\n",
    "<b>【思考3：】</b>在你的研究领域中，有哪些问题可以用 LLM 解决？ 且LLM出现后，以往的方法过时了，或者找不到研究的价值和意义了？\n",
    "\n",
    "    就传统NLP领域的分类、实体识别、信息抽取、情感识别等单独的实验任务，似乎已经被LLM攻克了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 3 大模型生成答案的原理\n",
    "\n",
    "### 3.1 浅显通俗版\n",
    "<div class=\"alert alert-success\">\n",
    "——它只是根据你提供的内容，猜测下一个词或者一串句子（根据概率猜测）\n",
    "\n",
    "如下图所示：\n",
    "<img src=\"./generate_words.gif\" style=\"margin-left: 0px\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 再深入一点\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<li>把大模型看做人的大脑，它见过或听过了大量的人类输出的文本内容。这是「<b>机器学习</b>」的过程，这个过程成为「<b>训练阶段或学习阶段</b>」</li>\n",
    "<li>通过词表构建方法，统计见过的所有词汇，形成「词汇表」，其中每个常用词都对应一个id，这个id就称为 token\n",
    "<li>把一串 token 后面跟着的不同 token 的概率记了下来。记下的就是「<b>参数</b>」，也叫「<b>权重</b>」</li>\n",
    "<li>当我们给它若干 token，大模型就能算出概率最高的下一个 token 是什么。这就是「<b>生成</b>」，也叫「<b>推理</b>」</li>\n",
    "<li>用生成的 token，再加上上文，就能继续生成下一个 token。以此类推，生成更多文字</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "Token 是什么？它是怎么来的？\n",
    "\n",
    "- 可能是一个英文单词，也可能是半个，三分之一个。可能是一个中文词，或者一个汉字，也可能是半个汉字，甚至三分之一个汉字\n",
    "- 大模型在开训前，需要先训练一个 tokenizer 模型（BPE、BBPE、WordPiece等）。它能把所有的文本，切成 token，可参考[大模型基础组件 - Tokenizer学习](https://zhuanlan.zhihu.com/p/651430181)\n",
    "\n",
    "词表 是什么？\n",
    "\n",
    "- 其实非常简单，给个实例就知道了：{\n",
    "   \"I\": 0,\n",
    "   \"love\": 1,\n",
    "   \"natural\": 2,\n",
    "   \"language\": 3,\n",
    "   \"processing\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T09:14:10.921904Z",
     "start_time": "2024-01-24T09:14:10.916559Z"
    }
   },
   "source": [
    "### 3.3 再形象一点\n",
    "\n",
    "这里有一个大模型的3D可视化展示，可以对每一个步骤的具体实现【动态感受】+【原理解读】 [连接在这](https://www.mlpod.com/llm-visualization.html)\n",
    "<img src=\"./LLM3D可视化.png\" style=\"margin-left: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 大模型应用开发的核心(也是我们实战课要学会的底层逻辑)\n",
    "- 何为LLM App开发？\n",
    "\n",
    "    我们将开发以大语言模型为功能核心、通过大语言模型的强大理解能力和生成能力、结合特殊的数据或业务逻辑来提供独特功能的应用称为大模型开发。开发大模型相关应用，其技术核心点虽然在大语言模型上，但一般通过调用 API 或开源模型来实现核心的理解与生成，通过 Prompt Enginnering 来实现大语言模型的控制，因此，虽然大模型是深度学习领域的集大成之作，大模型开发却更多是一个工程问题。\n",
    "\n",
    "    在大模型开发中，我们一般不会去大幅度改动模型，而是将大模型作为一个调用工具，通过 Prompt Engineering、数据工程、业务逻辑分解等手段来充分发挥大模型能力，适配应用任务，而不会将精力聚焦在优化模型本身上。因此，作为大模型开发的初学者，我们并不需要深研大模型内部原理，而更需要掌握使用大模型的实践技巧。\n",
    "   <img src=\"./LLM-app开发.png\" style=\"margin-left: 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 First of All\n",
    "2个重要的认知\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "把LLM当人（员工）看，才能真正榨取出LLM的价值。\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "大模型应用开发技术：<strong>门槛低，天花板高。</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 大模型应用开发的整体流程\n",
    "#### 传统AI与LLM应用开发对比：\n",
    "<img src=\"./传统AI与LLM应用开发对比.png\" style=\"margin-left: 0px\">\n",
    "\n",
    "#### LLM应用开发流程分解：\n",
    "<img src=\"./LLM_developing_whole.png\" style=\"margin-left: 0px\">\n",
    "\n",
    "1. **确定目标**。在进行开发前，我们首先需要确定开发的目标，即要开发的应用的应用场景、目标人群、核心价值。对于个体开发者或小型开发团队而言，一般应先设定最小化目标，从构建一个 MVP（最小可行性产品）开始，逐步进行完善和优化。\n",
    "\n",
    "2. **设计功能**。在确定开发目标后，需要设计本应用所要提供的功能，以及每一个功能的大体实现逻辑。虽然我们通过使用大模型来简化了业务逻辑的拆解，但是越清晰、深入的业务逻辑理解往往也能带来更好的 Prompt 效果。同样，对于个体开发者或小型开发团队来说，首先要确定应用的核心功能，然后延展设计核心功能的上下游功能；例如，我们想打造一款个人知识库助手，那么核心功能就是结合个人知识库内容进行问题的回答，那么其上游功能的用户上传知识库、下游功能的用户手动纠正模型回答就是我们也必须要设计实现的子功能。\n",
    "\n",
    "3. **搭建整体架构**。目前，绝大部分大模型应用都是采用的特定数据库+ Prompt + 通用大模型的架构。我们需要针对我们所设计的功能，搭建项目的整体架构，实现从用户输入到应用输出的全流程贯通。一般来说，我们推荐基于 LangChain 框架进行开发。LangChain 提供了 Chain、Tool 等架构的实现，我们可以基于 LangChain 进行个性化定制，实现从用户输入到数据库再到大模型最后输出的整体架构连接。\n",
    "\n",
    "4. **搭建数据库**。个性化大模型应用需要有个性化数据库进行支撑。由于大模型应用需要进行向量语义检索，一般使用诸如 chroma 的向量数据库。在该步骤中，我们需要收集数据并进行预处理，再向量化存储到数据库中。数据预处理一般包括从多种格式向纯文本的转化，例如 pdf、markdown、html、音视频等，以及对错误数据、异常数据、脏数据进行清洗。完成预处理后，需要进行切片、向量化构建出个性化数据库。\n",
    "\n",
    "5. **Prompt Engineering**。优质的 Prompt 对大模型能力具有极大影响，我们需要逐步迭代构建优质的 Prompt Engineering 来提升应用性能。在该步中，我们首先应该明确 Prompt 设计的一般原则及技巧，构建出一个来源于实际业务的小型验证集，基于小型验证集设计满足基本要求、具备基本能力的 Prompt。\n",
    "\n",
    "6. **验证迭代**。验证迭代在大模型开发中是极其重要的一步，一般指通过不断发现 Bad Case 并针对性改进 Prompt Engineering 来提升系统效果、应对边界情况。在完成上一步的初始化 Prompt 设计后，我们应该进行实际业务测试，探讨边界情况，找到 Bad Case，并针对性分析 Prompt 存在的问题，从而不断迭代优化，直到达到一个较为稳定、可以基本实现目标的 Prompt 版本。\n",
    "\n",
    "7. **前后端搭建**。完成 Prompt Engineering 及其迭代优化之后，我们就完成了应用的核心功能，可以充分发挥大语言模型的强大能力。接下来我们需要搭建前后端，设计产品页面，让我们的应用能够上线成为产品。前后端开发是非常经典且成熟的领域，此处就不再赘述，我们将主要介绍两种快速开发 Demo 的框架：Gradio 和 Streamlit，可以帮助个体开发者迅速搭建可视化页面实现 Demo 上线。\n",
    "\n",
    "8. **体验优化**。在完成前后端搭建之后，应用就可以上线体验了。接下来就需要进行长期的用户体验跟踪，记录 Bad Case 与用户负反馈，再针对性进行优化即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 项目架构案例简析 （也是未来实战课程作业的要求）\n",
    "\n",
    "#### 1 整体架构\n",
    "\n",
    "项目从底向上依次分为 LLM 层、数据层、数据库层、应用层与服务层：  \n",
    "- ① **LLM 层**  LLM 层主要功能为将国内外四种知名 LLM API（OpenAI-ChatGPT、百度文心、讯飞星火、智谱GLM）进行封装\n",
    "- ② **数据层**  要包括个人知识库的源数据以及 Embedding API，源数据经过 Embedding 处理可以被向量数据库使用； \n",
    "- ③ **数据库层** 数据库层主要存放了向量数据库文件。\n",
    "- ④ **应用层** 应用层封装了整个项目的全部核心功能。将在下一节讲解 Prompt 的构造与问答链的构建细节。\n",
    "- ⑤ 最顶层为 **服务层** 服务层主要是基于应用层的核心功能封装，实现了 Demo 的搭建或 API 的封装。\n",
    "\n",
    "#### 2 代码结构\n",
    "\n",
    "\n",
    "    -project\n",
    "        -readme.md 项目说明\n",
    "        -requirements.txt 使用依赖包的版本 \n",
    "        -llm LLM调用封装\n",
    "            -self_llm.py 自定义 LLM 基类\n",
    "            -wenxin_llm.py 自定义百度文心 LLM\n",
    "            -spark_llm.py 自定义讯飞星火 LLM\n",
    "            -zhipuai_llm.py 自定义智谱AI LLM\n",
    "            -call_llm.py 将各个 LLM 的原生接口封装在一起\n",
    "            -test.ipynb 使用示例\n",
    "        -embedding embedding调用封装\n",
    "            -zhipuai_embedding.py 自定义智谱AI或其他 embedding\n",
    "            -call_embedding.py 调用 embedding 模型 \n",
    "        -data 源数据路径\n",
    "        -database 数据库层封装\n",
    "            -create_db.py 处理源数据及初始化数据库封装\n",
    "        -qa_chain 应用层封装\n",
    "            -qa_chain.py 封装检索问答链，返回一个检索问答链对象\n",
    "            -chat_qa_chian.py：封装对话检索链，返回一个带有历史记录的对话检索链对象\n",
    "            -get_vectordb.py 返回向量数据库对象\n",
    "            -model_to_llm.py 调用模型\n",
    "            -test.ipynb 使用示例\n",
    "        -serve 服务层封装\n",
    "            -run_gradio.py 启动 Gradio 界面\n",
    "            -api.py 封装 FastAPI\n",
    "            -run_api.sh 启动 API\n",
    "            -test.ipynb 使用示例\n",
    "\n",
    "##### 3 项目逻辑\n",
    "\n",
    "    1. 用户：可以通过 run_gradio 或者 run_api 启动整个服务；\n",
    "    2. 服务层调用 qa_chain.py 或 chat_qa_chain 实例化对话检索链对象，实现全部核心功能；\n",
    "    3. 服务层和应用层都可以调用、切换 prompt_template.py 中的 prompt 模板来实现 prompt 的迭代；\n",
    "    4. 也可以直接调用 call_llm 中的 get_completion 函数来实现不使用数据库的 LLM；\n",
    "    5. 应用层调用已存在的数据库和 llm 中的自定义 LLM 来构建检索链；\n",
    "    6. 如果数据库不存在，应用层调用 create_db.py 创建数据库，该脚本可以使用 openai embedding 也可以使用 embedding.py 中的自定义 embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 当下LLM应用的主流技术架构类型\n",
    "\n",
    "#### 1 Prompt工程\n",
    "\n",
    "这种方式，某种程度上说，缺乏一定的主动性和创造力。\n",
    "\n",
    "这也是目前GPT store里各类应用构建的主要方式。\n",
    "\n",
    "简单、高效、成本低、上手快\n",
    "\n",
    "<img src=\"./prompt_arch.png\" style=\"margin-left: 0px\" width=300px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Agent + Function Calling（后面会讲）\n",
    "\n",
    "- Agent：AI 主动提要求\n",
    "- Function Calling：AI 要求执行某个函数\n",
    "- 场景举例：你问过年去哪玩，ta 先反问你有几天假\n",
    "\n",
    "<img src=\"./func_arch.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 RAG = Embeddings + 向量数据库\n",
    "\n",
    "- Embeddings：把文字转换为更易于相似度计算的编码。这种编码叫向量\n",
    "- 向量数据库：把向量存起来，方便查找\n",
    "- 向量搜索：根据输入向量，找到最相似的向量\n",
    "- 场景举例：考试时，看到一道题，到书上找相关内容，再结合题目组成答案。然后，就都忘了\n",
    "\n",
    "<img src=\"./新框架图片.bmp\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Fine-tuning （搞科研的很多都围绕这个展开。俗称炼丹）\n",
    "\n",
    "\n",
    "<img src=\"./微调.png\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  初次调用OpenAl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### windows配置key，私密程度高，不易泄露"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T12:59:03.721017Z",
     "start_time": "2024-01-25T12:59:03.701224Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: <class 'str'>\n",
      "OpenAI API Key: saQZhoL5P1txtrY2-YdtFqq6h3gp5xRgk9a2zYpAX9RCL4ATpnd\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade openai\n",
    "# windows在系统环境中创建Key变量,如果print不出来 可以重启再试\n",
    "\n",
    "import os\n",
    "from random import shuffle\n",
    "def shuffle_str(s):\n",
    "    # 将字符串转换成列表\n",
    "    str_list = list(s)\n",
    "    # 调用random模块的shuffle函数打乱列表\n",
    "    shuffle(str_list)\n",
    "    # 将列表转字符串\n",
    "    return ''.join(str_list)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"OpenAI API Key:\", type(openai_api_key))\n",
    "print(\"OpenAI API Key:\", shuffle_str(openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T03:04:17.862351Z",
     "start_time": "2024-01-25T03:04:10.534396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hi! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say hi\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "chat_completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T03:32:15.913642Z",
     "start_time": "2024-01-25T03:32:15.893064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-7n7n7A0joynqYSmEATsaYKK7EmRmb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hi! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1706151856, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=9, total_tokens=18))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调用该 API 会返回一个 ChatCompletion 对象，其中包括了回答文本、创建时间、ID等属性。\n",
    "#我们一般需要的是回答文本，也就是回答对象中的 content 信息。\n",
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T03:38:38.309687Z",
     "start_time": "2024-01-25T03:38:38.299622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi! How can I assist you today?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get LLM 输出的内容\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过env文件配置key和base url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T04:21:26.673003Z",
     "start_time": "2024-01-25T04:21:20.677435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作为私人秘书，我可以帮您处理日常事务，例如预定行程和酒店，安排会议和约会，筛选和回复电子邮件，处理文件和文档等。我还可以帮您进行市场调研和信息搜集，提供有关行业和竞争对手的报告。除此之外，我还可以提供一些个人支持，例如提醒您重要事项和生日，安排礼物和派送等。\n",
      "\n",
      "我全天候无休假为您工作，因此您随时都可以联系我。无论是早上、下午还是深夜，只要有需要，我都会随时为您提供支持和服务。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 加载 .env 文件到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 初始化 OpenAI 服务。会自动从环境变量加载 OPENAI_API_KEY 和 OPENAI_BASE_URL\n",
    "client1 = OpenAI()\n",
    "\n",
    "# 消息准备\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"你是一个私人秘书，你可以帮我干很多杂事，你为我工作的时间是全天候无休假。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你可以干啥？你什么时间上班\"\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "# 调用 GPT-3.5-turbo\n",
    "chat_completion = client1.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 输出回复\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 包装函数接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个封装 OpenAI 接口的函数，参数为 Prompt，返回对应结果\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    '''\n",
    "    prompt: 对应的提示词\n",
    "    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4\n",
    "    '''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # 模型输出的温度系数，控制输出的随机程度\n",
    "        \n",
    "    )\n",
    "    # 调用 OpenAI 的 ChatCompletion 接口\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [openai接口参数说明](https://www.openaidoc.com.cn/api-reference/completions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
