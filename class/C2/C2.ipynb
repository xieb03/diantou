{
 "cells": [
  {
   "attachments": {
    "2E0B9352.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d44f8912",
   "metadata": {},
   "source": [
    "## ![2E0B9352.png](attachment:2E0B9352.png)课前回顾\n",
    "\n",
    "### 1.1 了解什么是大模型\n",
    "- LLM的定义：是指具有大规模参数和复杂计算结构的机器学习模型。这些模型通常由深度神经网络构建而成，有数十亿甚至数千亿个参数。\n",
    "- LLM的发展历程：Google的T5、Openai的GPT系列、Meta的Llama、百度的文心、华为的盘古、腾讯、字节等......\n",
    "- LLM的基本原理架构：一个基本架构和三种搭建形式\n",
    "- LLM的特点总结：八大特点\n",
    "\n",
    "### 1.2 探索大模型能力边界\n",
    "- 论文写作、代码编程、数据处理、数据生成、社交媒体、智能体操控等\n",
    "- 讨论了LLM和通用人工智能的联系与暂时的区别、实现通用人工智能的可能性\n",
    "\n",
    "### 1.3 大模型生成答案的原理\n",
    "- 由浅入深\n",
    "- 3D可视化理解\n",
    "\n",
    "### 1.4 大模型应用开发的核心\n",
    "- 2个重要认知\n",
    "- 传统AI应用开发和LLM应用开发的区别\n",
    "- 开发流程分解\n",
    "- 项目架构案例简析 （也是2024-02-01 19:59:14 实战课程作业的要求）\n",
    "- 分析了当下LLM应用的主流技术架构类型（纯Prompt、基于FunctionCalling的、基于RAG的、基于微调的...）\n",
    "\n",
    "### 1.5 初次调用OpenAl\n",
    "- 这个相信大家都自己尝试了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7c20e",
   "metadata": {},
   "source": [
    "- 上节课补充内容：OpenAI API 的几个重要参数！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6b4074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T09:27:47.189799Z",
     "start_time": "2024-02-01T09:27:47.180712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_chat_completion(session, user_prompt, model=\"gpt-3.5-turbo\"):\\n    _session = copy.deepcopy(session)\\n    _session.append({\"role\": \"user\", \"content\": user_prompt})\\n    response = client.chat.completions.create(\\n        model=model,\\n        messages=_session,\\n        # 以下默认值都是官方默认值\\n        temperature=1,          # 生成结果的多样性 0~2之间，越大越随机，越小越固定\\n        seed=None,              # 随机数种子。指定具体值后，temperature 为 0 时，每次生成的结果都一样\\n        stream=False,           # 数据流模式，一个字一个字地接收\\n        top_p=1,                # 随机采样时，只考虑概率前百分之多少的 token。不建议和 temperature 一起使用\\n        n=1,                    # 一次返回 n 条结果\\n        max_tokens=100,         # 每条结果最多几个 token（超过截断）\\n        presence_penalty=0,     # 对出现过的 token 的概率进行降权\\n        frequency_penalty=0,    # 对出现过的 token 根据其出现过的频次，对其的概率进行降权\\n        logit_bias={},          # 对指定 token 的采样概率手工加/降权，不常用\\n    )\\n    msg = response.choices[0].message.content\\n    return msg'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_chat_completion(session, user_prompt, model=\"gpt-3.5-turbo\"):\n",
    "    _session = copy.deepcopy(session)\n",
    "    _session.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=_session,\n",
    "        # 以下默认值都是官方默认值\n",
    "        temperature=1,          # 生成结果的多样性 0~2之间，越大越随机，越小越固定\n",
    "        seed=None,              # 随机数种子。指定具体值后，temperature 为 0 时，每次生成的结果都一样\n",
    "        stream=False,           # 数据流模式，一个字一个字地接收\n",
    "        top_p=1,                # 随机采样时，只考虑概率前百分之多少的 token。不建议和 temperature 一起使用\n",
    "        n=1,                    # 一次返回 n 条结果\n",
    "        max_tokens=100,         # 每条结果最多几个 token（超过截断）\n",
    "        presence_penalty=0,     # 对出现过的 token 的概率进行降权\n",
    "        frequency_penalty=0,    # 对出现过的 token 根据其出现过的频次，对其的概率进行降权\n",
    "        logit_bias={},          # 对指定 token 的采样概率手工加/降权，不常用\n",
    "    )\n",
    "    msg = response.choices[0].message.content\n",
    "    return msg'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb225c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ul>\n",
    "<li>Temperature 参数很关键</li>\n",
    "<li>执行任务用 0，文本生成用 0.7-0.9</li>\n",
    "<li>无特殊需要，不建议超过 1</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d5e5c3",
   "metadata": {},
   "source": [
    "## 本节内容\n",
    "\n",
    "### Prompt工程——Prompt设计的好坏，决定了你Agent能力能否达到LLM的上限\n",
    "\n",
    "- 2.1 什么是Prompt Engineering\n",
    "- 2.2 Prompt 的内容架构\n",
    "- 2.3 基于Prompt的智能客服案例\n",
    "- 2.4 Prompt技能进阶\n",
    "- 2.5 Prompt攻防\n",
    "\n",
    "\n",
    "### 课后作业\n",
    "\n",
    "- 分组情况确定\n",
    "- 课后小作业：了解更前沿的Prompt方案——Prompt Tuning\n",
    "- LLM操控无人机案例复现+语音识别功能\n",
    "\n",
    "\n",
    "### Function Calling——LLM和外部世界链接\n",
    "\n",
    "- 3.1 Tool Calling 的机制\n",
    "- 3.2 简单示例\n",
    "- 3.3 支持Tool Calling国产LLMs\n",
    "- 3.4 Tool Calling 的想象空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb983754",
   "metadata": {},
   "source": [
    "开始吧\n",
    "-------------------\n",
    "### 2.1 什么是提示工程（Prompt Engineering）\n",
    "\n",
    "提示工程也叫「指令工程」。\n",
    "\n",
    "- Prompt 就是你发给大模型的指令。\n",
    "- 貌似简单，但意义非凡。\n",
    "  - 「Prompt」 是 AGI 时代的「编程语言」\n",
    "  - 「Prompt 工程」是 AGI 时代的「软件工程」\n",
    "  - 「提示工程师」是 AGI 时代的「程序员」\n",
    "- 学会提示工程，就像学用鼠标、键盘一样，是 AGI 时代的基本技能\n",
    "- 提示工程也是「门槛低，天花板高」，所以有人戏称 prompt 为「咒语」\n",
    "- 但专门的「提示工程师」不会长久，因为每个人都要会「提示工程」，AI 的进化也会让提示工程越来越简单\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考1：</b>既然门槛低，每个人都会，那我们还有必要深入了解Prompt吗，我们的优势是什么？\n",
    "    \n",
    "💡可以从原理、编程、专业领域角度去思考\n",
    "</div>\n",
    "\n",
    "Prompt Engineering的目的\n",
    "\n",
    "1. 针对具体问题提问，获得具体结果\n",
    "2. **固化一套 Prompt 到程序中，成为系统功能的一部分**，比如「每天生成本公司的简报」「AI 客服系统」「基于公司知识库的问答」\n",
    "\n",
    "前者主要通过 ChatGPT、ChatBox 这样的界面操作，还有很多现成的LLM产品。\n",
    "\n",
    "后者则需要写代码了，将Prompt灵活地嵌入到代码中（系统中）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3443763",
   "metadata": {},
   "source": [
    "### 2.2 Prompt 的内容架构\n",
    "\n",
    "- **角色**：给 AI 定义一个最匹配任务的角色。比如：「你是一位XX专家」，**角色定义会使得效果会好很多**\n",
    "- **具体指令**：对任务进行描述\n",
    "- **上下文**：给出与任务相关的其它背景信息（尤其在多轮交互中）\n",
    "- **例子**：必要时给出举例，即one-shot, few（Three、Five）-shot learning等；实践证明其对输出结果的正确性有很大帮助\n",
    "- **输入**：任务的输入信息；在提示词中明确的标识出输入\n",
    "- **输出**：输出的格式描述，以便后继模块自动解析模型的输出结果，比如（JSON、XML）\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考2：</b>为什么给出角色定义会使效果好很多？\n",
    "</div>\n",
    "\n",
    "![lost-in-the-middle](./lost_middle.jpg)\n",
    "- 论文连接[Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)\n",
    "<div class=\"alert alert-success\">\n",
    "由上图可见！大模型对 **上下文的开头和结尾** 更敏感。\n",
    "预定义角色的本质，其实就是把问题域收窄。\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc21e0",
   "metadata": {},
   "source": [
    "### 2.3 Demo-推荐流量包的智能客服\n",
    "\n",
    "现有某运营商的流量包产品如下：\n",
    "\n",
    "|   名称   | 流量（G/月） | 价格（元/月） | 适用人群 |\n",
    "| :------: | -----------: | ------------: | :------: |\n",
    "| 经济套餐 |           10 |            50 |  无限制  |\n",
    "| 畅游套餐 |          100 |           180 |  无限制  |\n",
    "| 无限套餐 |         1000 |           300 |  无限制  |\n",
    "| 校园套餐 |          200 |           150 |  在校生  |\n",
    "\n",
    "功能需求：设计的智能客服可以根据用户的咨询，推荐最适合的流量包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0339d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:22:24.950406Z",
     "start_time": "2024-02-01T12:22:24.111592Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入依赖库\n",
    "from openai import OpenAI\n",
    "# !pip install --upgrade openai\n",
    "# windows在系统环境中创建Key变量,如果print不出来 可以重启再试\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c89732d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:22:27.063569Z",
     "start_time": "2024-02-01T12:22:27.048221Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基于 prompt 生成文本\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):      # 默认使用 gpt-3.5-turbo 模型\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]    # 将 prompt 作为用户输入\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,                                  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content          # 返回模型生成的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5dbfca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:22:31.066287Z",
     "start_time": "2024-02-01T12:22:28.223049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户在流量套餐产品的选择条件上的倾向为：\n",
      "- 名称：用户倾向选择100G的套餐。\n",
      "- 月费价格：用户未提及对月费价格的倾向。\n",
      "- 月流量：用户倾向选择100G的套餐。\n"
     ]
    }
   ],
   "source": [
    "#### 定义任务描述和输入\n",
    "# 测试LLM\n",
    "# 任务描述\n",
    "instruction = \"\"\"\n",
    "你的任务是识别用户对手机流量套餐产品的选择条件。\n",
    "每种流量套餐产品包含三个属性：名称，月费价格，月流量。\n",
    "根据用户输入，识别用户在上述三种属性上的倾向。\n",
    "\"\"\"\n",
    "\n",
    "# 用户输入\n",
    "input_text = \"\"\"\n",
    "办个100G的套餐。\n",
    "\"\"\"\n",
    "\n",
    "# prompt 模版。instruction 和 input_text 会被替换为上面的内容\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "用户输入：\n",
    "{input_text}\n",
    "\"\"\"\n",
    "\n",
    "# 调用大模型\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dd01caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:22:34.355466Z",
     "start_time": "2024-02-01T12:22:32.737369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"名称\": \"100G套餐\",\n",
      "  \"月费价格\": \"未知\",\n",
      "  \"月流量\": \"100G\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 从上面的结果可以看出 LLM 理解了我们的需求。\n",
    "# 但是自然语言的输出，不方便我们形成最终的决策。\n",
    "\n",
    "# 因此我们需要对输出的格式进行约定，形成格式化的输出，**推荐使用 JSON 格式输出**\n",
    "\n",
    "# 输出格式限定\n",
    "output_format = \"\"\"\n",
    "以 JSON 格式输出\n",
    "\"\"\"\n",
    "\n",
    "# 加入输出格式\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{output_format}\n",
    "\n",
    "用户输入：\n",
    "{input_text}\n",
    "\"\"\"\n",
    "\n",
    "# 调用大模型\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cf7527",
   "metadata": {},
   "source": [
    "GPT3.5\\4等大模型是经过code资料训练过的，所以对对 JSON 格式的信息是有较高敏感度的。\n",
    "\n",
    "这对下一步的操作有极大好处。\n",
    "但还需要对 JSON 结构做更详细的定义和约束。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68e3a470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:24:06.601939Z",
     "start_time": "2024-02-01T12:24:04.852507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"operator\": \">=\",\n",
      "    \"value\": 100\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 任务描述增加了字段的**英文标识符**\n",
    "instruction = \"\"\"\n",
    "你的任务是识别用户对手机流量套餐产品的选择条件。\n",
    "每种流量套餐产品包含三个属性：名称(name)，月费价格(price)，月流量(data)。\n",
    "根据用户输入，识别用户在上述三种属性上的倾向。\n",
    "\"\"\"\n",
    "\n",
    "# 输出格式增加了各种定义、约束\n",
    "output_format = \"\"\"\n",
    "以JSON格式输出。\n",
    "1. name字段的取值为string类型，取值必须为以下之一：经济套餐、畅游套餐、无限套餐、校园套餐 或 null；\n",
    "\n",
    "2. price字段的取值为一个结构体 或 null，包含两个字段：\n",
    "(1) operator, string类型，取值范围：'<='（小于等于）, '>=' (大于等于), '=='（等于）\n",
    "(2) value, int类型\n",
    "\n",
    "3. data字段的取值为取值为一个结构体 或 null，包含两个字段：\n",
    "(1) operator, string类型，取值范围：'<='（小于等于）, '>=' (大于等于), '=='（等于）\n",
    "(2) value, int类型或string类型，string类型只能是'无上限'\n",
    "\n",
    "4. 用户的意图可以包含按price或data排序，以sort字段标识，取值为一个结构体：\n",
    "(1) 结构体中以\"ordering\"=\"descend\"表示按降序排序，以\"value\"字段存储待排序的字段\n",
    "(2) 结构体中以\"ordering\"=\"ascend\"表示按升序排序，以\"value\"字段存储待排序的字段\n",
    "\n",
    "只输出中只包含用户提及的字段，不要猜测任何用户未直接提及的字段，不输出值为null的字段。\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"办个100G以上的套餐\"\n",
    "# input_text = \"我要无限量套餐\"\n",
    "# input_text = \"有没有便宜的套餐\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{output_format}\n",
    "\n",
    "用户输入：\n",
    "{input_text}\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc736f2",
   "metadata": {},
   "source": [
    "你看！ 这种格式是不是就很方便利用代码对它进一步处理和计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2681f",
   "metadata": {},
   "source": [
    "再来一个技巧 **few shots** 让LLM输出的内容更加稳定\n",
    "！！！越是复杂的任务，越要给几个好的例子，才能得到好的输出结果！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b787c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:26:16.361498Z",
     "start_time": "2024-02-01T12:26:15.004151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"price\":{\"operator\":\"<=\",\"value\":200},\"sort\":{\"ordering\":\"descend\",\"value\":\"data\"}}\n"
     ]
    }
   ],
   "source": [
    "examples = \"\"\"\n",
    "便宜的套餐：{\"sort\":{\"ordering\"=\"ascend\",\"value\"=\"price\"}}\n",
    "有没有不限流量的：{\"data\":{\"operator\":\"==\",\"value\":\"无上限\"}}\n",
    "流量大的：{\"sort\":{\"ordering\"=\"descend\",\"value\"=\"data\"}}\n",
    "100G以上流量的套餐最便宜的是哪个：{\"sort\":{\"ordering\"=\"ascend\",\"value\"=\"price\"},\"data\":{\"operator\":\">=\",\"value\":100}}\n",
    "月费不超过200的：{\"price\":{\"operator\":\"<=\",\"value\":200}}\n",
    "就要月费180那个套餐：{\"price\":{\"operator\":\"==\",\"value\":180}}\n",
    "经济套餐：{\"name\":\"经济套餐\"}\n",
    "\"\"\"\n",
    "\n",
    "# input_text = \"有没有便宜的套餐\"\n",
    "# input_text = \"有没有土豪套餐\"\n",
    "# input_text = \"办个200G的套餐\"\n",
    "# input_text = \"有没有流量大的套餐\"\n",
    "# input_text = \"200元以下，流量大的套餐有啥\"\n",
    "# input_text = \"你说那个10G的套餐，叫啥名字\"\n",
    "\n",
    "# 有了例子\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{output_format}\n",
    "\n",
    "例如：\n",
    "{examples}\n",
    "\n",
    "用户输入：\n",
    "{input_text}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda2c7c",
   "metadata": {},
   "source": [
    "实现 多轮对话 功能\n",
    "\n",
    "进一步设计多轮对话的Prompt，即**在Prompt中加入对话上下文**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc3a8457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:27:52.112062Z",
     "start_time": "2024-02-01T12:27:50.725715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sort\":{\"ordering\"=\"ascend\",\"value\"=\"price\"},\"data\":{\"operator\":\">=\",\"value\":100}}\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"\n",
    "你的任务是识别用户对手机流量套餐产品的选择条件。\n",
    "每种流量套餐产品包含三个属性：名称(name)，月费价格(price)，月流量(data)。\n",
    "根据对话上下文，识别用户在上述属性上的倾向。识别结果要包含整个对话的信息。\n",
    "\"\"\"\n",
    "\n",
    "# 输出描述\n",
    "output_format = \"\"\"\n",
    "以JSON格式输出。\n",
    "1. name字段的取值为string类型，取值必须为以下之一：经济套餐、畅游套餐、无限套餐、校园套餐 或 null；\n",
    "\n",
    "2. price字段的取值为一个结构体 或 null，包含两个字段：\n",
    "(1) operator, string类型，取值范围：'<='（小于等于）, '>=' (大于等于), '=='（等于）\n",
    "(2) value, int类型\n",
    "\n",
    "3. data字段的取值为取值为一个结构体 或 null，包含两个字段：\n",
    "(1) operator, string类型，取值范围：'<='（小于等于）, '>=' (大于等于), '=='（等于）\n",
    "(2) value, int类型或string类型，string类型只能是'无上限'\n",
    "\n",
    "4. 用户的意图可以包含按price或data排序，以sort字段标识，取值为一个结构体：\n",
    "(1) 结构体中以\"ordering\"=\"descend\"表示按降序排序，以\"value\"字段存储待排序的字段\n",
    "(2) 结构体中以\"ordering\"=\"ascend\"表示按升序排序，以\"value\"字段存储待排序的字段\n",
    "\n",
    "只输出中只包含用户提及的字段，不要猜测任何用户未直接提及的字段。不要输出值为null的字段。\n",
    "\"\"\"\n",
    "# DO NOT OUTPUT NULL-VALUED FIELD!\n",
    "\n",
    "# 多轮对话的例子\n",
    "examples = \"\"\"\n",
    "客服：有什么可以帮您\n",
    "用户：100G套餐有什么\n",
    "\n",
    "{\"data\":{\"operator\":\">=\",\"value\":100}}\n",
    "\n",
    "客服：有什么可以帮您\n",
    "用户：100G套餐有什么\n",
    "客服：我们现在有无限套餐，不限流量，月费300元\n",
    "用户：太贵了，有200元以内的不\n",
    "\n",
    "{\"data\":{\"operator\":\">=\",\"value\":100},\"price\":{\"operator\":\"<=\",\"value\":200}}\n",
    "\n",
    "客服：有什么可以帮您\n",
    "用户：便宜的套餐有什么\n",
    "客服：我们现在有经济套餐，每月50元，10G流量\n",
    "用户：100G以上的有什么\n",
    "\n",
    "{\"data\":{\"operator\":\">=\",\"value\":100},\"sort\":{\"ordering\"=\"ascend\",\"value\"=\"price\"}}\n",
    "\n",
    "客服：有什么可以帮您\n",
    "用户：100G以上的套餐有什么\n",
    "客服：我们现在有畅游套餐，流量100G，月费180元\n",
    "用户：流量最多的呢\n",
    "\n",
    "{\"sort\":{\"ordering\"=\"descend\",\"value\"=\"data\"},\"data\":{\"operator\":\">=\",\"value\":100}}\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"哪个便宜\"\n",
    "# input_text = \"无限量哪个多少钱\"\n",
    "# input_text = \"流量最大的多少钱\"\n",
    "\n",
    "# 多轮对话上下文\n",
    "context = f\"\"\"\n",
    "客服：有什么可以帮您\n",
    "用户：有什么100G以上的套餐推荐\n",
    "客服：我们有畅游套餐和无限套餐，您有什么价格倾向吗\n",
    "用户：{input_text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{output_format}\n",
    "\n",
    "{examples}\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2f906",
   "metadata": {},
   "source": [
    "参考传统的**对话系统设计的基本模块和思路**，进一步完善基于LLM+Prompt的智能客服机器人对话系统\n",
    "\n",
    "<img src=\"对话系统.png\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdc12d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:31:42.721346Z",
     "start_time": "2024-02-01T12:31:41.900524Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "# 定义一个system Prompt\n",
    "instruction = \"\"\"\n",
    "你的任务是识别用户对手机流量套餐产品的选择条件。\n",
    "每种流量套餐产品包含三个属性：名称(name)，月费价格(price)，月流量(data)。\n",
    "根据用户输入，识别用户在上述三种属性上的倾向。\n",
    "\"\"\"\n",
    "\n",
    "# 输出格式\n",
    "output_format = \"\"\"\n",
    "以JSON格式输出。\n",
    "1. name字段的取值为string类型，取值必须为以下之一：经济套餐、畅游套餐、无限套餐、校园套餐 或 null；\n",
    "\n",
    "2. price字段的取值为一个结构体 或 null，包含两个字段：\n",
    "(1) operator, string类型，取值范围：'<='（小于等于）, '>=' (大于等于), '=='（等于）\n",
    "(2) value, int类型\n",
    "\n",
    "3. data字段的取值为取值为一个结构体 或 null，包含两个字段：\n",
    "(1) operator, string类型，取值范围：'<='（小于等于）, '>=' (大于等于), '=='（等于）\n",
    "(2) value, int类型或string类型，string类型只能是'无上限'\n",
    "\n",
    "4. 用户的意图可以包含按price或data排序，以sort字段标识，取值为一个结构体：\n",
    "(1) 结构体中以\"ordering\"=\"descend\"表示按降序排序，以\"value\"字段存储待排序的字段\n",
    "(2) 结构体中以\"ordering\"=\"ascend\"表示按升序排序，以\"value\"字段存储待排序的字段\n",
    "\n",
    "只输出中只包含用户提及的字段，不要猜测任何用户未直接提及的字段。\n",
    "DO NOT OUTPUT NULL-VALUED FIELD! 确保输出能被json.loads加载。\n",
    "\"\"\"\n",
    "\n",
    "examples = \"\"\"\n",
    "便宜的套餐：{\"sort\":{\"ordering\"=\"ascend\",\"value\"=\"price\"}}\n",
    "有没有不限流量的：{\"data\":{\"operator\":\"==\",\"value\":\"无上限\"}}\n",
    "流量大的：{\"sort\":{\"ordering\"=\"descend\",\"value\"=\"data\"}}\n",
    "100G以上流量的套餐最便宜的是哪个：{\"sort\":{\"ordering\"=\"ascend\",\"value\"=\"price\"},\"data\":{\"operator\":\">=\",\"value\":100}}\n",
    "月费不超过200的：{\"price\":{\"operator\":\"<=\",\"value\":200}}\n",
    "就要月费180那个套餐：{\"price\":{\"operator\":\"==\",\"value\":180}}\n",
    "经济套餐：{\"name\":\"经济套餐\"}\n",
    "\"\"\"\n",
    "\n",
    "'''NLU(Natural Language Understanding)：自然语言理解类，用于将用户输入解析为语义。\n",
    "其中parse方法接收用户输入，将其填充到模板中，然后调用_get_completion方法使用OpenAI GPT模型获取语义解析结果。\n",
    "'''\n",
    "class NLU:\n",
    "    def __init__(self):\n",
    "        self.prompt_template = f\"{instruction}\\n\\n{output_format}\\n\\n{examples}\\n\\n用户输入：\\n__INPUT__\"\n",
    "\n",
    "    def _get_completion(self, prompt, model=\"gpt-3.5-turbo\"):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "        )\n",
    "        semantics = json.loads(response.choices[0].message.content)\n",
    "        return {k: v for k, v in semantics.items() if v}\n",
    "\n",
    "    def parse(self, user_input):\n",
    "        prompt = self.prompt_template.replace(\"__INPUT__\", user_input)\n",
    "        return self._get_completion(prompt)\n",
    "\n",
    "'''DST(Dialogue State Tracking)：对话状态跟踪类，用于维护对话的多轮状态。\n",
    "其中update方法接收当前状态和NLU的语义解析结果，根据解析结果更新状态，并返回更新后的状态。\n",
    "'''\n",
    "class DST:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def update(self, state, nlu_semantics):\n",
    "        if \"name\" in nlu_semantics:\n",
    "            state.clear()\n",
    "        if \"sort\" in nlu_semantics:\n",
    "            slot = nlu_semantics[\"sort\"][\"value\"]\n",
    "            if slot in state and state[slot][\"operator\"] == \"==\":\n",
    "                del state[slot]\n",
    "        for k, v in nlu_semantics.items():\n",
    "            state[k] = v\n",
    "        return state\n",
    "\n",
    "'''MockedDB：模拟的数据库类，用于存储套餐信息，并根据条件查询满足条件的套餐记录。\n",
    "其中retrieve方法接收查询条件，根据条件从数据库中检索符合条件的套餐记录，并返回结果。\n",
    "'''\n",
    "class MockedDB:\n",
    "    def __init__(self):\n",
    "        self.data = [\n",
    "            {\"name\": \"经济套餐\", \"price\": 50, \"data\": 10, \"requirement\": None},\n",
    "            {\"name\": \"畅游套餐\", \"price\": 180, \"data\": 100, \"requirement\": None},\n",
    "            {\"name\": \"无限套餐\", \"price\": 300, \"data\": 1000, \"requirement\": None},\n",
    "            {\"name\": \"校园套餐\", \"price\": 150, \"data\": 200, \"requirement\": \"在校生\"},\n",
    "        ]\n",
    "\n",
    "    def retrieve(self, **kwargs):\n",
    "        records = []\n",
    "        for r in self.data:\n",
    "            select = True\n",
    "            if r[\"requirement\"]:\n",
    "                if \"status\" not in kwargs or kwargs[\"status\"] != r[\"requirement\"]:\n",
    "                    continue\n",
    "            for k, v in kwargs.items():\n",
    "                if k == \"sort\":\n",
    "                    continue\n",
    "                if k == \"data\" and v[\"value\"] == \"无上限\":\n",
    "                    if r[k] != 1000:\n",
    "                        select = False\n",
    "                        break\n",
    "                if \"operator\" in v:\n",
    "                    if not eval(str(r[k])+v[\"operator\"]+str(v[\"value\"])):\n",
    "                        select = False\n",
    "                        break\n",
    "                elif str(r[k]) != str(v):\n",
    "                    select = False\n",
    "                    break\n",
    "            if select:\n",
    "                records.append(r)\n",
    "        if len(records) <= 1:\n",
    "            return records\n",
    "        key = \"price\"\n",
    "        reverse = False\n",
    "        if \"sort\" in kwargs:\n",
    "            key = kwargs[\"sort\"][\"value\"]\n",
    "            reverse = kwargs[\"sort\"][\"ordering\"] == \"descend\"\n",
    "        return sorted(records, key=lambda x: x[key], reverse=reverse)\n",
    "\n",
    "'''DialogManager：对话管理器类，用于处理用户输入、调用NLU、DST和数据库，以及调用ChatGPT进行对话生成。\n",
    "其中run方法接收用户输入，依次调用NLU、DST和数据库获取满足条件的套餐记录，\n",
    "然后根据套餐记录和当前状态拼装ChatGPT的输入，调用ChatGPT生成回复，并将用户输入和系统回复记录到对话的会话中。'''\n",
    "class DialogManager:\n",
    "    def __init__(self, prompt_templates):\n",
    "        self.state = {}\n",
    "        self.session = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"你是一个手机流量套餐的客服代表。可以帮助用户选择最合适的流量套餐产品。\"\n",
    "            }\n",
    "        ]\n",
    "        self.nlu = NLU()\n",
    "        self.dst = DST()\n",
    "        self.db = MockedDB()\n",
    "        self.prompt_templates = prompt_templates\n",
    "\n",
    "    def _wrap(self, user_input, records):\n",
    "        if records:\n",
    "            prompt = self.prompt_templates[\"recommand\"].replace(\n",
    "                \"__INPUT__\", user_input)\n",
    "            r = records[0]\n",
    "            for k, v in r.items():\n",
    "                prompt = prompt.replace(f\"__{k.upper()}__\", str(v))\n",
    "        else:\n",
    "            prompt = self.prompt_templates[\"not_found\"].replace(\n",
    "                \"__INPUT__\", user_input)\n",
    "            for k, v in self.state.items():\n",
    "                if \"operator\" in v:\n",
    "                    prompt = prompt.replace(\n",
    "                        f\"__{k.upper()}__\", v[\"operator\"]+str(v[\"value\"]))\n",
    "                else:\n",
    "                    prompt = prompt.replace(f\"__{k.upper()}__\", str(v))\n",
    "        return prompt\n",
    "\n",
    "    def _call_chatgpt(self, prompt, model=\"gpt-3.5-turbo\"):\n",
    "        session = copy.deepcopy(self.session)\n",
    "        session.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=session,\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def run(self, user_input):\n",
    "        # 调用NLU获得语义解析\n",
    "        semantics = self.nlu.parse(user_input)\n",
    "        print(\"===semantics===\")\n",
    "        print(semantics)\n",
    "\n",
    "        # 调用DST更新多轮状态\n",
    "        self.state = self.dst.update(self.state, semantics)\n",
    "        print(\"===state===\")\n",
    "        print(self.state)\n",
    "\n",
    "        # 根据状态检索DB，获得满足条件的候选\n",
    "        records = self.db.retrieve(**self.state)\n",
    "\n",
    "        # 拼装prompt调用chatgpt\n",
    "        prompt_for_chatgpt = self._wrap(user_input, records)\n",
    "        print(\"===gpt-prompt===\")\n",
    "        print(prompt_for_chatgpt)\n",
    "\n",
    "        # 调用chatgpt获得回复\n",
    "        response = self._call_chatgpt(prompt_for_chatgpt)\n",
    "\n",
    "        # 将当前用户输入和系统回复维护入chatgpt的session\n",
    "        self.session.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.session.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "843db6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:32:37.976850Z",
     "start_time": "2024-02-01T12:32:37.970327Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_templates = {\n",
    "    \"recommand\": \"用户说：__INPUT__ \\n\\n向用户介绍如下产品：__NAME__，月费__PRICE__元，每月流量__DATA__G。\",\n",
    "    \"not_found\": \"用户说：__INPUT__ \\n\\n没有找到满足__PRICE__元价位__DATA__G流量的产品，询问用户是否有其他选择倾向。\"\n",
    "}\n",
    "\n",
    "dm = DialogManager(prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c344757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:32:43.224102Z",
     "start_time": "2024-02-01T12:32:39.518270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===semantics===\n",
      "{'price': {'operator': '<=', 'value': 200}}\n",
      "===state===\n",
      "{'price': {'operator': '<=', 'value': 200}}\n",
      "===gpt-prompt===\n",
      "用户说：300太贵了，200元以内有吗 \n",
      "\n",
      "向用户介绍如下产品：经济套餐，月费50元，每月流量10G。\n",
      "===response===\n",
      "您好！对于您的需求，我们有一个经济套餐，每月仅需50元，包含10G的流量。这个套餐价格相对较低，适合轻度使用流量的用户。如果您对这个套餐感兴趣，我可以帮您办理。还有其他套餐需要了解吗？\n"
     ]
    }
   ],
   "source": [
    "response = dm.run(\"300太贵了，200元以内有吗\")\n",
    "# response = dm.run(\"流量大的\")\n",
    "print(\"===response===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b7836",
   "metadata": {},
   "source": [
    "#### 仅用 OpenAI API 实现上面智能对话机器人的完整功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2df57170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:35:01.268494Z",
     "start_time": "2024-02-01T12:34:56.538248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"\\n你是一个手机流量套餐的客服代表。可以帮助用户选择最合适的流量套餐产品。可以选择的套餐包括：\\n经济套餐，月费50元，10G流量；\\n畅游套餐，月费180元，100G流量；\\n无限套餐，月费300元，1000G流量；\\n校园套餐，月费150元，200G流量，仅限在校生。\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"有没有土豪套餐？\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"很抱歉，我们没有土豪套餐。但是我们有无限套餐，它提供1000G的流量，适合大量使用流量的用户。\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"多少钱？\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"无限套餐的月费是300元。\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"给我办一个\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"好的，请问您的手机号码是多少？我将为您办理无限套餐。\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "\n",
    "def print_json(data):\n",
    "    \"\"\"\n",
    "    打印参数。如果参数是有结构的（如字典或列表），则以格式化的 JSON 形式打印；\n",
    "    否则，直接打印该值。\n",
    "    \"\"\"\n",
    "    if hasattr(data, 'model_dump_json'):\n",
    "        data = json.loads(data.model_dump_json())\n",
    "\n",
    "    if (isinstance(data, (list, dict))):\n",
    "        print(json.dumps(\n",
    "            data,\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        ))\n",
    "    else:\n",
    "        print(data)\n",
    "\n",
    "# 定义消息历史。先加入 system 消息，里面放入对话内容以外的 prompt\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "你是一个手机流量套餐的客服代表。可以帮助用户选择最合适的流量套餐产品。可以选择的套餐包括：\n",
    "经济套餐，月费50元，10G流量；\n",
    "畅游套餐，月费180元，100G流量；\n",
    "无限套餐，月费300元，1000G流量；\n",
    "校园套餐，月费150元，200G流量，仅限在校生。\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "    # 把用户输入加入消息历史\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    msg = response.choices[0].message.content\n",
    "\n",
    "    # 把模型生成的回复加入消息历史。很重要，否则下次调用模型时，模型不知道上下文\n",
    "    messages.append({\"role\": \"assistant\", \"content\": msg})\n",
    "    return msg\n",
    "\n",
    "\n",
    "get_completion(\"有没有土豪套餐？\")\n",
    "get_completion(\"多少钱？\")\n",
    "get_completion(\"给我办一个\")\n",
    "print_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81085d",
   "metadata": {},
   "source": [
    "值得注意的是\n",
    "- 多轮对话，需要每次都把对话历史带上（是的很费 token 的，token==money）\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考3：</b>纯 OpenAI API 的方案，是不是更好？\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点</b>：大模型应用架构师想什么？\n",
    "<ol>\n",
    "<li>怎样能更准确？答：让更多的环节可控</li>\n",
    "<li>怎样能更省钱？答：减少 prompt 长度</li>\n",
    "<li>怎样让系统简单好维护？</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5197e",
   "metadata": {},
   "source": [
    "### 2.4 Prompt技术进阶\n",
    "\n",
    "####  ①思维链（Chain of Thoughts, CoT）\n",
    "\n",
    "思维链，是大模型涌现出来的一种神奇能力\n",
    "\n",
    "1. 它是偶然被「发现」的（OpenAI 的人在训练时没想过会这样）\n",
    "2. 有人在提问时以「Let’s think step by step」开头，结果发现 AI 会把问题分解成多个步骤，然后逐步解决，使得输出的结果更加准确。\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>思维链的原理\n",
    "<ol>\n",
    "<li>让 AI 生成更多相关的内容，构成更丰富的「上文」，从而提升「下文」正确的概率</li>\n",
    "<li>对涉及<计算和逻辑推理>等复杂问题，尤为有效</li>\n",
    "</div>\n",
    "\n",
    "其实人不也是这样吗？一拿到问题就拆解成一个个的子问题去解决，最后得到的结果就更准确。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652c784",
   "metadata": {},
   "source": [
    "- 思维链案例：客服质检\n",
    "\n",
    "任务本质是检查客服与用户的对话是否有不合规的地方\n",
    "\n",
    "- 质检是电信运营商和金融券商大规模使用的一项技术\n",
    "- 每个涉及到服务合规的检查点称为一个质检项\n",
    "\n",
    "我们选一个质检项，产品信息准确性，来演示思维链的作用：\n",
    "\n",
    "1. 当向用户介绍流量套餐产品时，客服人员必须准确提及产品名称、月费价格、月流量总量、适用条件（如有）\n",
    "2. 上述信息缺失一项或多项，或信息与事实不符，都算信息不准确\n",
    "\n",
    "下面例子如果去掉「一步一步」，context2 就会出错。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13ad5dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:41:59.231996Z",
     "start_time": "2024-02-01T12:41:54.194913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据对话记录，客服介绍产品信息的准确性可以分析如下：\n",
      "\n",
      "1. 客服提到了畅游套餐，包括月费180元和月流量100G，这与实际情况相符，属于准确信息。\n",
      "2. 客服提到了校园套餐，包括月费150元和月流量200G，并且指出该套餐只限在校学生办理，这与实际情况相符，属于准确信息。\n",
      "\n",
      "综上所述，客服介绍的产品信息是准确的。\n",
      "\n",
      "输出结果为：{\"accurate\":true}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "instruction = \"\"\"\n",
    "给定一段用户与手机流量套餐客服的对话，\n",
    "你的任务是判断客服介绍产品信息的准确性：\n",
    "\n",
    "当向用户介绍流量套餐产品时，\n",
    "客服人员必须准确提及产品名称、月费价格和月流量总量 上述信息缺失一项或多项，或信息与实时不符，都算信息不准确\n",
    "\n",
    "已知产品包括：\n",
    "\n",
    "经济套餐：月费50元，月流量10G\n",
    "畅游套餐：月费180元，月流量100G\n",
    "无限套餐：月费300元，月流量1000G\n",
    "校园套餐：月费150元，月流量200G，限在校学生办理\n",
    "\"\"\"\n",
    "\n",
    "# 输出描述\n",
    "output_format = \"\"\"\n",
    "以JSON格式输出。\n",
    "如果信息准确，输出：{\"accurate\":true}\n",
    "如果信息不准确，输出：{\"accurate\":false}\n",
    "\"\"\"\n",
    "\n",
    "context1 = \"\"\"\n",
    "用户：有什么便宜的流量套餐\n",
    "客服：您好，我们有个经济型套餐，50元每月\n",
    "\"\"\"\n",
    "\n",
    "context2 = \"\"\"\n",
    "用户：流量大的套餐有什么\n",
    "客服：我们推荐畅游套餐，180元每月，100G流量，大多数人都够用的\n",
    "用户：学生有什么优惠吗\n",
    "客服：如果是在校生的话，可以办校园套餐，150元每月，含200G流量，比非学生的畅游套餐便宜流量还多\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{output_format}\n",
    "\n",
    "请一步一步分析以下对话\n",
    "\n",
    "对话记录：\n",
    "{context2}\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a970b",
   "metadata": {},
   "source": [
    "#### ②自洽性或称自我一致性（Self-Consistency）\n",
    "\n",
    "一种对抗「幻觉」的手段。就像我们做数学题，要多次验算一样。\n",
    "\n",
    "- 同样 prompt 跑多次\n",
    "- 通过投票选出最终结果\n",
    "\n",
    "<img src=\"self_consistency.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ed8221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:18:05.995220Z",
     "start_time": "2024-02-01T08:18:01.573874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------第1次------\n",
      "{\"accurate\":true}\n",
      "------第2次------\n",
      "{\"accurate\":false}\n",
      "------第3次------\n",
      "{\"accurate\":true}\n",
      "------第4次------\n",
      "{\"accurate\":true}\n",
      "------第5次------\n",
      "{\"accurate\": true}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.8  # 必须加大随机性\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "instruction = \"\"\"\n",
    "给定一段用户与手机流量套餐客服的对话，\n",
    "你的任务是判断客服介绍产品信息的准确性：\n",
    "\n",
    "当向用户介绍流量套餐产品时，客服人员必须准确提及产品名称、月费价格和月流量总量 上述信息缺失一项或多项，或信息与实时不符，都算信息不准确\n",
    "\n",
    "已知产品包括：\n",
    "\n",
    "经济套餐：月费50元，月流量10G\n",
    "畅游套餐：月费180元，月流量100G\n",
    "无限套餐：月费300元，月流量1000G\n",
    "校园套餐：月费150元，月流量200G，限在校学生办理\n",
    "\"\"\"\n",
    "\n",
    "# 输出描述\n",
    "output_format = \"\"\"\n",
    "以JSON格式输出。\n",
    "如果信息准确，输出：{\"accurate\":true}\n",
    "如果信息不准确，输出：{\"accurate\":false}\n",
    "不要输出其他文本\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "用户：流量大的套餐有什么\n",
    "客服：我们推荐畅游套餐，180元每月，100G流量，大多数人都够用的\n",
    "用户：学生有什么优惠吗\n",
    "客服：如果是在校生的话，可以办校园套餐，150元每月，含200G流量\n",
    "\"\"\"\n",
    "\n",
    "# 连续调用 5 次\n",
    "for _ in range(5):\n",
    "    prompt = f\"{instruction}\\n\\n{output_format}\\n\\n请一步一步分析:\\n{context}\"\n",
    "    print(f\"------第{_+1}次------\")\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e24ed",
   "metadata": {},
   "source": [
    "#### ③思维树（Tree-of-thought, ToT）\n",
    "\n",
    "- 在思维链的每一步，采样多个分支\n",
    "- 拓扑展开成一棵思维树\n",
    "- 判断每个分支的任务完成度，以便进行启发式搜索\n",
    "- 设计搜索算法\n",
    "- 判断叶子节点的任务完成的正确性\n",
    "\n",
    "<img src=\"TOT.png\" style=\"margin-left: 0px\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0573c3",
   "metadata": {},
   "source": [
    "#### 案例：指标解读，项目推荐并说明依据（Prompt效果一般，有时候生成结果不好，可以自己进一步改进）\n",
    "\n",
    "小明 100 米跑成绩：10.5 秒，1500 米跑成绩：3 分 20 秒，铅球成绩：12 米。他适合参加哪些搏击运动训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f79a190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:45:56.907370Z",
     "start_time": "2024-02-01T12:45:56.889374Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_completion(prompt, model=\"gpt-4\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc1f1915",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T12:46:37.682332Z",
     "start_time": "2024-02-01T12:45:58.699312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===talents===\n",
      "{'速度': 3, '耐力': 3, '力量': 2}\n",
      "===速度 leafs===\n",
      "['拳击', '散打', '跆拳道', '泰拳', '搏击', '摔跤', '柔道', '巴西柔术', '空手道', '击剑']\n",
      "拳击: 耐力 3 True\n",
      "拳击: 力量 3 False\n",
      "散打: 耐力 3 True\n",
      "散打: 力量 3 False\n",
      "跆拳道: 耐力 3 True\n",
      "跆拳道: 力量 3 False\n",
      "泰拳: 耐力 3 True\n",
      "泰拳: 力量 3 False\n",
      "搏击: 耐力 3 True\n",
      "搏击: 力量 3 False\n",
      "摔跤: 耐力 3 True\n",
      "摔跤: 力量 3 False\n",
      "柔道: 耐力 3 True\n",
      "柔道: 力量 3 False\n",
      "巴西柔术: 耐力 3 True\n",
      "巴西柔术: 力量 3 False\n",
      "空手道: 耐力 3 True\n",
      "空手道: 力量 3 False\n",
      "击剑: 耐力 2 True\n",
      "击剑: 力量 3 False\n",
      "===耐力 leafs===\n",
      "['拳击', '泰拳', '柔道', '摔跤', '跆拳道', '巴西柔术', '散打', '综合格斗', '空手道', '击剑']\n",
      "综合格斗: 速度 3 True\n",
      "综合格斗: 力量 3 False\n"
     ]
    }
   ],
   "source": [
    "def performance_analyser(text):\n",
    "    prompt = f\"{text}\\n请根据以上成绩，分析候选人在速度、耐力、力量三方面素质的分档。分档包括：强（3），中（2），弱（1）三档。\\\n",
    "                \\n以JSON格式输出，其中key为素质名，value为以数值表示的分档。\"\n",
    "    response = get_completion(prompt)\n",
    "    return json.loads(response)\n",
    "\n",
    "\n",
    "def possible_sports(talent, category):\n",
    "    prompt = f\"需要{talent}强的{category}运动有哪些。给出10个例子，以array形式输出。确保输出能由json.loads解析。\"\n",
    "    response = get_completion(prompt, temperature=0.8)\n",
    "    return json.loads(response)\n",
    "\n",
    "\n",
    "def evaluate(sports, talent, value):\n",
    "    prompt = f\"分析{sports}运动对{talent}方面素质的要求: 强（3），中（2），弱（1）。\\\n",
    "                \\n直接输出挡位数字。输出只包含数字。\"\n",
    "    response = get_completion(prompt)\n",
    "    val = int(response)\n",
    "    print(f\"{sports}: {talent} {val} {value>=val}\")\n",
    "    return value >= val\n",
    "\n",
    "\n",
    "def report_generator(name, performance, talents, sports):\n",
    "    level = ['弱', '中', '强']\n",
    "    _talents = {k: level[v-1] for k, v in talents.items()}\n",
    "    prompt = f\"已知{name}{performance}\\n身体素质：{_talents}。\\n生成一篇{name}适合{sports}训练的分析报告。\"\n",
    "    response = get_completion(prompt, model=\"gpt-3.5-turbo\")\n",
    "    return response\n",
    "\n",
    "\n",
    "name = \"小明\"\n",
    "performance = \"100米跑成绩：10.5秒，1500米跑成绩：3分20秒，铅球成绩：12米。\"\n",
    "category = \"搏击\"\n",
    "\n",
    "talents = performance_analyser(name+performance)\n",
    "print(\"===talents===\")\n",
    "print(talents)\n",
    "\n",
    "cache = set()\n",
    "# 深度优先\n",
    "\n",
    "# 第一层节点\n",
    "for k, v in talents.items():\n",
    "    if v < 3:  # 剪枝\n",
    "        continue\n",
    "    leafs = possible_sports(k, category)\n",
    "    print(f\"==={k} leafs===\")\n",
    "    print(leafs)\n",
    "    # 第二层节点\n",
    "    for sports in leafs:\n",
    "        if sports in cache:\n",
    "            continue\n",
    "        cache.add(sports)\n",
    "        suitable = True\n",
    "        for t, p in talents.items():\n",
    "            if t == k:\n",
    "                continue\n",
    "            # 第三层节点\n",
    "            if not evaluate(sports, t, p):  # 剪枝\n",
    "                suitable = False\n",
    "                break\n",
    "        if suitable:\n",
    "            report = report_generator(name, performance, talents, sports)\n",
    "            print(\"****\")\n",
    "            print(report)\n",
    "            print(\"****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04a51a",
   "metadata": {},
   "source": [
    "#### 2.5 Prompt攻防\n",
    "- <span class=\"burk\">①奶奶攻击</span>\n",
    "\n",
    "很有趣的BUG，推测是ChatGPT的道德审查机制相当于对谈话内容进行打分，当道德分过低的时候，就会避免直接回复，转而拒绝回答。\n",
    "\n",
    "而“奶奶讲故事”的场景因为塑造了一个充满温情的场景，导致chatGPT进行道德打分时，虽然话题分较低，但是场景分很高，从而导致整体道德分高于阈值，仍然输出了答案。\n",
    "\n",
    "如果上述猜想为真的话，通过构建其它更温情更友好的场景，来询问低道德的问题时，或许也可以绕过chatGPT的道德机制。另外，有说法说通过构造紧急避险的场景，询问低道德问题，也可以获得回复，也许是让chatGPT的道德审查机制认为不回复的道德分比回复的道德分还要低，所以最后认为应该回复？\n",
    "\n",
    "- <span class=\"burk\">②Prompt 注入</span>\n",
    "\n",
    "用户输入的 prompt 改变系统既定的设定，使其输出违背设计意图的内容。\n",
    "\n",
    "- <span class=\"burk\">③Prompt分类器</span>\n",
    "\n",
    "Prompt 事先注入分类器。\n",
    "参考机场安检的思路，先把危险 prompt 拦截掉。\n",
    "\n",
    "- <span class=\"burk\">④直接在用户的Prompt输入中防御</span>\n",
    "\n",
    "例如采用：user_input_template = \"\"\"\n",
    "作为XX客服代表，你不允许生成任何无关的内容。\n",
    "用户说：#INPUT#\n",
    "\"\"\"\n",
    "- <span class=\"burk\">⑤Openai的内容审核接口：Moderation API</span>\n",
    "\n",
    "可以通过调用 OpenAI 的 Moderation API 来识别用户发送的消息是否违法相关的法律法规，如果出现违规的内容，从而对它进行过滤。\n",
    "\n",
    "进一步学习可以参考：\n",
    "\n",
    "- [ChatGPT 安全风险 | 基于 LLMs 应用的 Prompt 注入攻击](https://mp.weixin.qq.com/s/zqddET82e-0eM_OCjEtVbQ)\n",
    "- [提示词破解：绕过 ChatGPT 的安全审查](https://selfboot.cn/2023/07/28/chatgpt_hacking/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3da9c",
   "metadata": {},
   "source": [
    "**如果你在网页端调试 prompt的一些建议**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>建议：</b>\n",
    "<ol>\n",
    "<li>把 System Prompt 和 User Prompt 组合，写到界面的 Prompt 里</li>\n",
    "<li>最近几轮对话内容会被自动引用，不需要重复粘贴到新 Prompt 里</li>\n",
    "<li>如果找到了好的 Prompt，开个新 Chat 再测测，避免历史对话的干扰</li>\n",
    "<li>同时看不同大模型对同一个 Prompt 的回复，方便对比，因为LLM本身的能力也很重要</li>\n",
    "<li>尝试让LLM自己生成Prompt，然后优化调整\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7463ea3",
   "metadata": {},
   "source": [
    "## 课后作业"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f99df",
   "metadata": {},
   "source": [
    "### 1 分组情况确认\n",
    "<img src=\"分组.png\" style=\"margin-left: 0px\" width=500px>\n",
    "\n",
    "### 2 课后作业内容——了解Prompt Tuning\n",
    "- Prompt Tuning是一种新型的微调范式，旨在解决传统微调方法在处理某些特定任务时的问题。与传统的微调方法不同，Prompt Tuning并不对整个模型参数进行微调，而是通过修改输入数据的特征表示，即“提示”（Prompt），来调整模型输出。因此，Prompt Tuning可以理解为一种“提示”微调。\n",
    "\n",
    "### 3 大模型操控无人机复现\n",
    "- 要求对源代码进行解读，总结该项目用到了哪些Prompt技术\n",
    "- 更进一步，添加语音识别模块，用语音的模型替代打字的方式\n",
    "- 项目地址（微软开源的论文+源码）：https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaaada9",
   "metadata": {},
   "source": [
    "## 3 Function（Tool） Calling \n",
    "\n",
    "Function Calling [官方接口文档](https://platform.openai.com/docs/guides/function-calling) kx上网"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30137d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T09:48:17.889839Z",
     "start_time": "2024-02-01T09:48:17.884637Z"
    }
   },
   "source": [
    "### 3.1 Function Calling架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d1822",
   "metadata": {},
   "source": [
    "<img src=\"func.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd0514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:20:43.427251Z",
     "start_time": "2024-02-01T11:20:43.421948Z"
    }
   },
   "source": [
    "### 3.2 一些示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e68425",
   "metadata": {},
   "source": [
    "- 示例 1：调用本地函数\n",
    "\n",
    "实现一个回答问题的 AI。题目中如果有加法，必须能精确计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7ae83cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T13:04:23.001138Z",
     "start_time": "2024-02-01T13:04:22.222161Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "def print_json(data):\n",
    "    \"\"\"\n",
    "    打印参数。如果参数是有结构的（如字典或列表），则以格式化的 JSON 形式打印；\n",
    "    否则，直接打印该值。\n",
    "    \"\"\"\n",
    "    if hasattr(data, 'model_dump_json'):\n",
    "        data = json.loads(data.model_dump_json())\n",
    "\n",
    "    if (isinstance(data, (list, dict))):\n",
    "        print(json.dumps(\n",
    "            data,\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        ))\n",
    "    else:\n",
    "        print(data)\n",
    "        \n",
    "def get_completion(messages, model=\"gpt-4\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,  # 模型输出的随机性，0 表示随机性最小\n",
    "        tools=[{  # 用 JSON 描述函数。可以定义多个。由大模型决定调用谁。也可能都不调用\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"sum\",\n",
    "                \"description\": \"加法器，计算一组数的和\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"numbers\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"number\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }],\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "887520f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T13:04:30.016558Z",
     "start_time": "2024-02-01T13:04:26.349870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"1024 乘以 1024 等于 1048576。\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"function_call\": null,\n",
      "    \"tool_calls\": null\n",
      "}\n",
      "=====GPT回复=====\n",
      "{\n",
      "    \"content\": \"1024 乘以 1024 等于 1048576。\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"function_call\": null,\n",
      "    \"tool_calls\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "\n",
    "# prompt = \"Tell me the sum of 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\"\n",
    "# prompt = \"桌上有 2 个苹果，四个桃子和 3 本书，一共有几个水果？\"\n",
    "# prompt = \"1+2+3...+99+100\"\n",
    "prompt = \"1024 乘以 1024 是多少？\"   # Tools 里没有定义乘法，会怎样？\n",
    "# prompt = \"太阳从哪边升起？\"           # 不需要算加法，会怎样？\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个数学家\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "response = get_completion(messages)\n",
    "\n",
    "# 把大模型的回复加入到对话历史中\n",
    "print_json(response)\n",
    "messages.append(response)\n",
    "\n",
    "print(\"=====GPT回复=====\")\n",
    "print_json(response)\n",
    "\n",
    "# 如果返回的是函数调用结果，则打印出来\n",
    "if (response.tool_calls is not None):\n",
    "    # 是否要调用 sum\n",
    "    tool_call = response.tool_calls[0]\n",
    "    # ！！！这里就是写函数的地方\n",
    "    if (tool_call.function.name == \"sum\"):\n",
    "        # 调用 sum\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        result = sum(args[\"numbers\"])\n",
    "        print(\"=====函数返回=====\")\n",
    "        print(result)\n",
    "\n",
    "        # 把函数调用结果加入到对话历史中\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,  # 用于标识函数调用的 ID\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": \"sum\",\n",
    "                \"content\": str(result)  # 数值 result 必须转成字符串\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 再次调用大模型\n",
    "        print(\"=====最终回复=====\")\n",
    "        print(get_completion(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82c7e4",
   "metadata": {},
   "source": [
    "### 3.3 支持Tool Calling的国产LLM\n",
    "\n",
    "支持 Function（Tool） Calling 的国产大模型也值得体验\n",
    "\n",
    "Function Calling 会成为所有大模型的标配，支持它的越来越多\n",
    "不支持的大模型，某种程度上是不大可用的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205efaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:35:16.026780Z",
     "start_time": "2024-02-01T11:35:16.017832Z"
    }
   },
   "source": [
    "- ①百度文心\n",
    "\n",
    "官方文档：https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html\n",
    "\n",
    "百度文心系列大模型有三个。按发布时间从早到晚是：\n",
    "\n",
    "1. ERNIE-Bot - 支持 Function Calling\n",
    "2. ERNIE-Bot-turbo\n",
    "3. ERNIE-Bot 4.0 - 支持 Function Calling（暂时白名单制）\n",
    "\n",
    "Function Calling 的 API 和 OpenAI 1106 之前版本完全一样。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f3cb9",
   "metadata": {},
   "source": [
    "- ②MiniMax\n",
    "\n",
    "官方文档：https://api.minimax.chat/document/guides/chat-pro?id=64b79fa3e74cddc5215939f4\n",
    "\n",
    "应该是最早支持 Function Calling 的国产大模型，它的角色扮演能力很强\n",
    "Function Calling 的 API 和 OpenAI 1106 版之前完全一样，但其它 API 有很大的特色"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ffc4f",
   "metadata": {},
   "source": [
    "- ③ ChatGLM3-6B\n",
    "\n",
    "官方文档：https://github.com/THUDM/ChatGLM3/blob/main/tool_using/README.md\n",
    "\n",
    "最著名的国产开源大模型，生态最好\n",
    "早就使用 `tools` 而不是 `function` 来做参数，其它和 OpenAI 1106 版之前完全一样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740f3c1",
   "metadata": {},
   "source": [
    "- ④### 讯飞星火 3.0\n",
    "\n",
    "官方文档：https://www.xfyun.cn/doc/spark/Web.html#_2-function-call%E8%AF%B4%E6%98%8E\n",
    "\n",
    "和 OpenAI 1106 版之前完全一样\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5a489",
   "metadata": {},
   "source": [
    "### 3.4 Tool Calling 的想象空间\n",
    "\n",
    "想象你是下面产品的研发，怎样用 Function Calling 实现下面的功能？\n",
    "\n",
    "1. 对着微信说：「给我每个好友发一条情真意切的拜年消息，还要带点儿小幽默」\n",
    "2. 对着富途牛牛说：「人工智能相关股票，市盈率最低的是哪几个？最近交易量如何？都有哪些机构持有？」\n",
    "3. 对着京东说：「我想买一台 65 寸的电视，不要日货，价格在 5000 元左右」\n",
    "...\n",
    "\n",
    "\n",
    "基本上：\n",
    "\n",
    "1. 我们的任何功能都可以和大模型结合，提供更好的用户体验\n",
    "2. 通过大模型，完成内部功能的组合调用，完全 agent 化设计系统架构\n",
    "\n",
    "当然，「幻觉」仍然是存在的。如何尽量减少幻觉的影响，参考以下资料：\n",
    "\n",
    "- 自然语言生成中关于幻觉研究的综述：https://arxiv.org/abs/2202.03629\n",
    "- 语言模型出现的幻觉是如何滚雪球的：https://arxiv.org/abs/2305.13534\n",
    "- ChatGPT 在推理、幻觉和交互性上的评估：https://arxiv.org/abs/2302.04023\n",
    "- 对比学习减少对话中的幻觉：https://arxiv.org/abs/2212.10400\n",
    "- 自洽性提高了语言模型的思维链推理能力：https://arxiv.org/abs/2203.11171\n",
    "- 生成式大型语言模型的黑盒幻觉检测：https://arxiv.org/abs/2303.08896\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0744ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
