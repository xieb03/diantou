import torch.cuda
from torchinfo import summary

from project_utils import *


def other_simple():
    # torch.Tensorï¼šä½¿ç”¨å®ƒåˆ›å»ºçš„å¼ é‡å¯¹è±¡æ²¡æœ‰æŒ‡å®šæ•°æ®ç±»å‹ï¼Œå› æ­¤å…¶é»˜è®¤ä¸ºæµ®ç‚¹æ•°ç±»å‹ï¼ˆfloat32ï¼‰ï¼Œå…¶å€¼å–å†³äºå†…å­˜ä¸­çš„éšæœºæ•°æ®ã€‚
    # torch.tensorï¼šæ ¹æ®ç»™å®šçš„æ•°æ®åˆ›å»ºä¸€ä¸ªå¼ é‡å¯¹è±¡ï¼Œå¹¶è‡ªåŠ¨æ¨æ–­æ•°æ®ç±»å‹ã€‚å¯ä»¥æ¥å—å¤šç§æ•°æ®ç±»å‹ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œä¾‹å¦‚åˆ—è¡¨ã€å…ƒç»„ã€æ•°ç»„ç­‰ã€‚
    # tensor([1.0561e-38, 1.0194e-38, 9.2755e-39, 8.9082e-39, 8.4490e-39, 9.2755e-39]) torch.Size([6])
    # ä¼ å…¥ä¸€ä¸ªæ•´æ•° n æ—¶ï¼Œtorch.Tensor è®¤è¯† n æ˜¯ä¸€ç»´å¼ é‡çš„å…ƒç´ ä¸ªæ•°ï¼Œå¹¶éšæœºåˆå§‹åŒ–
    print(torch.Tensor(6), torch.Tensor(6).shape)
    # tensor(6) torch.Size([])
    # torch.Size([]) å’Œ torch.Size([0]) çš„åŒºåˆ«ï¼Œå‰è€…æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œä¸èƒ½è¿­ä»£ï¼Œåè€…æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œåªä¸è¿‡æ²¡æœ‰å…ƒç´ ï¼Œå½¢å¦‚ []ï¼Œå¯ä»¥è¿­ä»£
    # torch.tensoråˆ™ä¼šå°†nè§†ä½œä¸€ä¸ªæ•°å­—è€Œä¸æ˜¯å…ƒç´ ä¸ªæ•°ã€‚ä¾‹å¦‚ï¼š
    print(torch.tensor(6), torch.tensor(6).shape)
    # tensor([1., 2., 3.])
    print(torch.Tensor([1, 2, 3]))
    # tensor([1, 2, 3])
    print(torch.tensor([1, 2, 3]))

    # torch.arange(start=0, end, step=1)
    # åŒ python çš„ rangeï¼Œå‰å¼€åé—­
    assert_tensor_equal(torch.arange(1, 10, 3), [1, 4, 7])
    assert_tensor_equal(torch.arange(1, 1, 3), [])

    # reshape ä¼šè§†æƒ…å†µè¿”å› view æˆ–è€…æ˜¯æ–°çš„ copyï¼Œä¸èƒ½ä¾èµ–è¿™ä¸€ç‚¹
    # ä½† view å¯èƒ½ä¼šå¤±è´¥ï¼Œå› ä¸ºå¿…é¡»æ˜¯ strided
    assert_tensor_shape_equal(torch.arange(1, 10).reshape((3, 3)), (3, 3))

    a = get_a_sample_tensor((2, 3))
    # transpose æ˜¯å°†ä¸¤ä¸ªç»´åº¦è¿›è¡Œè½¬ç½®ï¼Œå¦‚æœ strided åˆ™åŸä½ï¼Œå¦åˆ™è¿”å› copy
    b = a.transpose(0, 1)
    # view ç›¸å½“äºæ˜¯ reshapeï¼Œæ³¨æ„ view å¯èƒ½ä¼šæ‰§è¡Œå¤±è´¥ï¼Œå¦‚æœ tensor ä¸æ˜¯ stridedï¼Œè€Œ reshape åˆ™ä¸ä¼šå¤±è´¥ï¼Œå¦‚æœä¸æ˜¯ strided å°±è¿”å› copy
    c = a.view(3, 2)
    assert_tensor_equal(b, [[0, 3], [1, 4], [2, 5]])
    assert_tensor_equal(c, [[0, 1], [2, 3], [4, 5]])
    assert_tensor_shape_equal(b, c)
    assert not torch.equal(b, c)

    # linalg.vector_norm: Expected a floating point or complex tensor as input. Got Long
    # å¦‚æœä¸åŠ  dimï¼Œå°±ä¸èƒ½ keepdim=Trueï¼Œå› ä¸ºè¿™ä¸ªæ—¶å€™å·²ç»æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œæ²¡æ³•æ‰©å±•ç»´åº¦ï¼Œå·²ç»æ¢å¤ä¸äº†äº†
    a = get_a_sample_tensor((2, 3))
    # å¦‚æœ norm ä¸ä¼ å…¥ä»»ä½•å‚æ•°ï¼Œåˆ™ç­‰ä»·äºå°† tensor å±•å¹³ï¼Œè¿”å›æ‰€æœ‰å…ƒç´ çš„ norm
    # norm(p: Optional[Union[float, str]] = "fro", dim=None, keepdim=False, dtype=None,
    assert_tensor_close(a.norm(), 7.4162)
    assert_tensor_close(a.norm(keepdim=True), [[7.4162]])
    assert_tensor_close(a.norm(dim=0), [3.0000, 4.1231, 5.3852])
    assert_tensor_close(a.norm(dim=(0, 1)), 7.4162)

    # tf.expand: å°†å¼ é‡å¹¿æ’­åˆ°æ–°çš„å½¢çŠ¶ã€‚
    # æ³¨æ„ï¼š åªèƒ½å¯¹ç»´åº¦å€¼ä¸º 1 çš„ç»´åº¦è¿›è¡Œæ‰©å±•ï¼Œæ— éœ€æ‰©å±•çš„ç»´åº¦ï¼Œç»´åº¦å€¼ä¸å˜ï¼Œå¯¹åº”ä½ç½®å¯å†™ä¸ŠåŸå§‹ç»´åº¦å¤§å°æˆ–ç›´æ¥å†™ä½œ -1
    # ä¸”æ‰©å±•çš„Tensorä¸ä¼šåˆ†é…æ–°çš„å†…å­˜ï¼Œåªæ˜¯åŸæ¥çš„åŸºç¡€ä¸Šåˆ›å»ºæ–°çš„è§†å›¾å¹¶è¿”å›ï¼Œè¿”å›çš„å¼ é‡å†…å­˜æ˜¯ä¸è¿ç»­çš„ã€‚
    # ç±»ä¼¼äºnumpyä¸­çš„broadcast_toå‡½æ•°çš„ä½œç”¨ã€‚å¦‚æœå¸Œæœ›å¼ é‡å†…å­˜è¿ç»­ï¼Œå¯ä»¥è°ƒç”¨contiguouså‡½æ•°ã€‚
    # expandå‡½æ•°å¯èƒ½å¯¼è‡´åŸå§‹å¼ é‡çš„å‡ç»´ï¼Œå…¶ä½œç”¨åœ¨å¼ é‡å‰é¢çš„ç»´åº¦ä¸Š(åœ¨tensorçš„ä½ç»´å¢åŠ æ›´å¤šç»´åº¦)ï¼Œå› æ­¤é€šè¿‡expandå‡½æ•°å¯å°†å¼ é‡æ•°æ®å¤åˆ¶å¤šä»½ï¼ˆå¯ç†è§£ä¸ºæ²¿ç€ç¬¬ä¸€ä¸ªbatchçš„ç»´åº¦ä¸Šï¼‰
    # expand_as å¯è§†ä¸º expand çš„å¦ä¸€ç§è¡¨è¾¾ï¼Œå…¶sizeé€šè¿‡å‡½æ•°ä¼ é€’çš„ç›®æ ‡å¼ é‡çš„sizeæ¥å®šä¹‰ã€‚
    a = torch.arange(6).reshape((1, 1, 2, 3))
    assert_tensor_shape_equal(a.expand(2, -1, -1, -1), [2, 1, 2, 3])
    assert_tensor_shape_equal(a.squeeze(), [2, 3])
    assert_tensor_shape_equal(a.squeeze(0), [1, 2, 3])
    assert_tensor_shape_equal(a.squeeze((0, 1)), [2, 3])
    # å¦‚æœ squeeze æŸä¸€ä½ä¸æ˜¯ 1ï¼Œä¼šå…¼å®¹ä¸å¤„ç†ï¼Œå¯ä»¥ä¼ å…¥ tuple
    assert_tensor_shape_equal(a.squeeze((0, 1, 2)), [2, 3])
    # unsqueeze ä¸èƒ½ä¼ å…¥ tuple
    assert_tensor_shape_equal(a.unsqueeze(2), [1, 1, 1, 2, 3])

    # tensor.repeat()ï¼šå’Œexpand()ä½œç”¨ç±»ä¼¼ï¼Œå‡æ˜¯å°†tensorå¹¿æ’­åˆ°æ–°çš„å½¢çŠ¶ã€‚
    # æ³¨æ„ï¼šä¸å…è®¸ä½¿ç”¨ç»´åº¦ -1ï¼Œ1 å³ä¸ºä¸å˜ã€‚
    # å‰æ–‡æåŠexpandä»…èƒ½ä½œç”¨äºå•æ•°ç»´ï¼Œé‚£å¯¹äºéå•æ•°ç»´çš„æ‹“å±•ï¼Œé‚£å°±éœ€è¦å€ŸåŠ©äºrepeatå‡½æ•°äº†ã€‚
    # tensor.repeat(*sizes)
    # å‚æ•°*sizesæŒ‡å®šäº†åŸå§‹å¼ é‡åœ¨å„ç»´åº¦ä¸Šå¤åˆ¶çš„æ¬¡æ•°ã€‚æ•´ä¸ªåŸå§‹å¼ é‡ä½œä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œå¤åˆ¶ï¼Œè¿™ä¸Numpyä¸­çš„repeatå‡½æ•°æˆªç„¶ä¸åŒï¼Œè€Œæ›´æ¥è¿‘äºtileå‡½æ•°çš„æ•ˆæœã€‚
    # ä¸expandä¸åŒï¼Œrepeatå‡½æ•°ä¼šçœŸæ­£çš„å¤åˆ¶æ•°æ®å¹¶å­˜æ”¾äºå†…å­˜ä¸­ã€‚repeatå¼€è¾Ÿäº†æ–°çš„å†…å­˜ç©ºé—´ï¼Œtorch.repeatè¿”å›çš„å¼ é‡åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­çš„
    assert_tensor_shape_equal(a.repeat(1, 2, 3, 4), [1, 2, 6, 12])


# å„ç§ä¹˜æ³•
def check_mul():
    a = get_a_sample_tensor((2, 3))
    b = get_a_sample_tensor((2, 3))
    c = get_a_sample_tensor((3, 2))
    d = get_a_sample_tensor((1,))
    f = get_a_sample_tensor((3,))
    g = get_a_sample_tensor((3,))
    h = get_a_sample_tensor((2, 2, 3))
    x = get_a_sample_tensor((10, 1, 3, 4))
    y = get_a_sample_tensor((10, 3, 4, 5))
    z = get_a_sample_tensor((10, 3, 4, 5))

    # torch.mul é€ä¸ªå…ƒç´ ç›¸ä¹˜ï¼Œå¯ä»¥è¿›è¡Œå¹¿æ’­ï¼Œç®€å†™æ˜¯ *
    # å¹¿æ’­æœºåˆ¶ï¼š
    # 1.å¦‚æœç»´åº¦ä¸ªæ•°ä¸åŒï¼Œåˆ™åœ¨ç»´åº¦è¾ƒå°‘çš„å·¦è¾¹è¡¥1ï¼Œä½¿å¾—ç»´åº¦çš„ä¸ªæ•°ç›¸åŒã€‚
    # 2.å„ç»´åº¦çš„ç»´åº¦å¤§å°ä¸åŒæ—¶ï¼Œå¦‚æœæœ‰ç»´åº¦ä¸º1çš„ï¼Œç›´æ¥å°†è¯¥ç»´æ‹‰ä¼¸è‡³ç»´åº¦ç›¸åŒ
    assert_tensor_shape_equal(torch.mul(a, b), (2, 3))
    assert_tensor_shape_equal(torch.mul(a, d), (2, 3))
    # The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 1
    # å¹¿æ’­åªèƒ½å¹¿æ’­æœ‰ 1 çš„ï¼Œä¸èƒ½æ™ºèƒ½çš„æ±‚å…¬å€æ•°
    # assert_tensor_shape_equal(torch.mul(a, e), (2, 3))

    # torch.matmul çŸ©é˜µç›¸ä¹˜ï¼Œç®€å†™æ˜¯ @
    # vector * vectorï¼Œå¾—åˆ°ä¸€ä¸ªæ ‡é‡
    # 1D * 1D = 0D
    assert_tensor_shape_equal(torch.matmul(f, g), tuple())
    # matrix * vectorï¼Œå¾—åˆ°ä¸€ä¸ª vector
    # 2D * 1D = 1D
    assert_tensor_shape_equal(torch.matmul(a, g), (2,))
    # 3D * vector = 2D
    assert_tensor_shape_equal(torch.matmul(h, g), (2, 2))
    # (..., a, b)D * (..., b, c)D = (..., a, c)Dï¼Œæœ€å2D å¿…é¡»æ»¡è¶³çŸ©é˜µä¹˜æ³•çš„æ¡ä»¶ï¼Œå‰é¢å¿…é¡»ä¸€è‡´ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¸­å¯ä»¥è§¦å‘å¹¿æ’­æœºåˆ¶
    assert_tensor_shape_equal(torch.matmul(x, y), (10, 3, 3, 5))
    assert_tensor_shape_equal(torch.matmul(x, z), (10, 3, 3, 5))

    # torch.mmï¼ŒçŸ©é˜µç›¸ä¹˜ï¼Œä¸ä¼šè¿›è¡Œå¹¿æ’­ï¼Œå¿…é¡»æ»¡è¶³çŸ©é˜µç›¸ä¹˜ç»´æ•°æ¡ä»¶,ä¸¤çŸ©é˜µæœ€å¤šæ˜¯2ç»´
    assert_tensor_shape_equal(torch.mm(a, c), (2, 2))

    # torch.bmmï¼Œæ‰¹çŸ©é˜µç›¸ä¹˜ï¼Œä¸ä¼šè¿›è¡Œå¹¿æ’­ï¼Œå¿…é¡»æ»¡è¶³çŸ©é˜µç›¸ä¹˜ç»´æ•°æ¡ä»¶ï¼Œa,bæœ€å¤šåªèƒ½3ç»´ï¼Œä¸”a,bä¸­å¿…é¡»åŒ…å«ç›¸åŒçš„çŸ©é˜µä¸ªæ•°å³a,bç¬¬ä¸€ç»´åº¦å¿…é¡»ç›¸åŒ
    assert_tensor_shape_equal(torch.bmm(torch.unsqueeze(a, 0), torch.unsqueeze(c, 0)), (1, 2, 2))

    # torch.dot(a,b)ï¼Œå‘é‡ç‚¹ç§¯ï¼Œä¸¤å‘é‡ç›¸ä¹˜ç›¸åŠ å¾—åˆ°ä¸€ä¸ªæ ‡é‡ï¼Œå¿…é¡»éƒ½æ˜¯ä¸€ç»´çš„
    assert_tensor_shape_equal(torch.dot(f, g), tuple())


# dim (int or tuple of python:ints) â€“ the dimension or dimensions to reduce.
# åœ¨å“ªäº›ç»´åº¦ä¸Šé¢åšå¹³å‡
# keepdim (bool) â€“ whether the output tensor has dim retained or not.
# æ˜¯å¦ä¿æŒå’ŒåŸæ¥ä¸€æ ·çš„ç»´åº¦ï¼Œé»˜è®¤æ˜¯ Falseï¼Œæ³¨æ„ç»´åº¦è¡¨ç¤ºåæ ‡ç³»ï¼Œå³ä¸‰ç»´è¡¨ç¤ºæœ‰ä¸‰ä¸ªæ–¹å‘ï¼Œshape è¡¨ç¤ºæ¯ä¸ªæ–¹å‘å¤šå¤§
def check_mean_op():
    # 2 * 3 * 4
    array = np.resize(np.array(range(1, 25)), (2, 3, 4))
    tensor = torch.tensor(array, dtype=torch.float)

    # æ³¨æ„ tensor.mean() æ˜¯æ ‡é‡ï¼Œä¸èƒ½ç”¨ to_tuple(0) æ¥æ¯”è¾ƒ
    assert_tensor_shape_equal(tensor.mean(), tuple())
    # å¦‚æœä¸åŠ  dimï¼Œå°±ä¸èƒ½ keepdim=Trueï¼Œå› ä¸ºè¿™ä¸ªæ—¶å€™å·²ç»æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œæ²¡æ³•æ‰©å±•ç»´åº¦ï¼Œå·²ç»æ¢å¤ä¸äº†äº†
    # tensor.mean(keepdim=True)
    assert_tensor_shape_equal(tensor.mean(dim=(1,)), (2, 4))
    assert_tensor_shape_equal(tensor.mean(dim=(1,), keepdim=True), (2, 1, 4))
    assert_tensor_shape_equal(tensor.mean(dim=(0,)), (3, 4))
    assert_tensor_shape_equal(tensor.mean(dim=(0,), keepdim=True), (1, 3, 4))
    assert_tensor_shape_equal(tensor.mean(dim=(0, 1)), 4)
    assert_tensor_shape_equal(tensor.mean(dim=(0, 1), keepdim=True), (1, 1, 4))


# unbiased (bool) â€“ whether to use Besselâ€™s correction
# æ˜¯å¦å¼€å¯ è´å¡å°”æ ¡æ­£ï¼Œé»˜è®¤æ˜¯ Trueï¼Œå½¢å¦‚ np.std() ä¸­çš„ ddof=1ï¼ŒMeans Delta Degrees of Freedom
# åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œè´å¡å°”æ ¡æ­£æ˜¯åœ¨æ ·æœ¬çš„æ–¹å·®å’Œæ ‡å‡†å·®çš„å…¬å¼ä¸­ç”¨n-1æ¥ä»£æ›¿nã€‚è¿™ä¸ªæ–¹æ³•æ ¡æ­£äº†æ ·æœ¬æ–¹å·®/æ ·æœ¬æ ‡å‡†å·®ï¼Œä¸æ€»ä½“æ–¹å·®/æ ·æœ¬æ ‡å‡†å·®ä¹‹é—´çš„è¯¯å·®ã€‚
# ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œå¦‚æœä¸€ä¸ªæ•°æ®é›†æ»¡è¶³é«˜æ–¯åˆ†å¸ƒï¼ˆNormal Distributionï¼‰ï¼Œé‚£å½“æˆ‘ä»¬æå–æ ·æœ¬çš„æ—¶å€™ï¼Œæ•°æ®åŸºæœ¬ä¸Šä¼šé›†ä¸­åœ¨ä¸­é—´çš„éƒ¨åˆ†ï¼Œè€Œè¾¹ç¼˜å€¼çš„æ•°ç›®å¯èƒ½ä¼šæ¯”è¾ƒå°‘ï¼Œ
# æ‰€ä»¥æœ€åå¾—åˆ°çš„æ ·æœ¬æ–¹å·®å’Œæ ·æœ¬æ ‡å‡†å·®ä¼šæ¯”æ€»ä½“è¦å°ã€‚ä¸ºäº†ä¿®æ­£è¿™ä¸ªåå·®ï¼Œåœ¨è®¡ç®—æ ·æœ¬çš„æ–¹å·®å’Œæ ‡å‡†å·®æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ n-1 ä»£æ›¿ nã€‚è¿™æ ·å¤„ç†åæœ€ç›´æ¥çš„ç»“æœæ˜¯ï¼Œå…¬å¼ä¸­çš„åˆ†æ¯å˜å°ï¼Œå¾—åˆ°çš„ç»“æœå°†ä¼šå˜å¤§ï¼Œèƒ½å¤Ÿæ›´åŠ å‡†ç¡®åœ°é€šè¿‡è¯¥æ ·æœ¬é¢„æµ‹æ€»ä½“çš„æƒ…å†µã€‚
def check_std_op():
    # 2 * 3 * 4
    array = np.array(range(1, 4))
    # sqrt((1 + 0 + 1) / 3) = 0.816496580927726
    assert_close(np.std(array), 0.8165)
    # sqrt((1 + 0 + 1) / (3 - 1)) = 1.0
    assert_equal(np.std(array, ddof=1), 1)

    tensor = torch.tensor(array, dtype=torch.float)
    assert_tensor_equal(tensor.std(), 1)
    assert_tensor_close(tensor.std(unbiased=False), 0.8165)


# per channel
# æ¯ä¸€ä¸ª C =  channel å†…ï¼Œå¯¹æ•´ä¸ª mini-batch çš„å½’ä¸€åŒ–ï¼Œæ”¶ç¼©å‡ ç»´ï¼Œå°±æœ‰å¤šå°‘å¯¹ (Î³, Î²)
# é™¤äº† C éƒ½æ”¶ç¼©
# normalized_shape = C, æ¯ä¸€ä¸ª normalized_shape æœ‰ä¸€å¯¹ (Î³, Î²)
# (N, C) -> (1, C)
# nlp, C æ˜¯ embedding çš„ç»´åº¦ï¼Œl æ˜¯æ ·æœ¬é•¿åº¦
# (N, C, L) -> (1, C, 1)
# cvï¼ŒC æ˜¯é€šé“æ•°ï¼ŒHã€W æ˜¯é•¿å®½
# (N, C, H, W) -> (1, C, 1, 1)
def check_batch_norm():
    # Applies Batch Normalization over a 2D or 3D input
    # ä¸€ç»´ BNï¼Œé’ˆå¯¹ 2d æˆ–è€… 3d input
    # num_features â€“ number of features or channels C of the input
    # eps â€“ a value added to the denominator for numerical stability. Default: 1e-5
    # momentum â€“ the value used for the running_mean and running_var computation.
    # Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1
    # affine â€“ a boolean value that when set to True, this module has learnable affine parameters. Default: True
    # track_running_stats â€“ a boolean value that when set to True, this module tracks the running mean and variance,
    # and when set to False, this module does not track such statistics, and initializes statistics buffers
    # running_mean and running_var as None. When these buffers are None, this module always uses batch statistics.
    # in both training and eval modes. Default: True
    c_index = 1

    # (N, C) -> (1, C)
    shape = (2, 3)
    c = shape[c_index]
    other_index_list = get_index_exclude_index(shape, c_index)
    x = get_a_sample_tensor(shape)
    x_bn = nn.BatchNorm1d(c)(x)
    x_bn_check = get_tensor_norm(x, other_index_list)
    assert_tensor_close(x_bn, x_bn_check)

    # (N, C, L) -> (1, C, 1)
    shape = (2, 3, 4)
    c = shape[c_index]
    x = get_a_sample_tensor(shape)
    x_bn = nn.BatchNorm1d(c)(x)
    other_index_list = get_index_exclude_index(shape, c_index)
    # å¯¹æ¯” nn.BatchNorm1d(c)ï¼Œå¯¹é™¤äº† c ä»¥å¤–çš„ç»´åº¦å…¨éƒ¨æ”¶ç¼©
    x_bn_check = get_tensor_norm(x, other_index_list)
    assert_tensor_close(x_bn, x_bn_check)

    # Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension)
    # äºŒç»´ BNï¼Œé’ˆå¯¹ 4d input
    # (N, C, H, W) -> (1, C, 1, 1)
    shape = (2, 3, 4, 5)
    c = shape[c_index]
    other_index_list = get_index_exclude_index(shape, c_index)
    x = get_a_sample_tensor(shape)
    x_bn = nn.BatchNorm2d(c)(x)
    # å¯¹æ¯” nn.BatchNorm1d(c)ï¼Œå¯¹é™¤äº† c ä»¥å¤–çš„ç»´åº¦å…¨éƒ¨æ”¶ç¼©
    x_bn_check = get_tensor_norm(x, other_index_list)
    assert_tensor_close(x_bn, x_bn_check)


# per sample per layer
# åªå¯¹æŒ‡å®šçš„åå‡ ç»´åšæ”¶ç¼©
# normalized_shape = æœ€åå‡ ä¸ªç»´åº¦ï¼Œæ”¶ç¼©å‡ ç»´ï¼Œå°±æœ‰å¤šå°‘å¯¹ (Î³, Î²)
# (N, C) -> (N, 1)
# nlp
# (N, L, C) -> (N, L, 1)
# cv
# (N, C, H, W) -> (N, 1, 1, 1)

# NLP Example
# embedding = torch.randn(batch, sentence_length, embedding_dim)
# layer_norm = nn.LayerNorm(embedding_dim)
# layer_norm(embedding)

# Image Example
# N, C, H, W = 20, 5, 10, 10
# input = torch.randn(N, C, H, W)
# layer_norm = nn.LayerNorm([C, H, W])
def check_layer_norm():
    # Applies Layer Normalization over a mini-batch of inputs
    # ä»»æ„ç»´ LN
    # å’Œ BN ä¸åŒï¼ŒLN ä¸­çš„ mean å’Œ std æ˜¯ç”±å½“å‰æ ·æœ¬å†³å®šçš„ï¼Œä¸æ›´æ–°

    # (N, C) -> (N, 1)
    shape = (2, 3)
    last_dimensions = [-1]
    normalized_shape = to_tuple(get_list_from_index(shape, last_dimensions))
    x = get_a_sample_tensor(shape)
    x_bn = nn.LayerNorm(normalized_shape)(x)
    x_bn_check = get_tensor_norm(x, last_dimensions)
    assert_tensor_close(x_bn, x_bn_check)

    # (N, L, C) -> (N, L, 1)
    shape = (2, 3, 4)
    last_dimensions = [-1]
    normalized_shape = to_tuple(get_list_from_index(shape, last_dimensions))
    x = get_a_sample_tensor(shape)
    x_bn = nn.LayerNorm(normalized_shape)(x)
    x_bn_check = get_tensor_norm(x, last_dimensions)
    assert_tensor_close(x_bn, x_bn_check)

    # (N, L, C) -> (N, 1, 1)
    shape = (2, 3, 4)
    last_dimensions = [-2, -1]
    normalized_shape = to_tuple(get_list_from_index(shape, last_dimensions))
    x = get_a_sample_tensor(shape)
    x_bn = nn.LayerNorm(normalized_shape)(x)
    x_bn_check = get_tensor_norm(x, last_dimensions)
    assert_tensor_close(x_bn, x_bn_check)

    # (N, C, H, W) -> (N, 1, 1, 1)
    shape = (2, 3, 4, 5)
    last_dimensions = [-3, -2, -1]
    normalized_shape = to_tuple(get_list_from_index(shape, last_dimensions))
    x = get_a_sample_tensor(shape)
    x_bn = nn.LayerNorm(normalized_shape)(x)
    x_bn_check = get_tensor_norm(x, last_dimensions)
    assert_tensor_close(x_bn, x_bn_check, abs_tol=1e-6)


# per sample per channel
# ä¸€å®šä¿ç•™ Cï¼Œå¦‚æœæœ‰ Nï¼Œä¹Ÿä¿ç•™ Nï¼Œæ”¶ç¼©å‡ ç»´ï¼Œå°±æœ‰å¤šå°‘å¯¹ (Î³, Î²)
# (C, L) -> (C, 1)
# nlp
# (N, L, C) -> (N, L, 1)
# (C, H, W) -> (C, 1, 1)
# cv
# (N, C, H, W) -> (N, C, 1, 1)
def check_instance_norm():
    # (C, L) -> (C, 1)
    c_index = 0
    shape = (2, 3)
    c = shape[c_index]
    x = get_a_sample_tensor(shape)
    x_bn = nn.InstanceNorm1d(c)(x)
    x_bn_check = get_tensor_norm(x, 1)
    assert_tensor_close(x_bn, x_bn_check)

    # (N, L, C) -> (N, L, 1)
    c_index = 1
    shape = (2, 3, 4)
    c = shape[c_index]
    x = get_a_sample_tensor(shape)
    x_bn = nn.InstanceNorm1d(c)(x)
    x_bn_check = get_tensor_norm(x, 2)
    assert_tensor_close(x_bn, x_bn_check)

    # (C, H, W) -> (C, 1, 1)
    c_index = 0
    shape = (2, 3, 4)
    c = shape[c_index]
    x = get_a_sample_tensor(shape)
    x_bn = nn.InstanceNorm2d(c)(x)
    x_bn_check = get_tensor_norm(x, (1, 2))
    assert_tensor_close(x_bn, x_bn_check, abs_tol=1e-6)

    # (N, C, H, W) -> (N, C, 1, 1)
    c_index = 1
    shape = (2, 3, 4, 5)
    c = shape[c_index]
    x = get_a_sample_tensor(shape)
    x_bn = nn.InstanceNorm2d(c)(x)
    x_bn_check = get_tensor_norm(x, (2, 3))
    assert_tensor_close(x_bn, x_bn_check, abs_tol=1e-6)


# per sample per group
# group_norm æ˜¯ layer_norm çš„ç‰¹æ®Šæƒ…å†µ
# åªå¯¹æŒ‡å®šçš„åå‡ ç»´åšæ”¶ç¼©
# normalized_shape = æœ€åå‡ ä¸ªç»´åº¦ï¼Œæ”¶ç¼©å‡ ç»´ï¼Œå°±æœ‰å¤šå°‘å¯¹ (Î³, Î²)
# num_channels must be divisible by num_groups
# num_groups å¿…é¡»èƒ½å‡åˆ† C
# (N, C) -> num_groups * (N, 1)
# (N, C, L) -> num_groups * (N, 1, 1)
# (N, C, H, W) -> num_groups * (N, 1, 1, 1)

# NLP Example
# embedding = torch.randn(batch, sentence_length, embedding_dim)
# layer_norm = nn.LayerNorm(embedding_dim)
# layer_norm(embedding)

# Image Example
# N, C, H, W = 20, 5, 10, 10
# input = torch.randn(N, C, H, W)
# layer_norm = nn.LayerNorm([C, H, W])
def check_group_norm():
    c_index = 1

    for num_groups in (1, 2, 4):
        # (N, C) -> num_groups * (N, 1)
        shape = (2, 4)
        c = shape[c_index]
        x = get_a_sample_tensor(shape)
        x_bn = nn.GroupNorm(num_groups, c)(x)
        x_bn_check_list = list()
        for sub_x in torch.split(x, c // num_groups, dim=c_index):
            sub_x_bn_check = get_tensor_norm(sub_x, 1)
            x_bn_check_list.append(sub_x_bn_check)
        # cat æ˜¯ split çš„é€†æ“ä½œï¼Œè¿™é‡Œç”¨äº split ä¸€æ ·çš„ dim
        x_bn_check = torch.cat(x_bn_check_list, dim=c_index)
        assert_tensor_close(x_bn, x_bn_check)

        # (N, C, L) -> num_groups * (N, 1, 1)
        shape = (2, 4, 5)
        c = shape[c_index]
        x = get_a_sample_tensor(shape)
        x_bn = nn.GroupNorm(num_groups, c)(x)
        x_bn_check_list = list()
        for sub_x in torch.split(x, c // num_groups, dim=c_index):
            sub_x_bn_check = get_tensor_norm(sub_x, (1, 2))
            x_bn_check_list.append(sub_x_bn_check)
        # cat æ˜¯ split çš„é€†æ“ä½œï¼Œè¿™é‡Œç”¨äº split ä¸€æ ·çš„ dim
        x_bn_check = torch.cat(x_bn_check_list, dim=c_index)
        assert_tensor_close(x_bn, x_bn_check)

        # (N, C, H, W) -> num_groups * (N, 1, 1, 1)
        shape = (2, 4, 5, 6)
        c = shape[c_index]
        x = get_a_sample_tensor(shape)
        x_bn = nn.GroupNorm(num_groups, c)(x)
        x_bn_check_list = list()
        for sub_x in torch.split(x, c // num_groups, dim=c_index):
            sub_x_bn_check = get_tensor_norm(sub_x, (1, 2, 3))
            x_bn_check_list.append(sub_x_bn_check)
        # cat æ˜¯ split çš„é€†æ“ä½œï¼Œè¿™é‡Œç”¨äº split ä¸€æ ·çš„ dim
        x_bn_check = torch.cat(x_bn_check_list, dim=c_index)
        assert_tensor_close(x_bn, x_bn_check, abs_tol=1E-6)


# https://pytorch.org/docs/2.2/generated/torch.nn.utils.parametrizations.weight_norm.html#torch.nn.utils.parametrizations.weight_norm
# w = g * v / |v|
# å°† weight æƒé‡çŸ©é˜µæ‹†æˆä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯å¹…å€¼ gï¼Œå¦å¤–ä¸€ä¸ªæ˜¯æ–¹å‘ v / |v|
# v = w, g = |w| æ‰€ä»¥ g * v / |v| = w
# å…¶ä¸­ï¼Œ|w| = w.norm(dim=1, keepdim=True))
def check_weight_norm():
    shape = (3, 5)
    x = get_a_sample_tensor(shape)

    linear = nn.Linear(5, 7, bias=False)
    y = linear(x)
    assert_tensor_shape_equal(y, (3, 7))

    weight = linear.weight
    assert_tensor_shape_equal(weight, (7, 5))
    assert_tensor_shape_equal(weight.T, (5, 7))
    y_check = torch.matmul(x, weight.T)
    assert_tensor_equal(y, y_check)

    wn_linear = torch.nn.utils.parametrizations.weight_norm(linear)
    # weight æœ¬èº«æ˜¯ä¸å˜çš„ï¼Œåªæ˜¯æ¯æ¬¡è¿›è¡Œ forward ä¹‹å‰ä¼šåˆ©ç”¨ä¸‹é¢çš„ g å’Œ v æ¥è®¡ç®—
    assert_tensor_equal(weight, wn_linear.weight)
    wn_y = wn_linear(x)
    assert_tensor_equal(y, wn_y)

    # æ¯ä¸ª x æ˜¯ä¸€ä¸ª 5D vectorï¼Œå› æ­¤æ¯ä¸ª w æ˜¯ä¸€ä¸ª 5D vectorï¼Œå› ä¸ºè¾“å‡ºå±‚æ˜¯ 7ï¼Œ å› æ­¤éœ€è¦æœ‰ 7 ä¸ª w ç»„æˆä¸€ä¸ª W
    # è¿™é‡ŒçŸ©é˜µèŒƒæ•° |W| æ˜¯è¡¨ç¤ºå°†æ¯ä¸ª w è¿›è¡Œå½’ä¸€åŒ– (L2 èŒƒæ•°)ï¼Œè¿™æ · W @ W = çš„å¯¹è§’çº¿éƒ½æ˜¯ 1
    weight_norm = weight.norm(dim=1, keepdim=True)
    # å¦å¤–ä¸€ç§è®¡ç®—çŸ©é˜µèŒƒæ•°çš„æ–¹æ³•
    assert_tensor_equal(weight_norm,
                        torch.tensor([get_vector_norm(weight[i, :]) for i in torch.arange(weight.shape[0])])
                        .unsqueeze(-1))
    assert_tensor_shape_equal(weight_norm, (7, 1))
    weight_direction = weight / weight_norm

    assert_tensor_close(weight_direction.norm(dim=-1), [1.0] * 7)
    assert_tensor_close((weight_direction @ weight_direction.T).diagonal().sum(), 7.0)

    # # åˆ©ç”¨çŸ©é˜µèŒƒæ•°å½’ä¸€åŒ–ï¼Œä½¿å¾— weight_v è¡¨ç¤ºæ–¹å‘ï¼ŒçŸ©é˜µèŒƒæ•° = çŸ©é˜µå„é¡¹å…ƒç´ å¹³æ–¹å’Œå†å¼€æ ¹å·ï¼Œæ³¨æ„è¿™é‡Œç”¨çš„å¹¶ä¸æ˜¯è¿™ä¸ªèŒƒæ•°
    weight_v = wn_linear.parametrizations.weight.original1
    weight_g = wn_linear.parametrizations.weight.original0
    assert_tensor_shape_equal(weight_g, (7, 1))
    assert_tensor_shape_equal(weight_v, (7, 5))

    assert_tensor_equal(weight_norm, weight_g)
    assert_tensor_equal(weight, weight_v)


def check_gpu(_with_speed=False):
    # 2.2.1+cu121
    print(torch.__version__)

    assert torch.cuda.is_available()
    assert torch.backends.cudnn.enabled

    if _with_speed:
        dimension = 5000

        # i9-9900K
        # spent 111.40064930915833
        # i9-14900KF
        # spent 40.08144783973694
        # device = torch.device("cpu")

        # 2080Ti
        # spent 4.195726633071899
        # 4090
        # spent 2.9713356494903564
        device = torch.device("cuda")

        x = torch.rand((dimension, dimension), dtype=torch.float32)
        y = torch.rand((dimension, dimension), dtype=torch.float32)

        x = x.to(device)
        y = y.to(device)

        start_time = time.time()
        for i in range(10000):
            # noinspection PyUnusedLocal
            z = x * y
        end_time = time.time()

        # æ€»æ˜¾å­˜ (GB):      2.0
        # torch æ˜¾å­˜ (GB):  0.4
        # tensor æ˜¾å­˜ (GB): 0.3
        print_gpu_memory_summary()

        print("spent {}".format(end_time - start_time))


# æ£€æŸ¥ half çš„ç”¨æ³•ï¼Œå…¶å®å°±æ˜¯è½¬åŒ–ä¸º float 16
def check_half():
    float_64 = torch.tensor([3.1415926], dtype=torch.float64)
    float_32 = torch.tensor([3.1415926], dtype=torch.float32)
    float_16 = torch.tensor([3.1415926], dtype=torch.float16)

    # tensor([3.1416], dtype=torch.float64)
    # tensor([3.1406], dtype=torch.float16)
    # tensor([3.1406], dtype=torch.float16)
    print(float_64)
    print(float_64.half())
    print(float_64.half().half())

    # tensor([3.1416])
    # tensor([3.1406], dtype=torch.float16)
    # tensor([3.1406], dtype=torch.float16)
    print(float_32)
    print(float_32.half())
    print(float_32.half().half())

    # tensor([3.1406], dtype=torch.float16)
    # tensor([3.1406], dtype=torch.float16)
    # tensor([3.1406], dtype=torch.float16)
    print(float_16)
    print(float_16.half())
    print(float_16.half().half())


# https://huggingface.co/THUDM/chatglm3-6b
@func_timer(arg=True)
def check_chatglm3():
    from transformers import AutoModel, AutoTokenizer
    # trust_remote_code è¡¨ç¤ºç›¸ä¿¡æœ¬åœ°çš„ä»£ç ï¼Œè€Œä¸æ˜¯è¡¨ç¤ºåŒæ„ä¸‹è½½è¿œç¨‹ä»£ç ï¼Œä¸è¦æ··æ·†
    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=CHATGLM3_6B_model_dir,
                                              trust_remote_code=True)
    # <class 'transformers_modules.chatglm3-6b.tokenization_chatglm.ChatGLMTokenizer'>
    print(type(tokenizer))
    # ['SPECIAL_TOKENS_ATTRIBUTES', 'add_special_tokens', 'add_tokens', 'added_tokens_decoder', 'added_tokens_encoder',
    # 'additional_special_tokens', 'additional_special_tokens_ids', 'all_special_ids', 'all_special_tokens',
    # 'all_special_tokens_extended', 'apply_chat_template', 'as_target_tokenizer', 'batch_decode', 'batch_encode_plus',
    # 'bos_token', 'bos_token_id', 'build_chat_input', 'build_inputs_with_special_tokens', 'build_single_message',
    # 'chat_template', 'clean_up_tokenization', 'clean_up_tokenization_spaces', 'cls_token', 'cls_token_id',
    # 'convert_added_tokens', 'convert_ids_to_tokens', 'convert_tokens_to_ids', 'convert_tokens_to_string',
    # 'create_token_type_ids_from_sequences', 'decode', 'default_chat_template', 'deprecation_warnings',
    # 'encode', 'encode_plus', 'eos_token', 'eos_token_id', 'from_pretrained', 'get_added_vocab', 'get_command',
    # 'get_prefix_tokens', 'get_special_tokens_mask', 'get_vocab', 'init_inputs', 'init_kwargs', 'is_fast',
    # 'mask_token', 'mask_token_id', 'max_len_sentences_pair', 'max_len_single_sentence', 'max_model_input_sizes',
    # 'model_input_names', 'model_max_length', 'name', 'name_or_path', 'num_special_tokens_to_add', 'pad',
    # 'pad_token', 'pad_token_id', 'pad_token_type_id', 'padding_side', 'prepare_for_model', 'prepare_for_tokenization',
    # 'prepare_seq2seq_batch', 'pretrained_init_configuration', 'pretrained_vocab_files_map', 'push_to_hub',
    # 'register_for_auto_class', 'sanitize_special_tokens', 'save_pretrained', 'save_vocabulary', 'sep_token',
    # 'sep_token_id', 'slow_tokenizer_class', 'special_tokens', 'special_tokens_map', 'special_tokens_map_extended',
    # 'split_special_tokens', 'tokenize', 'tokenizer', 'tokens_trie', 'truncate_sequences', 'truncation_side',
    # 'unk_token', 'unk_token_id', 'verbose', 'vocab_file', 'vocab_files_names', 'vocab_size']
    print_dir(tokenizer)

    dictionary = tokenizer.get_vocab()
    # <class 'dict'> 64796 True
    # å­—å…¸
    print(type(dictionary), len(dictionary), "æœˆå…‰" in dictionary)

    # encode å°±æ˜¯ encode_plus çš„ä¸€éƒ¨åˆ†
    # return self.encode_plus()["input_ids"]
    # [64790, 64792, 34211, 51225, 34886, 30930]
    # print(tokenizer.encode('æˆ‘çˆ±æˆ‘è€å©†.'))

    # {'input_ids': [0, 0, 64790, 64792, 34211, 51225, 34886, 30930, 34211, 34886, 54532, 55266, 54678, 30930, 2],
    # 'token_type_ids': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'special_tokens_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    # 'attention_mask': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    # 'position_ids': [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}
    # æ”¯æŒä¼ ä¸€å¥è¯æˆ–è€…ä¸¤å¥è¯ï¼Œå¦‚æ¯å¥è¯çš„å¼€å¤´æœ‰ "_"
    # å¦‚æœè¦æƒ³æ‰¹é‡ç¼–ç ï¼Œè°ƒç”¨ batch_encode_plusï¼Œä¼šå¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œè¡¨ç¤º batch
    sen_code = tokenizer.encode_plus('æˆ‘çˆ±æˆ‘è€å©†.', 'æˆ‘è€å©†æ˜¯é™ˆå¹³.', truncation=True, max_length=15,
                                     padding="max_length", return_token_type_ids=True, return_special_tokens_mask=True)
    print(sen_code)
    # ['', '', '[gMASK]', 'sop', 'â–æˆ‘', 'çˆ±æˆ‘', 'è€å©†', '.', 'â–æˆ‘', 'è€å©†', 'æ˜¯', 'é™ˆ', 'å¹³', '.', '']
    print(tokenizer.convert_ids_to_tokens(sen_code['input_ids']))

    sen_code = tokenizer.encode_plus('ä½ è¯´ä»€ä¹ˆ.', 'è¿™ä¸ªè¯¾ç¨‹å¤ªéš¾å­¦äº†.')
    print(sen_code)
    # ['[gMASK]', 'sop', 'â–ä½ ', 'è¯´ä»€ä¹ˆ', '.', 'â–è¿™ä¸ª', 'è¯¾ç¨‹', 'å¤ªéš¾', 'å­¦äº†', '.', '']
    print(tokenizer.convert_ids_to_tokens(sen_code['input_ids']))

    # é€šè¿‡æŸ¥çœ‹ config.jsonï¼Œtorch_dtype = float16"ï¼Œå› æ­¤è¿™é‡Œç”¨ä¸ç”¨ half éƒ½å¯ä»¥
    model = AutoModel.from_pretrained(CHATGLM3_6B_model_dir, trust_remote_code=True).cuda()
    # <class 'transformers_modules.chatglm3-6b.modeling_chatglm.ChatGLMForConditionalGeneration'>
    print(type(model))
    # ['T_destination', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags',
    # 'add_module', 'apply', 'assisted_decoding', 'base_model', 'base_model_prefix', 'beam_sample', 'beam_search',
    # 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'chat', 'children', 'compile',
    # 'compute_transition_scores', 'config', 'config_class', 'constrained_beam_search', 'contrastive_search', 'cpu',
    # 'create_extended_attention_mask_for_decoder', 'cuda', 'device', 'disable_adapters', 'disable_input_require_grads',
    # 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'enable_adapters', 'enable_input_require_grads',
    # , 'eval', 'extra_repr', 'float', 'floating_point_ops', 'forward', 'framework', 'from_pretrained', 'generate',
    # 'generation_config', 'get_adapter_state_dict', 'get_buffer', 'get_extended_attention_mask', 'get_extra_state',
    # 'get_head_mask', 'get_input_embeddings', 'get_masks', 'get_memory_footprint', 'get_output_embeddings',
    # 'get_parameter', 'get_position_embeddings', 'get_position_ids', 'get_submodule', 'gradient_checkpointing_disable',
    # 'gradient_checkpointing_enable', 'greedy_search', 'group_beam_search', 'half', 'init_weights',
    # 'invert_attention_mask', 'ipu', 'is_gradient_checkpointing', 'is_parallelizable', 'load_adapter',
    # 'load_state_dict', 'main_input_name', 'max_sequence_length', 'model_tags', 'modules', 'name_or_path',
    # 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_parameters', 'parameters',
    # 'post_init', 'prepare_inputs_for_generation', 'process_response', 'prune_heads', 'push_to_hub', 'quantize',
    # 'quantized', 'register_backward_hook', 'register_buffer', 'register_for_auto_class', 'register_forward_hook',
    # 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook',
    # 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook',
    # 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings', 'resize_token_embeddings',
    # 'retrieve_modules_from_names', 'reverse_bettertransformer', 'sample', 'save_pretrained', 'set_adapter',
    # 'set_extra_state', 'set_input_embeddings', 'share_memory', 'state_dict', 'stream_chat', 'stream_generate',
    # 'supports_gradient_checkpointing', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training',
    # 'transformer', 'type', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']
    print_dir(model)

    # model = AutoModel.from_pretrained(CHATGLM3_6B_model_dir, trust_remote_code=True).half().cuda()
    total_parameters = model.num_parameters()
    # æ€»æ˜¾å­˜ (GB):      13.22
    # torch æ˜¾å­˜ (GB):  11.66
    # tensor æ˜¾å­˜ (GB): 11.66
    print_gpu_memory_summary()

    # å‚æ•°é‡ï¼š6243584000ï¼Œå ç”¨æ˜¾å­˜: 11.63 GB
    print(F"å‚æ•°é‡ï¼š{total_parameters}ï¼Œå ç”¨æ˜¾å­˜: {round(total_parameters * 2 / 1024 ** 3, 2)} GB")

    # ================================================================================
    # Layer (type:depth-idx)                                  Param #
    # ================================================================================
    # ChatGLMForConditionalGeneration                         --
    # â”œâ”€ChatGLMModel: 1-1                                     --
    # â”‚    â””â”€Embedding: 2-1                                   --
    # â”‚    â”‚    â””â”€Embedding: 3-1                              266,338,304
    # â”‚    â””â”€RotaryEmbedding: 2-2                             --
    # â”‚    â””â”€GLMTransformer: 2-3                              --
    # â”‚    â”‚    â””â”€ModuleList: 3-2                             5,710,903,296
    # â”‚    â”‚    â””â”€RMSNorm: 3-3                                4,096
    # â”‚    â””â”€Linear: 2-4                                      266,338,304
    # ================================================================================
    # Total params: 6,243,584,000
    # Trainable params: 6,243,584,000
    # Non-trainable params: 0
    # ================================================================================
    # æ³¨æ„ï¼Œéœ€è¦ç»™ input æ‰èƒ½çŸ¥é“æ•´ä¸ªçš„å‚æ•°é‡
    summary(model)

    # ChatGLMForConditionalGeneration(
    #   (transformer): ChatGLMModel(
    #     (embedding): Embedding(
    #       (word_embeddings): Embedding(65024, 4096)
    #     )
    #     (rotary_pos_emb): RotaryEmbedding()
    #     (encoder): GLMTransformer(
    #       (layers): ModuleList(
    #         (0-27): 28 x GLMBlock(
    #           (input_layernorm): RMSNorm()
    #           (self_attention): SelfAttention(
    #             (query_key_value): Linear(in_features=4096, out_features=4608, bias=True)
    #             (core_attention): CoreAttention(
    #               (attention_dropout): Dropout(p=0.0, inplace=False)
    #             )
    #             (dense): Linear(in_features=4096, out_features=4096, bias=False)
    #           )
    #           (post_attention_layernorm): RMSNorm()
    #           (mlp): MLP(
    #             (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)
    #             (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)
    #           )
    #         )
    #       )
    #       (final_layernorm): RMSNorm()
    #     )
    #     (output_layer): Linear(in_features=4096, out_features=65024, bias=False)
    #   )
    # )
    print(model)

    # =========================================================================================================
    # Layer (type:depth-idx)                                  Output Shape              Param #
    # =========================================================================================================
    # ChatGLMForConditionalGeneration                         [512, 16, 2, 128]         --
    # â”œâ”€ChatGLMModel: 1-1                                     [512, 16, 2, 128]         --
    # â”‚    â””â”€Embedding: 2-1                                   [512, 16, 4096]           --
    # â”‚    â”‚    â””â”€Embedding: 3-1                              [16, 512, 4096]           266,338,304
    # â”‚    â””â”€RotaryEmbedding: 2-2                             [8192, 32, 2]             --
    # â”‚    â””â”€GLMTransformer: 2-3                              [512, 16, 4096]           --
    # â”‚    â”‚    â””â”€ModuleList: 3-2                             --                        5,710,903,296
    # â”‚    â”‚    â””â”€RMSNorm: 3-3                                [512, 16, 4096]           4,096
    # â”‚    â””â”€Linear: 2-4                                      [512, 16, 65024]          266,338,304
    # =========================================================================================================
    # Total params: 6,243,584,000
    # Trainable params: 6,243,584,000
    # Non-trainable params: 0
    # Total mult-adds (Units.TERABYTES): 3.06
    # =========================================================================================================
    # Input size (MB): 0.03
    # Forward/backward pass size (MB): 46791.66
    # Params size (MB): 12487.17
    # Estimated Total Size (MB): 59278.86
    # =========================================================================================================
    summary(model, input_size=(16, 512), dtypes=[torch.int])
    model = model.eval()

    # ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
    response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
    print(response)
    # print_history_message_list(history)

    # 1. å°è¯•æ”¾æ¾èº«å¿ƒï¼Œå¦‚æ·±å‘¼å¸ã€å†¥æƒ³æˆ–æ¸©å’Œçš„ç‘œä¼½ã€‚
    # 2. é¿å…åˆºæ¿€æ€§é£Ÿç‰©å’Œé¥®æ–™ï¼Œå¦‚å’–å•¡ã€èŒ¶å’Œå·§å…‹åŠ›ã€‚
    # 3. ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨ã€‚
    # 4. å°è¯•èˆ’é€‚çš„ç¯å¢ƒï¼Œå¦‚è°ƒæš—ç¯å…‰ã€ä½¿ç”¨ç™½å™ªéŸ³æˆ–èˆ’é€‚çš„åºŠå«ã€‚
    # 5. é¿å…åœ¨æ™šä¸Šè¿‡åº¦ä½¿ç”¨ç”µå­è®¾å¤‡ï¼Œå¦‚æ‰‹æœºã€å¹³æ¿ç”µè„‘å’Œç”µè§†ã€‚
    # 6. ä¿æŒé€‚åº¦çš„è¿åŠ¨ï¼Œå¦‚æ•£æ­¥ã€ç‘œä¼½æˆ–ä¼¸å±•è¿åŠ¨ã€‚
    # 7. å¦‚æœéœ€è¦ï¼Œå¯ä»¥è€ƒè™‘é‡‡ç”¨æ”¾æ¾æŠ€å·§ï¼Œå¦‚æ¸è¿›æ€§è‚Œè‚‰æ¾å¼›æˆ–å‘¼å¸ç»ƒä¹ ã€‚
    # 8. ç¡å‰é€‚å½“é™åˆ¶ä½¿ç”¨å…´å¥‹å‰‚ï¼Œå¦‚å°¼å¤ä¸å’Œé…’ç²¾ã€‚
    # 9. ç¡å‰å°è¯•å†¥æƒ³æˆ–æ·±åº¦æ”¾æ¾ç»ƒä¹ ã€‚
    # 10. å¦‚æœ‰å¿…è¦ï¼Œå¯å’¨è¯¢åŒ»ç”Ÿæˆ–ä¸“ä¸šå¿ƒç†å¥åº·ä¸“å®¶ã€‚
    response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠï¼Œå›å¤å­—æ•°ä¸è¦è¶…è¿‡ 100 ä¸ª", history=history)
    print(response)
    # print_history_message_list(history)

    # 1. å°è¯•è°ƒæ•´å’–å•¡å› æ‘„å…¥é‡ï¼Œæ§åˆ¶åœ¨ä¸€æ—¥ limit å†…ã€‚
    # 2. å°è¯•å…¶ä»–éå’–å•¡å› çš„æç¥é¥®æ–™ï¼Œå¦‚èŒ¶ã€æœæ±æˆ–è‹æ‰“æ°´ã€‚
    # 3. è€ƒè™‘é‡‡ç”¨æ”¾æ¾æŠ€å·§ï¼Œå¦‚å†¥æƒ³æˆ–æ·±åº¦æ”¾æ¾ç»ƒä¹ ã€‚
    # 4. å¢åŠ ç™½å¤©ä¼‘æ¯æ—¶é—´ï¼Œå¦‚å°æ†©æˆ–åˆç¡ã€‚
    # 5. è°ƒæ•´é¥®é£Ÿç»“æ„ï¼Œå¢åŠ æ˜“æ¶ˆåŒ–çš„é£Ÿç‰©ï¼Œå¦‚åšæœã€å…¨éº¦é¢åŒ…æˆ–é¦™è•‰ã€‚
    # 6. å°è¯•è¿›è¡Œæœ‰æ°§è¿åŠ¨ï¼Œå¦‚è·‘æ­¥æˆ–æ¸¸æ³³ã€‚
    # 7. ä¿æŒè‰¯å¥½çš„ç¡çœ æ—¶é—´è¡¨ï¼Œå°½é‡åœ¨åŒä¸€æ—¶é—´å…¥ç¡å’Œèµ·åºŠã€‚
    # 8. é¿å…åœ¨ç¡å‰è¿‡åº¦ä½¿ç”¨ç”µå­è®¾å¤‡ï¼Œå¦‚æ‰‹æœºã€å¹³æ¿ç”µè„‘å’Œç”µè§†ã€‚
    # 9. ç¡å‰é€‚å½“é™åˆ¶å’–å•¡å› æ‘„å…¥ï¼Œå¦‚å‡å°‘å’–å•¡æˆ–èŒ¶æ‘„å…¥é‡ã€‚
    # 10. å¦‚æœ‰å¿…è¦ï¼Œå¯å’¨è¯¢åŒ»ç”Ÿæˆ–ä¸“ä¸šå¿ƒç†å¥åº·ä¸“å®¶ã€‚
    response, history = model.chat(tokenizer, "ä½†æˆ‘å·¥ä½œçš„åŸå› å¿…é¡»å–å’–å•¡ï¼Œå›å¤å­—æ•°ä¸è¦è¶…è¿‡ 100 ä¸ª", history=history)
    print(response)
    # print_history_message_list(history)

    # æˆ‘æ˜ç™½æ‚¨çš„å·¥ä½œåŸå› éœ€è¦å–å’–å•¡æ¥ä¿æŒæ¸…é†’å’Œæé«˜å·¥ä½œæ•ˆç‡ã€‚å’–å•¡å› æ˜¯ä¸€ç§å…´å¥‹å‰‚ï¼Œå¯ä»¥å¢åŠ è­¦è§‰æ€§å’Œæ³¨æ„åŠ›ï¼Œå¸®åŠ©æ‚¨æ›´å¥½åœ°åº”å¯¹æ—¥å¸¸ä»»åŠ¡ã€‚å½“ç„¶ï¼Œé€‚é‡é¥®ç”¨å’–å•¡å¯¹å¤§å¤šæ•°äººæ¥è¯´æ˜¯å®‰å…¨çš„ï¼Œä½†è¯·æ³¨æ„ä¸è¦è¿‡é‡æ‘„å…¥å’–å•¡å› ï¼Œä»¥å…å‡ºç°ä¸è‰¯ååº”ã€‚
    # å†å²å¯¹è¯éœ€è¦é€šè¿‡ä¼ å…¥ history æ¥å¼•å…¥ï¼Œå¦åˆ™æ¨¡å‹è®°ä¸ä½ä¸Šä¸‹æ–‡
    response, history = model.chat(tokenizer, "ä½†æˆ‘å·¥ä½œçš„åŸå› å¿…é¡»å–å’–å•¡ï¼Œå›å¤å­—æ•°ä¸è¦è¶…è¿‡ 100 ä¸ª", history=[])
    print(response)
    # print_history_message_list(history)


# https://huggingface.co/BAAI/bge-large-zh-v1.5
@func_timer(arg=True)
def check_bge_zh():
    from transformers import AutoModel, AutoTokenizer
    # trust_remote_code è¡¨ç¤ºç›¸ä¿¡æœ¬åœ°çš„ä»£ç ï¼Œè€Œä¸æ˜¯è¡¨ç¤ºåŒæ„ä¸‹è½½è¿œç¨‹ä»£ç ï¼Œä¸è¦æ··æ·†
    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=BGE_LARGE_CN_model_dir,
                                              trust_remote_code=True)
    # <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>
    print(type(tokenizer))
    # ['SPECIAL_TOKENS_ATTRIBUTES', 'add_special_tokens', 'add_tokens', 'added_tokens_decoder', 'added_tokens_encoder',
    # 'additional_special_tokens', 'additional_special_tokens_ids', 'all_special_ids', 'all_special_tokens',
    # 'all_special_tokens_extended', 'apply_chat_template', 'as_target_tokenizer', 'backend_tokenizer',
    # 'batch_decode', 'batch_encode_plus', 'bos_token', 'bos_token_id', 'build_inputs_with_special_tokens',
    # 'can_save_slow_tokenizer', 'chat_template', 'clean_up_tokenization', 'clean_up_tokenization_spaces',
    # 'cls_token', 'cls_token_id', 'convert_added_tokens', 'convert_ids_to_tokens', 'convert_tokens_to_ids',
    # 'convert_tokens_to_string', 'create_token_type_ids_from_sequences', 'decode', 'decoder', 'default_chat_template',
    # 'deprecation_warnings', 'do_lower_case', 'encode', 'encode_plus', 'eos_token', 'eos_token_id', 'from_pretrained',
    # 'get_added_vocab', 'get_special_tokens_mask', 'get_vocab', 'init_inputs', 'init_kwargs', 'is_fast', 'mask_token',
    # 'mask_token_id', 'max_len_sentences_pair', 'max_len_single_sentence', 'max_model_input_sizes',
    # 'model_input_names', 'model_max_length', 'name_or_path', 'num_special_tokens_to_add', 'pad', 'pad_token',
    # 'pad_token_id', 'pad_token_type_id', 'padding_side', 'prepare_for_model', 'prepare_seq2seq_batch',
    # 'pretrained_init_configuration', 'pretrained_vocab_files_map', 'push_to_hub', 'register_for_auto_class',
    # 'sanitize_special_tokens', 'save_pretrained', 'save_vocabulary', 'sep_token', 'sep_token_id',
    # 'set_truncation_and_padding', 'slow_tokenizer_class', 'special_tokens_map', 'special_tokens_map_extended',
    # 'split_special_tokens', 'tokenize', 'train_new_from_iterator', 'truncate_sequences', 'truncation_side',
    # 'unk_token', 'unk_token_id', 'verbose', 'vocab', 'vocab_files_names', 'vocab_size']
    print_dir(tokenizer)

    dictionary = tokenizer.get_vocab()
    # <class 'dict'> 21128 False True True
    # å­—å…¸
    print(type(dictionary), len(dictionary), "æœˆå…‰" in dictionary, "æœˆ" in dictionary, "å…‰" in dictionary)
    # 1000000000000000019884624838653
    # 1000000000000000019884624838654
    # {'google-bert/bert-base-uncased': 512, 'google-bert/bert-large-uncased': 512, 'google-bert/bert-base-cased': 512,
    # 'google-bert/bert-large-cased': 512, 'google-bert/bert-base-multilingual-uncased': 512,
    # 'google-bert/bert-base-multilingual-cased': 512, 'google-bert/bert-base-chinese': 512,
    # 'google-bert/bert-base-german-cased': 512, 'google-bert/bert-large-uncased-whole-word-masking': 512,
    # 'google-bert/bert-large-cased-whole-word-masking': 512,
    # 'google-bert/bert-large-uncased-whole-word-masking-finetuned-squad': 512,
    # 'google-bert/bert-large-cased-whole-word-masking-finetuned-squad': 512,
    # 'google-bert/bert-base-cased-finetuned-mrpc': 512,
    # 'google-bert/bert-base-german-dbmdz-cased': 512,
    # 'google-bert/bert-base-german-dbmdz-uncased': 512, 'TurkuNLP/bert-base-finnish-cased-v1': 512,
    # 'TurkuNLP/bert-base-finnish-uncased-v1': 512, 'wietsedv/bert-base-dutch-cased': 512}
    # 1000000000000000019884624838656
    print(tokenizer.max_len_sentences_pair, tokenizer.max_len_single_sentence, tokenizer.max_model_input_sizes,
          tokenizer.model_max_length)

    # encode å°±æ˜¯ encode_plus çš„ä¸€éƒ¨åˆ†
    # return self.encode_plus()["input_ids"]
    # [64790, 64792, 34211, 51225, 34886, 30930]
    # print(tokenizer.encode('æˆ‘çˆ±æˆ‘è€å©†.'))

    # {'input_ids': [101, 2769, 4263, 2769, 5439, 2038, 119, 102, 2769, 5439, 2038, 3221, 7357, 2398, 102],
    # 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],
    # 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    # 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], 'length': [15]}
    # æ”¯æŒä¼ ä¸€å¥è¯æˆ–è€…ä¸¤å¥è¯ï¼Œå¦‚æ¯å¥è¯çš„å¼€å¤´æœ‰ "_"
    # å¦‚æœè¦æƒ³æ‰¹é‡ç¼–ç ï¼Œè°ƒç”¨ batch_encode_plusï¼Œä¼šå¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œè¡¨ç¤º batch
    sen_code = tokenizer.encode_plus('æˆ‘çˆ±æˆ‘è€å©†.', 'æˆ‘è€å©†æ˜¯é™ˆå¹³.', truncation=True, max_length=15,
                                     padding="max_length", return_token_type_ids=True, return_special_tokens_mask=True,
                                     return_length=True)
    print(sen_code)
    # ['[CLS]', 'æˆ‘', 'çˆ±', 'æˆ‘', 'è€', 'å©†', '.', '[SEP]', 'æˆ‘', 'è€', 'å©†', 'æ˜¯', 'é™ˆ', 'å¹³', '[SEP]']
    print(tokenizer.convert_ids_to_tokens(sen_code['input_ids']))

    sen_code = tokenizer.encode_plus('ä½ è¯´ä»€ä¹ˆ.', 'è¿™ä¸ªè¯¾ç¨‹å¤ªéš¾å­¦äº†.')
    print(sen_code)
    # ['[CLS]', 'ä½ ', 'è¯´', 'ä»€', 'ä¹ˆ', '.', '[SEP]', 'è¿™', 'ä¸ª', 'è¯¾', 'ç¨‹', 'å¤ª', 'éš¾', 'å­¦', 'äº†', '.', '[SEP]']
    print(tokenizer.convert_ids_to_tokens(sen_code['input_ids']))

    # é€šè¿‡æŸ¥çœ‹ config.jsonï¼Œtorch_dtype = float32"
    model = AutoModel.from_pretrained(BGE_LARGE_CN_model_dir, trust_remote_code=True).cuda()
    # model = AutoModel.from_pretrained(BGE_LARGE_CN_model_dir, trust_remote_code=True).half().cuda()
    # <class 'transformers.models.bert.modeling_bert.BertModel'>
    print(type(model))
    # cuda:0
    print(model.device)
    # ['T_destination', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags',
    # 'add_module', 'apply', 'assisted_decoding', 'base_model', 'base_model_prefix', 'beam_sample', 'beam_search',
    # 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'children', 'compile', 'compute_transition_scores',
    # 'config', 'config_class', 'constrained_beam_search', 'contrastive_search', 'cpu',
    # 'create_extended_attention_mask_for_decoder', 'cuda', 'device', 'disable_adapters',
    # 'disable_input_require_grads', 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'embeddings',
    # 'enable_adapters', 'enable_input_require_grads', 'encoder', 'estimate_tokens', 'eval', 'extra_repr', 'float',
    # 'floating_point_ops', 'forward', 'framework', 'from_pretrained', 'generate', 'generation_config',
    # 'get_adapter_state_dict', 'get_buffer', 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask',
    # 'get_input_embeddings', 'get_memory_footprint', 'get_output_embeddings', 'get_parameter',
    # 'get_position_embeddings', 'get_submodule', 'gradient_checkpointing_disable', 'gradient_checkpointing_enable',
    # 'greedy_search', 'group_beam_search', 'half', 'init_weights', 'invert_attention_mask', 'ipu',
    # 'is_gradient_checkpointing', 'is_parallelizable', 'load_adapter', 'load_state_dict', 'load_tf_weights',
    # 'main_input_name', 'model_tags', 'modules', 'name_or_path', 'named_buffers', 'named_children', 'named_modules',
    # 'named_parameters', 'num_parameters', 'parameters', 'pooler', 'post_init', 'prepare_inputs_for_generation',
    # 'prune_heads', 'push_to_hub', 'register_backward_hook', 'register_buffer', 'register_for_auto_class',
    # 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook',
    # 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter',
    # 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings',
    # 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'sample',
    # 'save_pretrained', 'set_adapter', 'set_extra_state', 'set_input_embeddings', 'share_memory', 'state_dict',
    # 'supports_gradient_checkpointing', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training',
    # 'type', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']
    print_dir(model)

    total_parameters = model.num_parameters()
    # half() ä¹‹å‰
    # æ€»æ˜¾å­˜ (GB):      2.62
    # torch æ˜¾å­˜ (GB):  1.22
    # tensor æ˜¾å­˜ (GB): 1.21
    # half() ä¹‹åï¼Œä» float32 -> float16ï¼Œå°‘äº†ä¸€åŠ
    # æ€»æ˜¾å­˜ (GB):      2.0
    # torch æ˜¾å­˜ (GB):  0.61
    # tensor æ˜¾å­˜ (GB): 0.61
    print_gpu_memory_summary()

    # å‚æ•°é‡ï¼š325522432ï¼Œå ç”¨æ˜¾å­˜: 1.21 GB
    print(F"å‚æ•°é‡ï¼š{total_parameters}ï¼Œå ç”¨æ˜¾å­˜: {round(total_parameters * 2 / 1024 ** 3, 2)} GB")

    # ===========================================================================
    # Layer (type:depth-idx)                             Param #
    # ===========================================================================
    # BertModel                                          --
    # â”œâ”€BertEmbeddings: 1-1                              --
    # â”‚    â””â”€Embedding: 2-1                              21,635,072
    # â”‚    â””â”€Embedding: 2-2                              524,288
    # â”‚    â””â”€Embedding: 2-3                              2,048
    # â”‚    â””â”€LayerNorm: 2-4                              2,048
    # â”‚    â””â”€Dropout: 2-5                                --
    # â”œâ”€BertEncoder: 1-2                                 --
    # â”‚    â””â”€ModuleList: 2-6                             --
    # â”‚    â”‚    â””â”€BertLayer: 3-1                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-2                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-3                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-4                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-5                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-6                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-7                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-8                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-9                         12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-10                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-11                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-12                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-13                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-14                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-15                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-16                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-17                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-18                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-19                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-20                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-21                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-22                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-23                        12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-24                        12,596,224
    # â”œâ”€BertPooler: 1-3                                  --
    # â”‚    â””â”€Linear: 2-7                                 1,049,600
    # â”‚    â””â”€Tanh: 2-8                                   --
    # ===========================================================================
    # Total params: 325,522,432
    # Trainable params: 325,522,432
    # Non-trainable params: 0
    # ===========================================================================
    # æ³¨æ„ï¼Œéœ€è¦ç»™ input æ‰èƒ½çŸ¥é“æ•´ä¸ªçš„å‚æ•°é‡
    summary(model)

    # BertModel(
    #   (embeddings): BertEmbeddings(
    #     (word_embeddings): Embedding(21128, 1024, padding_idx=0)
    #     (position_embeddings): Embedding(512, 1024)
    #     (token_type_embeddings): Embedding(2, 1024)
    #     (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
    #     (dropout): Dropout(p=0.1, inplace=False)
    #   )
    #   (encoder): BertEncoder(
    #     (layer): ModuleList(
    #       (0-23): 24 x BertLayer(
    #         (attention): BertAttention(
    #           (self): BertSelfAttention(
    #             (query): Linear(in_features=1024, out_features=1024, bias=True)
    #             (key): Linear(in_features=1024, out_features=1024, bias=True)
    #             (value): Linear(in_features=1024, out_features=1024, bias=True)
    #             (dropout): Dropout(p=0.1, inplace=False)
    #           )
    #           (output): BertSelfOutput(
    #             (dense): Linear(in_features=1024, out_features=1024, bias=True)
    #             (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
    #             (dropout): Dropout(p=0.1, inplace=False)
    #           )
    #         )
    #         (intermediate): BertIntermediate(
    #           (dense): Linear(in_features=1024, out_features=4096, bias=True)
    #           (intermediate_act_fn): GELUActivation()
    #         )
    #         (output): BertOutput(
    #           (dense): Linear(in_features=4096, out_features=1024, bias=True)
    #           (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
    #           (dropout): Dropout(p=0.1, inplace=False)
    #         )
    #       )
    #     )
    #   )
    #   (pooler): BertPooler(
    #     (dense): Linear(in_features=1024, out_features=1024, bias=True)
    #     (activation): Tanh()
    #   )
    # )
    print(model)

    # ====================================================================================================
    # Layer (type:depth-idx)                             Output Shape              Param #
    # ====================================================================================================
    # BertModel                                          [16, 1024]                --
    # â”œâ”€BertEmbeddings: 1-1                              [16, 512, 1024]           --
    # â”‚    â””â”€Embedding: 2-1                              [16, 512, 1024]           21,635,072
    # â”‚    â””â”€Embedding: 2-2                              [16, 512, 1024]           2,048
    # â”‚    â””â”€Embedding: 2-3                              [1, 512, 1024]            524,288
    # â”‚    â””â”€LayerNorm: 2-4                              [16, 512, 1024]           2,048
    # â”‚    â””â”€Dropout: 2-5                                [16, 512, 1024]           --
    # â”œâ”€BertEncoder: 1-2                                 [16, 512, 1024]           --
    # â”‚    â””â”€ModuleList: 2-6                             --                        --
    # â”‚    â”‚    â””â”€BertLayer: 3-1                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-2                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-3                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-4                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-5                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-6                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-7                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-8                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-9                         [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-10                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-11                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-12                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-13                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-14                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-15                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-16                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-17                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-18                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-19                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-20                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-21                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-22                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-23                        [16, 512, 1024]           12,596,224
    # â”‚    â”‚    â””â”€BertLayer: 3-24                        [16, 512, 1024]           12,596,224
    # â”œâ”€BertPooler: 1-3                                  [16, 1024]                --
    # â”‚    â””â”€Linear: 2-7                                 [16, 1024]                1,049,600
    # â”‚    â””â”€Tanh: 2-8                                   [16, 1024]                --
    # ====================================================================================================
    # Total params: 325,522,432
    # Trainable params: 325,522,432
    # Non-trainable params: 0
    # Total mult-adds (Units.GIGABYTES): 5.20
    # ====================================================================================================
    # Input size (MB): 0.03
    # Forward/backward pass size (MB): 17922.39
    # Params size (MB): 1302.09
    # Estimated Total Size (MB): 19224.51
    # ====================================================================================================
    summary(model, input_size=(16, 512), dtypes=[torch.int])
    model = model.eval()

    # (0, 1) = 0.8791518807411194
    # (0, 2) = 0.6639465689659119
    # (1, 2) = 0.7661015391349792
    # (0, 1) > (1, 2) > (0, 2)ï¼Œæ¯”è¾ƒç¬¦åˆç›´è§‰
    sentences = ["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2", "é”™ä¾‹æ•°æ®-2"]
    # ç­‰ä»·äº batch_encode_plusï¼Œè¿”å›çš„æ˜¯äºŒç»´å‘é‡ï¼Œè€Œä¸æ˜¯å°†ä¸¤ä¸ªå¥å­æ”¾åœ¨ä¸€èµ·ï¼Œå¯ä»¥æ”¯æŒå¤šä¸ªå¥å­
    # Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length.
    # Default to no truncation. å¦‚æœè®¾å®š truncation=Trueï¼Œéœ€è¦æŒ‡å®šæœ€å¤§é•¿åº¦
    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=500, return_tensors='pt')
    # å¦‚æœ model åœ¨æ˜¾å¡ä¸­ï¼Œé‚£ä¹ˆå‚æ•°ä¹Ÿè¦éƒ½åœ¨æ˜¾å¡ä¸­
    change_dict_value_to_gpu(encoded_input)
    # {'input_ids': tensor([[ 101, 3416,  891, 3144, 2945,  118,  122,  102],
    #         [ 101, 3416,  891, 3144, 2945,  118,  123,  102],
    #         [ 101, 7231,  891, 3144, 2945,  118,  123,  102]], device='cuda:0'),
    #         'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],
    #         [0, 0, 0, 0, 0, 0, 0, 0],
    #         [0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],
    #         [1, 1, 1, 1, 1, 1, 1, 1],
    #         [1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}
    print(encoded_input)

    with torch.no_grad():
        model_output = model(**encoded_input)
        # Perform pooling. In this case, cls pooling.
        # cls-poolingï¼šç›´æ¥å– [CLS] çš„ embedding
        # mean-poolingï¼šå–æ¯ä¸ª Token çš„å¹³å‡ embedding
        # max-poolingï¼šå¯¹å¾—åˆ°çš„æ¯ä¸ª Embedding å– max
        sentence_embeddings = model_output[0][:, 0]
    # normalize embeddings
    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)
    # [3, 1024]
    # print(sentence_embeddings.shape)
    print("Sentence embeddings:", sentence_embeddings)
    # å› ä¸ºæ˜¯ normalize ä¹‹åï¼Œè‡ªä¹˜å€¼è‚¯å®šæ˜¯ 1
    for i in range(sentence_embeddings.shape[0]):
        for j in range(i, sentence_embeddings.shape[0]):
            print(F"{i} @ {j} = {sentence_embeddings[i] @ sentence_embeddings[j]}")


# https://huggingface.co/BAAI/bge-reranker-large
# ä¸ check_bge_zh ä¸åŒï¼Œreranker æ¨¡å‹ç›´æ¥æ‹¿ä¸¤ä¸ªæ ·æœ¬ä½œä¸ºè¾“å…¥ï¼Œç„¶åè¾“å…¥å®ƒä»¬çš„ç›¸ä¼¼åº¦ï¼Œscore è¶Šå¤§è¡¨ç¤ºç›¸ä¼¼åº¦è¶Šé«˜
# ä½† score çš„èŒƒå›´å¹¶ä¸æ˜¯åƒç›¸ä¼¼åº¦é‚£æ · âˆˆ [0, 1]ï¼Œå³æ²¡æœ‰å›ºå®šèŒƒå›´
@func_timer(arg=True)
def check_bge_reranker():
    from transformers import AutoModelForSequenceClassification, AutoTokenizer
    # trust_remote_code è¡¨ç¤ºç›¸ä¿¡æœ¬åœ°çš„ä»£ç ï¼Œè€Œä¸æ˜¯è¡¨ç¤ºåŒæ„ä¸‹è½½è¿œç¨‹ä»£ç ï¼Œä¸è¦æ··æ·†
    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=BGE_RERANKER_LARGE_model_dir,
                                              trust_remote_code=True)
    # <class 'transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast'>
    print(type(tokenizer))
    # ['SPECIAL_TOKENS_ATTRIBUTES', 'add_special_tokens', 'add_tokens', 'added_tokens_decoder', 'added_tokens_encoder',
    # 'additional_special_tokens', 'additional_special_tokens_ids', 'all_special_ids', 'all_special_tokens',
    # 'all_special_tokens_extended', 'apply_chat_template', 'as_target_tokenizer', 'backend_tokenizer', 'batch_decode',
    # 'batch_encode_plus', 'bos_token', 'bos_token_id', 'build_inputs_with_special_tokens', 'can_save_slow_tokenizer',
    # 'chat_template', 'clean_up_tokenization', 'clean_up_tokenization_spaces', 'cls_token', 'cls_token_id',
    # 'convert_added_tokens', 'convert_ids_to_tokens', 'convert_tokens_to_ids', 'convert_tokens_to_string',
    # 'create_token_type_ids_from_sequences', 'decode', 'decoder', 'default_chat_template', 'deprecation_warnings',
    # 'encode', 'encode_plus', 'eos_token', 'eos_token_id', 'from_pretrained', 'get_added_vocab',
    # 'get_special_tokens_mask', 'get_vocab', 'init_inputs', 'init_kwargs', 'is_fast', 'mask_token', 'mask_token_id',
    # 'max_len_sentences_pair', 'max_len_single_sentence', 'max_model_input_sizes', 'model_input_names',
    # 'model_max_length', 'name_or_path', 'num_special_tokens_to_add', 'pad', 'pad_token', 'pad_token_id',
    # 'pad_token_type_id', 'padding_side', 'prepare_for_model', 'prepare_seq2seq_batch',
    # 'pretrained_init_configuration', 'pretrained_vocab_files_map', 'push_to_hub', 'register_for_auto_class',
    # 'sanitize_special_tokens', 'save_pretrained', 'save_vocabulary', 'sep_token', 'sep_token_id',
    # 'set_truncation_and_padding', 'slow_tokenizer_class', 'special_tokens_map', 'special_tokens_map_extended',
    # 'split_special_tokens', 'tokenize', 'train_new_from_iterator', 'truncate_sequences', 'truncation_side',
    # 'unk_token', 'unk_token_id', 'verbose', 'vocab', 'vocab_file', 'vocab_files_names', 'vocab_size']
    print_dir(tokenizer)

    dictionary = tokenizer.get_vocab()
    # <class 'dict'> 250002 False True True
    # å­—å…¸
    print(type(dictionary), len(dictionary), "æœˆå…‰" in dictionary, "æœˆ" in dictionary, "å…‰" in dictionary)
    # 508
    # 510
    # {'FacebookAI/xlm-roberta-base': 512, 'FacebookAI/xlm-roberta-large': 512,
    # 'FacebookAI/xlm-roberta-large-finetuned-conll02-dutch': 512,
    # 'FacebookAI/xlm-roberta-large-finetuned-conll02-spanish': 512,
    # 'FacebookAI/xlm-roberta-large-finetuned-conll03-english': 512,
    # 'FacebookAI/xlm-roberta-large-finetuned-conll03-german': 512}
    # 512
    print(tokenizer.max_len_sentences_pair, tokenizer.max_len_single_sentence, tokenizer.max_model_input_sizes,
          tokenizer.model_max_length)

    # encode å°±æ˜¯ encode_plus çš„ä¸€éƒ¨åˆ†
    # return self.encode_plus()["input_ids"]
    # [64790, 64792, 34211, 51225, 34886, 30930]
    # print(tokenizer.encode('æˆ‘çˆ±æˆ‘è€å©†.'))

    # {'input_ids': [0, 13129, 7558, 631, 79299, 5, 2, 2, 13129, 79299, 354, 16426, 5511, 5, 2],
    # 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    # 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    # 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1], 'length': [15]}
    # æ”¯æŒä¼ ä¸€å¥è¯æˆ–è€…ä¸¤å¥è¯ï¼Œå¦‚æ¯å¥è¯çš„å¼€å¤´æœ‰ "_"
    # å¦‚æœè¦æƒ³æ‰¹é‡ç¼–ç ï¼Œè°ƒç”¨ batch_encode_plusï¼Œä¼šå¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œè¡¨ç¤º batch
    sen_code = tokenizer.encode_plus('æˆ‘çˆ±æˆ‘è€å©†.', 'æˆ‘è€å©†æ˜¯é™ˆå¹³.', truncation=True, max_length=15,
                                     padding="max_length", return_token_type_ids=True, return_special_tokens_mask=True,
                                     return_length=True)
    print(sen_code)
    # ['<s>', 'â–æˆ‘', 'çˆ±', 'æˆ‘', 'è€å©†', '.', '</s>', '</s>', 'â–æˆ‘', 'è€å©†', 'æ˜¯', 'é™ˆ', 'å¹³', '.', '</s>']
    print(tokenizer.convert_ids_to_tokens(sen_code['input_ids']))

    sen_code = tokenizer.encode_plus('ä½ è¯´ä»€ä¹ˆ.', 'è¿™ä¸ªè¯¾ç¨‹å¤ªéš¾å­¦äº†.')
    print(sen_code)
    # ['<s>', 'â–ä½ ', 'è¯´ä»€ä¹ˆ', '.', '</s>', '</s>', 'â–', 'è¿™ä¸ª', 'è¯¾ç¨‹', 'å¤ª', 'éš¾', 'å­¦', 'äº†', '.', '</s>']
    print(tokenizer.convert_ids_to_tokens(sen_code['input_ids']))

    # é€šè¿‡æŸ¥çœ‹ config.jsonï¼Œtorch_dtype = float32"
    model = (AutoModelForSequenceClassification.from_pretrained(BGE_RERANKER_LARGE_model_dir, trust_remote_code=True)
             .cuda())
    # model = AutoModelForSequenceClassification.from_pretrained(BGE_RERANKER_LARGE_model_dir, trust_remote_code=True)
    # <class 'transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForSequenceClassification'>
    print(type(model))
    # cuda:0
    print(model.device)
    # ['T_destination', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags',
    # 'add_module', 'apply', 'assisted_decoding', 'base_model', 'base_model_prefix', 'beam_sample', 'beam_search',
    # 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'children', 'classifier', 'compile',
    # 'compute_transition_scores', 'config', 'config_class', 'constrained_beam_search', 'contrastive_search', 'cpu',
    # 'create_extended_attention_mask_for_decoder', 'cuda', 'device', 'disable_adapters', 'disable_input_require_grads',
    # 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'enable_adapters', 'enable_input_require_grads',
    # 'estimate_tokens', 'eval', 'extra_repr', 'float', 'floating_point_ops', 'forward', 'framework',
    # 'from_pretrained', 'generate', 'generation_config', 'get_adapter_state_dict', 'get_buffer',
    # 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask', 'get_input_embeddings', 'get_memory_footprint',
    # 'get_output_embeddings', 'get_parameter', 'get_position_embeddings', 'get_submodule',
    # 'gradient_checkpointing_disable', 'gradient_checkpointing_enable', 'greedy_search', 'group_beam_search', 'half',
    # 'init_weights', 'invert_attention_mask', 'ipu', 'is_gradient_checkpointing', 'is_parallelizable', 'load_adapter',
    # 'load_state_dict', 'main_input_name', 'model_tags', 'modules', 'name_or_path', 'named_buffers', 'named_children',
    # 'named_modules', 'named_parameters', 'num_labels', 'num_parameters', 'parameters', 'post_init',
    # 'prepare_inputs_for_generation', 'prune_heads', 'push_to_hub', 'register_backward_hook', 'register_buffer',
    # 'register_for_auto_class', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook',
    # 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter',
    # 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings',
    # 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'roberta', 'sample',
    # 'save_pretrained', 'set_adapter', 'set_extra_state', 'set_input_embeddings', 'share_memory', 'state_dict',
    # 'supports_gradient_checkpointing', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training',
    # 'type', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']
    print_dir(model)

    total_parameters = model.num_parameters()
    # æ€»æ˜¾å­˜ (GB):      5.16
    # torch æ˜¾å­˜ (GB):  3.31
    # tensor æ˜¾å­˜ (GB): 3.3
    print_gpu_memory_summary()

    # å‚æ•°é‡ï¼š559891457ï¼Œå ç”¨æ˜¾å­˜: 2.09 GB
    print(F"å‚æ•°é‡ï¼š{total_parameters}ï¼Œå ç”¨æ˜¾å­˜: {round(total_parameters * 4 / 1024 ** 3, 2)} GB")

    # ==========================================================================================
    # Layer (type:depth-idx)                                            Param #
    # ==========================================================================================
    # XLMRobertaForSequenceClassification                               --
    # â”œâ”€XLMRobertaModel: 1-1                                            --
    # â”‚    â””â”€XLMRobertaEmbeddings: 2-1                                  --
    # â”‚    â”‚    â””â”€Embedding: 3-1                                        256,002,048
    # â”‚    â”‚    â””â”€Embedding: 3-2                                        526,336
    # â”‚    â”‚    â””â”€Embedding: 3-3                                        1,024
    # â”‚    â”‚    â””â”€LayerNorm: 3-4                                        2,048
    # â”‚    â”‚    â””â”€Dropout: 3-5                                          --
    # â”‚    â””â”€XLMRobertaEncoder: 2-2                                     --
    # â”‚    â”‚    â””â”€ModuleList: 3-6                                       302,309,376
    # â”œâ”€XLMRobertaClassificationHead: 1-2                               --
    # â”‚    â””â”€Linear: 2-3                                                1,049,600
    # â”‚    â””â”€Dropout: 2-4                                               --
    # â”‚    â””â”€Linear: 2-5                                                1,025
    # ==========================================================================================
    # Total params: 559,891,457
    # Trainable params: 559,891,457
    # Non-trainable params: 0
    # ==========================================================================================
    # æ³¨æ„ï¼Œéœ€è¦ç»™ input æ‰èƒ½çŸ¥é“æ•´ä¸ªçš„å‚æ•°é‡
    summary(model)

    # XLMRobertaForSequenceClassification(
    #   (roberta): XLMRobertaModel(
    #     (embeddings): XLMRobertaEmbeddings(
    #       (word_embeddings): Embedding(250002, 1024, padding_idx=1)
    #       (position_embeddings): Embedding(514, 1024, padding_idx=1)
    #       (token_type_embeddings): Embedding(1, 1024)
    #       (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    #       (dropout): Dropout(p=0.1, inplace=False)
    #     )
    #     (encoder): XLMRobertaEncoder(
    #       (layer): ModuleList(
    #         (0-23): 24 x XLMRobertaLayer(
    #           (attention): XLMRobertaAttention(
    #             (self): XLMRobertaSelfAttention(
    #               (query): Linear(in_features=1024, out_features=1024, bias=True)
    #               (key): Linear(in_features=1024, out_features=1024, bias=True)
    #               (value): Linear(in_features=1024, out_features=1024, bias=True)
    #               (dropout): Dropout(p=0.1, inplace=False)
    #             )
    #             (output): XLMRobertaSelfOutput(
    #               (dense): Linear(in_features=1024, out_features=1024, bias=True)
    #               (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    #               (dropout): Dropout(p=0.1, inplace=False)
    #             )
    #           )
    #           (intermediate): XLMRobertaIntermediate(
    #             (dense): Linear(in_features=1024, out_features=4096, bias=True)
    #             (intermediate_act_fn): GELUActivation()
    #           )
    #           (output): XLMRobertaOutput(
    #             (dense): Linear(in_features=4096, out_features=1024, bias=True)
    #             (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    #             (dropout): Dropout(p=0.1, inplace=False)
    #           )
    #         )
    #       )
    #     )
    #   )
    #   (classifier): XLMRobertaClassificationHead(
    #     (dense): Linear(in_features=1024, out_features=1024, bias=True)
    #     (dropout): Dropout(p=0.1, inplace=False)
    #     (out_proj): Linear(in_features=1024, out_features=1, bias=True)
    #   )
    # )
    print(model)

    # ===================================================================================================================
    # Layer (type:depth-idx)                                            Output Shape              Param #
    # ===================================================================================================================
    # XLMRobertaForSequenceClassification                               [16, 1]                   --
    # â”œâ”€XLMRobertaModel: 1-1                                            [16, 512, 1024]           --
    # â”‚    â””â”€XLMRobertaEmbeddings: 2-1                                  [16, 512, 1024]           --
    # â”‚    â”‚    â””â”€Embedding: 3-1                                        [16, 512, 1024]           256,002,048
    # â”‚    â”‚    â””â”€Embedding: 3-2                                        [16, 512, 1024]           1,024
    # â”‚    â”‚    â””â”€Embedding: 3-3                                        [16, 512, 1024]           526,336
    # â”‚    â”‚    â””â”€LayerNorm: 3-4                                        [16, 512, 1024]           2,048
    # â”‚    â”‚    â””â”€Dropout: 3-5                                          [16, 512, 1024]           --
    # â”‚    â””â”€XLMRobertaEncoder: 2-2                                     [16, 512, 1024]           --
    # â”‚    â”‚    â””â”€ModuleList: 3-6                                       --                        302,309,376
    # â”œâ”€XLMRobertaClassificationHead: 1-2                               [16, 1]                   --
    # â”‚    â””â”€Dropout: 2-3                                               [16, 1024]                --
    # â”‚    â””â”€Linear: 2-4                                                [16, 1024]                1,049,600
    # â”‚    â””â”€Dropout: 2-5                                               [16, 1024]                --
    # â”‚    â””â”€Linear: 2-6                                                [16, 1]                   1,025
    # ===================================================================================================================
    # Total params: 559,891,457
    # Trainable params: 559,891,457
    # Non-trainable params: 0
    # Total mult-adds (Units.GIGABYTES): 8.96
    # ===================================================================================================================
    # Input size (MB): 0.03
    # Forward/backward pass size (MB): 17985.31
    # Params size (MB): 2239.57
    # Estimated Total Size (MB): 20224.91
    # ===================================================================================================================
    summary(model, input_size=(16, 512), dtypes=[torch.int])
    model = model.eval()

    # rank
    # tensor([-0.9298, -0.0641,  3.5109], device='cuda:0')
    # pairs = [["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2"], ["æ ·ä¾‹æ•°æ®-1", "é”™ä¾‹æ•°æ®-2"], ["æ ·ä¾‹æ•°æ®-2", "é”™ä¾‹æ•°æ®-2"]]
    # tensor([-5.6085,  5.7650], device='cuda:0')
    pairs = [['what is panda?', 'hi'], ['what is panda?',
                                        'The giant panda, sometimes called a panda bear or '
                                        'simply panda, is a bear species endemic to China.']]
    with torch.no_grad():
        # æ³¨æ„ padding = True å¿…é¡»æŒ‡å®šï¼Œå› ä¸ºè¿™é‡Œç›¸å½“äºæ˜¯ batchï¼Œå¿…é¡»å°†æ‰€æœ‰æ ·æœ¬å‡‘æˆä¸€æ ·é•¿çš„ï¼Œå¦åˆ™æŠ¥é”™
        encoded_input = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)
        # å¦‚æœ model åœ¨æ˜¾å¡ä¸­ï¼Œé‚£ä¹ˆå‚æ•°ä¹Ÿè¦éƒ½åœ¨æ˜¾å¡ä¸­
        change_dict_value_to_gpu(encoded_input)
        scores = model(**encoded_input, return_dict=True)
    # {'input_ids': tensor([[     0,   2367,     83,      6,  85407,     32,      2,      2,   1274,
    #               2,      1,      1,      1,      1,      1,      1,      1,      1,
    #               1,      1,      1,      1,      1,      1,      1,      1,      1,
    #               1,      1,      1,      1,      1,      1,      1,      1],
    #         [     0,   2367,     83,      6,  85407,     32,      2,      2,    581,
    #            6051,     18,      6,  85407,      4,  68018,  35839,     10,      6,
    #           85407,  81148,    707,  42856,      6,  85407,      4,     83,     10,
    #           81148, 114149,  28117,  21068,     47,   9098,      5,      2]],
    #        device='cuda:0'),
    #        'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    #          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    #         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    #          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}
    print(encoded_input)
    # SequenceClassifierOutput(loss=None, logits=tensor([[-5.6085],
    #         [ 5.7650]], device='cuda:0'), hidden_states=None, attentions=None)
    print(scores)
    scores = scores.logits.view(-1, ).float()
    # tensor([-5.6085,  5.7650], device='cuda:0')
    print(scores)


# scan æ•°æ®é›†ï¼Œåˆ©ç”¨ LtM è¿›è¡Œæµ‹è¯•
# å¦‚æœæ²¡æœ‰å¼€é­”æ³•ï¼Œä¼šå› ä¸ºè¶…æ—¶æ‰¾ä¸åˆ°çº¿ä¸Š hugging face å¯¹åº”çš„ scan æ•°æ®é›†ï¼Œå› æ­¤åªä¼šæ‰¾ cache_dir æŒ‡å®šçš„æ•°æ®
# Using the latest cached version of the dataset since scan couldn't be found on the Hugging Face Hub
# Found the latest cached dataset configuration 'simple' at D:\PycharmProjects\xiebo\diantou\bigdata\data\scan\simple\1.0.0\53972e5fdb6cc7b38752356eb96ef06841e717b3 (last modified on Sun Mar 17 21:17:12 2024).
# Using custom data configuration simple
# Loading Dataset Infos from D:\Users\admin\anaconda3\Lib\site-packages\datasets\packaged_modules\cache
# Overwrite dataset info from restored data version if exists.
# Loading Dataset info from D:\PycharmProjects\xiebo\diantou\bigdata\data\/scan/simple/1.0.0/53972e5fdb6cc7b38752356eb96ef06841e717b3

# å¦‚æœå¼€äº†é­”æ³•ï¼Œåˆ™å¯èƒ½ä¼šæ‹‰å–æœ€æ–°çš„æ•°æ®é›†ï¼Œä½†å¦‚æœå‘ç°å½“å‰ cache_dir ä¸­å·²ç»æ˜¯æœ€æ–°çš„ï¼Œé‚£ä¹ˆå°±ä¸ä¼šå†æ‹‰å–
# Overwrite dataset info from restored data version if exists.
# Loading Dataset info from D:\PycharmProjects\xiebo\diantou\bigdata\data\/scan/simple/1.0.0/53972e5fdb6cc7b38752356eb96ef06841e717b3
# Found cached dataset scan (D:/PycharmProjects/xiebo/diantou/bigdata/data/scan/simple/1.0.0/53972e5fdb6cc7b38752356eb96ef06841e717b3)
# Loading Dataset info from D:/PycharmProjects/xiebo/diantou/bigdata/data/scan/simple/1.0.0/53972e5fdb6cc7b38752356eb96ef06841e717b3

#  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:40<01:03, 10.54s/it]jump around left thrice and run right thrice
# The output of â€œjump around left thrice and run right thriceâ€ concatenates: the output of â€œjump around left thriceâ€, the output of â€œrun right thriceâ€. â€œjump around left thriceâ€ outputs (â€œTURN LEFTâ€ + â€œJUMPâ€) * 3. â€œrun right thriceâ€ outputs (â€œTURN RIGHTâ€ + â€œRUNâ€) * 3. So concatenating the output of â€œjump around left thriceâ€ and the output of â€œrun right thriceâ€ leads to (â€œTURN LEFTâ€ + â€œJUMPâ€) * 3 + (â€œTURN RIGHTâ€ + â€œRUNâ€) * 3. So the output of â€œjump around left thrice and run right thriceâ€ is (â€œTURN LEFTâ€ + â€œJUMPâ€) * 3 + (â€œTURN RIGHTâ€ + â€œRUNâ€) * 3.
# I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN
# I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN
# --------------------------------------------------------------------------------
#  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:59<00:39, 10.00s/it]jump opposite right after walk around right thrice
# The output of â€œjump opposite right after walk around right thriceâ€ concatenates: the output of â€œwalk around right thriceâ€, the output of â€œjump opposite rightâ€. â€œwalk around right thriceâ€ outputs (â€œTURN RIGHTâ€ + â€œWALKâ€) * 3. â€œjump opposite rightâ€ outputs â€œTURN RIGHTâ€ * 2 + â€œJUMPâ€. So concatenating the output of â€œwalk around right thriceâ€ and the output of â€œjump opposite rightâ€ leads to (â€œTURN RIGHTâ€ + â€œWALKâ€) * 3 + (â€œTURN RIGHTâ€ * 2 + â€œJUMPâ€). So the output of â€œjump opposite right after walk around right thriceâ€ is (â€œTURN RIGHTâ€ + â€œWALKâ€) * 3 + (â€œTURN RIGHTâ€ * 2 + â€œJUMPâ€).
# I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_JUMP
# I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_JUMP
# --------------------------------------------------------------------------------
#  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:10<00:30, 10.08s/it]look around left after jump around left twice
# The output of â€œlook around left after jump around left twiceâ€ concatenates: the output of â€œjump around left twiceâ€, the output of â€œlook around leftâ€. â€œjump around left twiceâ€ outputs (â€œTURN LEFTâ€ + â€œJUMPâ€) * 6. â€œlook around leftâ€ outputs â€œLOOK LEFTâ€ * 4. So concatenating the output of â€œjump around left twiceâ€ and the output of â€œlook around leftâ€ leads to (â€œTURN LEFTâ€ + â€œJUMPâ€) * 6 + â€œLOOK LEFTâ€ * 4. So the output of â€œlook around left after jump around left twiceâ€ is (â€œTURN LEFTâ€ + â€œJUMPâ€) * 6 + â€œLOOK LEFTâ€ * 4.
# I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK
# I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_LOOK_LEFT I_LOOK_LEFT I_LOOK_LEFT I_LOOK_LEFT
# --------------------------------------------------------------------------------
# 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:39<00:00,  9.92s/it]
# walk twice after look opposite left
# The output of â€œwalk twice after look opposite leftâ€ concatenates: the output of â€œlook opposite leftâ€, the output of â€œwalk twiceâ€. â€œlook opposite leftâ€ outputs â€œLOOK LEFTâ€ * 2. â€œwalk twiceâ€ outputs â€œWALKâ€ * 2. So concatenating the output of â€œlook opposite leftâ€ and the output of â€œwalk twiceâ€ leads to â€œLOOK LEFTâ€ * 2 + â€œWALKâ€ * 2. So the output of â€œwalk twice after look opposite leftâ€ is â€œLOOK LEFTâ€ * 2 + â€œWALKâ€ * 2.
# I_TURN_LEFT I_TURN_LEFT I_LOOK I_WALK I_WALK
# I_LOOK_LEFT I_LOOK_LEFT I_WALK I_WALK
# --------------------------------------------------------------------------------
# ['turn opposite right thrice and turn opposite left', 'run right twice after walk right twice', 'look around right twice and turn left thrice', 'jump around left thrice and run right thrice', 'run thrice and walk opposite left', 'jump opposite right after walk around right thrice', 'look around left after jump around left twice', 'look opposite right twice and jump opposite left twice', 'look opposite right thrice after look around left', 'walk twice after look opposite left']
# ['I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_LEFT I_TURN_LEFT', 'I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN', 'I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT', 'I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN', 'I_RUN I_RUN I_RUN I_TURN_LEFT I_TURN_LEFT I_WALK', 'I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_JUMP', 'I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK', 'I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_LEFT I_TURN_LEFT I_JUMP I_TURN_LEFT I_TURN_LEFT I_JUMP', 'I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK', 'I_TURN_LEFT I_TURN_LEFT I_LOOK I_WALK I_WALK']
# ['I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_LEFT I_TURN_LEFT', 'I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN', 'I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT', 'I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN', 'I_RUN I_RUN I_RUN I_TURN_LEFT I_TURN_LEFT I_WALK', 'I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_JUMP', 'I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_LOOK_LEFT I_LOOK_LEFT I_LOOK_LEFT I_LOOK_LEFT', 'I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_LEFT I_TURN_LEFT I_JUMP I_TURN_LEFT I_TURN_LEFT I_JUMP', 'I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_TURN_RIGHT I_LOOK', 'I_LOOK_LEFT I_LOOK_LEFT I_WALK I_WALK']
# 0.6
def check_scan_dataset():
    # DatasetDict({
    #     train: Dataset({
    #         features: ['commands', 'actions'],
    #         num_rows: 16728
    #     })
    #     test: Dataset({
    #         features: ['commands', 'actions'],
    #         num_rows: 4182
    #     })
    # })
    scan_ds = dataset_download(path="scan", name="simple", _info=True)
    scan_test = scan_ds["test"]
    # {'commands': 'jump opposite right twice and turn opposite right thrice',
    # 'actions': 'I_TURN_RIGHT I_TURN_RIGHT I_JUMP I_TURN_RIGHT I_TURN_RIGHT I_JUMP I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT'}
    # print(scan_train[0])
    # å¯ä»¥è½¬åŒ–ä¸º pandas.DataFrane
    assert_equal(scan_test.to_pandas().shape, (4182, 2))

    # scan_train = scan_ds["train"]
    # command_0 = scan_train[0]["commands"]
    # action_0 = scan_train[0]["actions"]
    # command_1 = scan_train[1]["commands"]
    # action_1 = scan_train[1]["actions"]
    # command_2 = scan_train[2]["commands"]
    # action_2 = scan_train[2]["actions"]

    # # few-shot
    # few_shot_prompt = F'Q: {command_0}, A: {action_0}, Q: {command_1}, A: {action_1}, Q: {command_2}, A: '
    # print(few_shot_prompt)
    #
    # action = get_completion_content(few_shot_prompt, strip=True)
    # èƒ½å¤Ÿå‘ç°ï¼Œç®€å•çš„ä»¥é—®é¢˜+ç­”æ¡ˆç»„æˆçš„few-shotï¼Œåœ¨å½“å‰SCANæ•°æ®é›†ä¸Šä»ç„¶æ— æ³•è¿›è¡Œè¾ƒä¸ºå‡†ç¡®çš„é¢„æµ‹ã€‚
    # äº‹å®ä¸Šï¼Œæ ¹æ®åŸè®ºæ–‡çš„æè¿°ï¼Œç®€å•çš„few-shotæç¤ºæ–¹æ³•åœ¨SCANæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ä¸åˆ°17%ã€‚
    # print(action, " vs ", action_2)

    # few-shot-LtM
    # zero_shot_ltm_prompt = F"In order to translate '{command_0}', we need to first solve "
    # # å¾ˆæ˜æ˜¾ï¼Œåœ¨Zero-shot-LtMçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„æ ¸å¿ƒé—®é¢˜ä»ç„¶è¿˜æ˜¯æ— æ³•ç²¾å‡†ç†è§£é—®é¢˜ï¼Œæ›´åˆ«è°ˆè¿›è¡Œæœ‰æ•ˆçš„æ½œåœ¨è¯­ä¹‰å…³ç³»å­¦ä¹ äº†ã€‚
    # # å½“ç„¶ï¼Œç©¶å…¶åŸå› è¿˜æ˜¯å› ä¸ºå¯¹äºå¾ˆå¤šå®Œå…¨è„±ç¦»è‡ªç„¶è¯­è¨€è¯­ä¹‰è§„åˆ™çš„é—®é¢˜ï¼Œç®€å•æç¤ºæ¨¡æ¿æ˜¯å¾ˆéš¾è®©æ¨¡å‹å®Œæˆæœ‰æ„ä¹‰çš„é—®é¢˜æ‹†è§£çš„ï¼Œ
    # # ä¾‹å¦‚å¯¹äºSCANæ•°æ®é›†ä¸­çš„æŒ‡ä»¤ç¿»è¯‘é—®é¢˜ï¼Œç”±äºæœ¬èº«æŒ‡ä»¤ç¿»è¯‘çš„è§„åˆ™å°±ä¸æ˜¯è‡ªç„¶è¯­è¨€è§„åˆ™ï¼Œæ¨¡å‹ä¹Ÿä»æœªå­¦ä¹ è¿‡ç›¸å…³è§„åˆ™ï¼Œæ­¤æ—¶åœ¨Zero-shotçš„æƒ…å†µä¸‹æ˜¯å¾ˆéš¾è®©æ¨¡å‹è¿›è¡Œé—®é¢˜æ‹†è§£çš„ï¼Œ
    # # æˆ–è€…è¯´æ­¤æ—¶æ¨¡å‹æ‹†è§£çš„é—®é¢˜ä¹Ÿå‡ ä¹ä¸ä¼šæœ‰åŠ©äºæœ€ç»ˆçš„æŒ‡ä»¤ç¿»è¯‘ä»»åŠ¡ï¼Œæ‹†è§£çš„å­é—®é¢˜æ˜¯æ¯«æ— æ„ä¹‰çš„ã€‚
    # print(zero_shot_ltm_prompt)
    #
    # action = get_completion_content(zero_shot_ltm_prompt, strip=True)
    # print(action)

    # # Stage 1.Command decompositionï¼šæŒ‡ä»¤æ‹†è§£
    # cd_few_shot = ('Q: "look opposite right thrice after walk" '
    #                'A: "look opposite right thrice" can be solved by: "look opposite right", "look opposite right '
    #                'thrice". "walk" can be solved by "walk". So, "look opposite right thrice after walk" can be '
    #                'solved by: "walk", "look opposite right", "look opposite right thrice". '
    #                'Q: "look around right thrice and walk" '
    #                'A: "look around right thrice" can be solved by: "look right", "look around right", "look around '
    #                'right thrice". "walk" can be solved by "walk". So, "look around right thrice and walk" can be '
    #                'solved by: "look right", "look around right", "look around right thrice", "walk". ')
    #
    # # cd_few_shot = ('Q: "look opposite right thrice after walk" '
    # #                'A: "look opposite right thrice" can be solved by: "look opposite right", "look opposite right thrice". '
    # #                '"walk" can be solved by "walk". So, "look opposite right thrice after walk" can be '
    # #                'solved by: "walk", "look opposite right", "look opposite right thrice". '
    # #                'Q: "look around right and walk" '
    # #                'A: "look around right " can be solved by: "look right", "look around right". '
    # #                '"walk" can be solved by "walk". So, "look around right and walk" can be '
    # #                'solved by: "look right", "look around right", "walk". ')
    #
    # prompt_cd = cd_few_shot + F'Qï¼š"{command_1}" A:'
    # response_cd = get_completion_content(prompt_cd, strip=True, temperature=0.5)
    # # "run opposite left" can be solved by: "run", "opposite left". "walk right" can be solved by: "walk", "walk right".
    # # So, "run opposite left after walk right" can be solved by: "walk", "walk right", "run", "opposite left".
    # print(response_cd)
    #
    # # Stage 2.Command mappingï¼šæŒ‡ä»¤ç¿»è¯‘ï¼Œå°†æ‹†è§£åçš„çŸ­æŒ‡ä»¤é€ä¸€ç¿»è¯‘ï¼Œå¹¶ä¸æ–­æ‹¼æ¥åˆ° few-shot ä¸­ï¼Œæœ€ç»ˆè·å¾—åŸå§‹é•¿æŒ‡ä»¤çš„æ€»ç¿»è¯‘ç»“æœ
    # cm_few_shot = ('Q: "jump left" '
    #                'A: The output of "jump left" concatenates: the output of "turn left", the output of "jump". "turn '
    #                'left" outputs "TURN LEFT". "jump" outputs "JUMP". So concatenating the output of "turn '
    #                'left" and the output of "jump" leads to "TURN LEFT" + "JUMP". So the output of "jump left" '
    #                'is "TURN LEFT" + "JUMP". '
    #                'Q: "run and look twice" '
    #                'A: The output of "run and look twice" concatenates: the output of "run", the output of "look '
    #                'twice". "run" outputs "RUN". "look twice" outputs "LOOK" * 2. So concatenating the output of '
    #                'run" and the output of "look twice" leads to "RUN" + "LOOK" * 2. So the output of "run and '
    #                'look twice" is "RUN" + "LOOK" * 2. '
    #                'Q: "walk opposite left" '
    #                'A: The output of "walk opposite left" concatenates: the output of "turn opposite left", the output of '
    #                '"walk". "turn opposite left" outputs "TURN LEFT" * 2. "walk" outputs "WALK". So concatenating the '
    #                'output of "turn opposite left" and the output of "walk" leads to "TURN LEFT" * 2 + "WALK". So the '
    #                'output of "walk opposite left" is "TURN LEFT" * 2 + "WALK" ')
    #
    # prompt_cm_1 = cm_few_shot + 'Q: "walk right" Aï¼š'
    # response_cm_1 = get_completion_content(prompt_cm_1, strip=True, temperature=0.5)
    # # The output of "walk right" concatenates: the output of "turn right", the output of "walk". "turn right" outputs "TURN RIGHT". "walk" outputs "WALK".
    # # So concatenating the output of "turn right" and the output of "walk" leads to "TURN RIGHT" + "WALK".
    # # So the output of "walk right" is "TURN RIGHT" + "WALK".
    # print(response_cm_1)
    #
    # prompt_cm_2 = prompt_cm_1 + response_cm_1 + 'Q: "run left" Aï¼š'
    # response_cm_2 = get_completion_content(prompt_cm_2, strip=True, temperature=0.5)
    # # The output of "walk right" concatenates: the output of "turn right", the output of "walk". "turn right" outputs "TURN RIGHT". "walk" outputs "WALK".
    # # So concatenating the output of "turn right" and the output of "walk" leads to "TURN RIGHT" + "WALK".
    # # So the output of "walk right" is "TURN RIGHT" + "WALK".
    # print(response_cm_2)
    #
    # prompt_cm_3 = prompt_cm_2 + response_cm_2 + 'Q: "run opposite left" Aï¼š'
    # response_cm_3 = get_completion_content(prompt_cm_3, strip=True, temperature=0.5)
    # # The output of "walk right" concatenates: the output of "turn right", the output of "walk". "turn right" outputs "TURN RIGHT". "walk" outputs "WALK".
    # # So concatenating the output of "turn right" and the output of "walk" leads to "TURN RIGHT" + "WALK".
    # # So the output of "walk right" is "TURN RIGHT" + "WALK".
    # print(response_cm_3)
    #
    # prompt_cm = prompt_cm_3 + response_cm_3 + F'Q: "{command_1}" Aï¼š'
    # print(prompt_cm)
    # response_cm = get_completion_content(prompt_cm, strip=True, temperature=0.5)
    # print(response_cm)

    cd_few_shot = 'Q: â€œlook right after look twiceâ€ \
                   A: â€œlook right after look twiceâ€ can be solved by: â€œlook rightâ€, â€œlook twiceâ€. \
                   Q: â€œjump opposite right thrice and walkâ€ \
                   A: â€œjump opposite right thriceâ€ can be solved by: â€œjump opposite rightâ€, â€œjump opposite right thriceâ€. \
                   â€œwalkâ€ can be solved by: â€œwalkâ€. So, â€œjump opposite right thrice and walkâ€ can be solved by: â€œjump \
                   opposite rightâ€, â€œjump opposite right thriceâ€, â€œwalkâ€. \
                   Q: â€œrun left twice and run rightâ€ \
                   A: â€œrun left twiceâ€ can be solved by: â€œrun leftâ€, â€œrun left twiceâ€. â€œrun rightâ€ can be solved by â€œrun rightâ€. \
                   So, â€œrun left twice and run rightâ€ can.be solved by: â€œrun leftâ€, â€œrun left twiceâ€, â€œrun rightâ€. \
                   Q: â€œrun opposite rightâ€ \
                   A: â€œrun opposite rightâ€ can be solved by â€œrun opposite rightâ€. \
                   Q: â€œlook opposite right thrice after walkâ€ \
                   A: â€œlook opposite right thriceâ€ can be solved by: â€œlook opposite rightâ€, â€œlook opposite right thriceâ€. \
                   â€œwalkâ€ can be solved by â€œwalkâ€. So, â€œlook opposite right thrice after walkâ€ can be solved by: â€œlook \
                   opposite rightâ€, â€œlook opposite right thriceâ€, â€œwalkâ€. \
                   Q: â€œjump around rightâ€ \
                   A: â€œjump around rightâ€ can be solved by: â€œjump rightâ€, â€œjump around rightâ€. So, â€œjump around rightâ€ \
                   can be solved by: â€œjump rightâ€, â€œjump around rightâ€. \
                   Q: â€œlook around right thrice and walkâ€ \
                   A: â€œlook around right thriceâ€ can be solved by: â€œlook rightâ€, â€œlook around rightâ€, â€œlook around right \
                   thriceâ€. â€œwalkâ€ can be solved by â€œwalkâ€. So, â€œlook around right thrice and walkâ€ can be solved by: \
                   â€œlook rightâ€, â€œlook around rightâ€, â€œlook around right thriceâ€, â€œwalkâ€. \
                   Q: â€œturn right after run right thriceâ€ \
                   A: â€œturn rightâ€ can be solved by: â€œturn rightâ€. â€œrun right thriceâ€ can be solved by: â€œrun rightâ€, â€œrun \
                   right thriceâ€. So, â€œturn right after run right thriceâ€ can be solved by: â€œturn rightâ€, â€œrun rightâ€, â€œrun right \
                   thriceâ€. \
                   '

    cm_few_shot = 'Q: â€œturn leftâ€ \
                   A: â€œturn leftâ€ outputs â€œTURN LEFTâ€. \
                   Q: â€œturn rightâ€ \
                   A: â€œturn rightâ€ outputs â€œTURN RIGHTâ€. \
                   Q: â€œjump leftâ€ \
                   A: The output of â€œjump leftâ€ concatenates: the output of â€œturn leftâ€, the output of â€œjumpâ€. â€œturn leftâ€ \
                   outputs â€œTURN LEFTâ€. â€œjumpâ€ outputs â€œJUMPâ€. So concatenating the output of â€œturn leftâ€ and the output of â€œjumpâ€ \
                   leads to â€œTURN LEFTâ€ + â€œJUMPâ€. So the output of â€œjump leftâ€ is â€œTURN LEFTâ€ + â€œJUMPâ€. \
                   Q: â€œrun rightâ€ \
                   A: The output of â€œrun rightâ€ concatenates: the output of â€œturn rightâ€, the output of â€œrunâ€. â€œturn rightâ€ \
                   outputs â€œTURN RIGHTâ€. â€œrunâ€ outputs â€œRUNâ€. So concatenating the output of â€œturn rightâ€ and the \
                   output of â€œrunâ€ leads to â€œTURN RIGHTâ€ + â€œRUNâ€. So the output of â€œrun rightâ€ is â€œTURN RIGHTâ€ + \
                   â€œRUNâ€. \
                   Q: â€œlook twiceâ€ \
                   A: The output of â€œlook twiceâ€ concatenates: the output of â€œlookâ€, the output of â€œlookâ€. â€œlookâ€ outputs \
                   â€œLOOKâ€. So repeating the output of â€œlookâ€ two times leads to â€œLOOKâ€ * 2. So the output of â€œlook \
                   twiceâ€ is â€œLOOKâ€ * 2. \
                   Q: â€œrun and look twiceâ€ \
                   A: The output of â€œrun and look twiceâ€ concatenates: the output of â€œrunâ€, the output of â€œlook twiceâ€. \
                   â€œrunâ€ outputs â€œRUNâ€. â€œlook twiceâ€ outputs â€œLOOKâ€ * 2. So concatenating the output of â€œrunâ€ and the \
                   output of â€œlook twiceâ€ leads to â€œRUNâ€ + â€œLOOKâ€ * 2. So the output of â€œrun and look twiceâ€ is â€œRUNâ€ + \
                   â€œLOOKâ€ * 2. \
                   Q: â€œjump right thriceâ€ \
                   A: The output of â€œjump right thriceâ€ concatenates: the output of â€œjump rightâ€, the output of â€œjump \
                   rightâ€, the output of â€œjump rightâ€. â€œjump rightâ€ outputs â€œTURN RIGHTâ€ + â€œJUMPâ€. So repeating the \
                   output of â€œjump rightâ€ three times leads to (â€œTURN RIGHTâ€ + â€œJUMPâ€) * 3. So the output of â€œjump \
                   right thriceâ€ is (â€œTURN RIGHTâ€ + â€œJUMPâ€) * 3. \
                   Q: â€œwalk after runâ€ \
                   A: The output of â€œwalk after runâ€ concatenates: the output of â€œrunâ€, the output of â€œwalkâ€. â€œrunâ€ outputs \
                   â€œRUNâ€. â€œwalkâ€ outputs â€œWALKâ€. So concatenating the output of â€œrunâ€ and the output of â€œwalkâ€ leads to \
                   â€œRUNâ€ + â€œWALKâ€. So the output of â€œwalk after runâ€ is â€œRUNâ€ + â€œWALKâ€. \
                   Q: â€œturn opposite leftâ€ \
                   A: The output of â€œturn opposite leftâ€ concatenates: the output of â€œturn leftâ€, the output of â€œturn leftâ€. \
                   â€œturn leftâ€ outputs â€œTURN LEFTâ€. So repeating the output of â€œturn leftâ€ twice leads to â€œTURN LEFTâ€ * \
                   2. So the output of â€œturn opposite leftâ€ is â€œTURN LEFTâ€ * 2. \
                   Q: â€œturn around leftâ€ \
                   A: The output of â€œturn around leftâ€ concatenates: the output of â€œturn leftâ€, the output of â€œturn leftâ€, the \
                   output of â€œturn leftâ€, the output of â€œturn leftâ€. â€œturn leftâ€ outputs â€œTURN LEFTâ€. So repeating the output \
                   of â€œturn leftâ€ four times leads to â€œTURN LEFTâ€ * 4. So the output of â€œturn around leftâ€ is â€œTURN LEFTâ€ \
                   * 4. \
                   Q: â€œturn opposite rightâ€ \
                   A: The output of â€œturn opposite rightâ€ concatenates: the output of â€œturn rightâ€, the output of â€œturn \
                   rightâ€. â€œturn rightâ€ outputs â€œTURN RIGHTâ€. So repeating the output of â€œturn rightâ€ twice leads to \
                   â€œTURN RIGHTâ€ * 2. So the output of â€œturn opposite rightâ€ is â€œTURN RIGHTâ€ * 2. \
                   Q: â€œturn around rightâ€ \
                   A: The output of â€œturn around rightâ€ concatenates: the output of â€œturn rightâ€, the output of â€œturn rightâ€, \
                   the output of â€œturn rightâ€, the output of â€œturn rightâ€. â€œturn rightâ€ outputs â€œTURN RIGHTâ€. So repeating \
                   the output of â€œturn rightâ€ four times leads to â€œTURN RIGHTâ€ * 4. So the output of â€œturn around rightâ€ \
                   is â€œTURN RIGHTâ€ * 4. \
                   Q: â€œwalk opposite leftâ€ \
                   A: The output of â€œwalk opposite leftâ€ concatenates: the output of â€œturn opposite leftâ€, the output of \
                   â€œwalkâ€. â€œturn opposite leftâ€ outputs â€œTURN LEFTâ€ * 2. â€œwalkâ€ outputs â€œWALKâ€. So concatenating the \
                   output of â€œturn opposite leftâ€ and the output of â€œwalkâ€ leads to â€œTURN LEFTâ€ * 2 + â€œWALKâ€. So the \
                   output of â€œwalk opposite leftâ€ is â€œTURN LEFTâ€ * 2 + â€œWALKâ€. \
                   Q: â€œwalk around leftâ€ \
                   A: The output of â€œwalk around leftâ€ concatenates: the output of â€œwalk leftâ€, the output of â€œwalk leftâ€, \
                   the output of â€œwalk leftâ€, the output of â€œwalk leftâ€. â€œwalk leftâ€ outputs â€œTURN LEFTâ€ + â€œWALKâ€. So \
                   repeating the output of â€œwalk around leftâ€ four times leads to (â€œTURN LEFTâ€ + â€œWALKâ€) * 4. So the \
                   output of â€œwalk around leftâ€ is (â€œTURN LEFTâ€ + â€œWALKâ€) * 4. \
                  '

    def extract_phrases(text):
        # æŸ¥æ‰¾æœ€åä¸€ä¸ª "solved by:" åé¢çš„æ‰€æœ‰å†…å®¹
        last_solved_by = text.rsplit("solved by:", 1)[-1]

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å¼•å·ä¸­çš„çŸ­è¯­
        phrases = re.findall(r'â€œ([^â€]*)â€', last_solved_by)

        return phrases

    def transform_expression(s):
        # Regular expression pattern
        pattern = r'is .*'

        # Find the match
        match = re.search(pattern, s)

        s = match.group()
        if s.endswith("."):
            s = s[3: -1].replace('â€œ', '"').replace('â€', '"')
        else:
            s = s[3:].replace('â€œ', '"').replace('â€', '"')

        # å¤šä¸ªä¹˜æ•°å˜æˆä¸€ä¸ª
        # (â€œTURN RIGHTâ€ + â€œLOOKâ€) * 4 * 2
        pattern = r'(\d+) \* (\d+)'
        matches = re.findall(pattern, s)
        while matches:
            for match in matches:
                replacement = str(int(match[0]) * int(match[1]))
                s = s.replace(f'{match[0]} * {match[1]}', replacement)
            matches = re.findall(pattern, s)

        # Step 1: Handle multiplications
        pattern = r'"([^"]+)" \* (\d+)'
        matches = re.findall(pattern, s)
        for match in matches:
            replacement = ' '.join([f'"{match[0]}"'] * int(match[1]))
            s = s.replace(f'"{match[0]}" * {match[1]}', replacement)

        # Step 1.5: Handle multiplications
        # ("TURN RIGHT" * 2) * 3 + "TURN LEFT" * 2
        # ("TURN RIGHT" + "WALK") * 2 + ("TURN RIGHT" + "RUN") * 2
        # æ³¨æ„è¦ç”¨éè´ªå©ª
        pattern = r'\((.+?)\) \* (\d+)'
        matches = re.findall(pattern, s)
        while matches:
            for match in matches:
                replacement = ' '.join([f'{match[0]}'] * int(match[1]))
                s = s.replace(f'({match[0]}) * {match[1]}', replacement)
            matches = re.findall(pattern, s)

        # Step 2: Replace spaces within quotes with underscores
        pattern = r'"([^"]+)"'
        matches = re.findall(pattern, s)
        for match in matches:
            replacement = match.replace(' ', '_')
            s = s.replace(f'"{match}"', f'"{replacement}"')

        # Step 3: Add 'I_' prefix within quotes
        pattern = r'"([^"]+)"'
        matches = re.findall(pattern, s)
        for match in matches:
            replacement = 'I_' + match
            s = s.replace(f'"{match}"', f'"{replacement}"')

        # Step 4: Remove quotes
        s = s.replace('"', '')
        s = s.replace(' +', '')
        s = s.replace(')', '')
        s = s.replace('(', '')

        s = replace_multiple_spaces(s)

        return s

    def scan_predict(dataset):
        # è½¬åŒ–ä¸ºdataframe
        data_frame = dataset.to_pandas()
        # æœ€åä¸€åˆ—æ ‡è®°ä¸º unknown
        data_frame['actions_predict'] = 'unknown'
        # åœ¨å­—å…¸ä¸­å¾ªç¯
        # æ³¨æ„è¦å…ˆ tqdm å† enumerate
        for i, data in enumerate(tqdm(dataset)):
            # é˜¶æ®µä¸€ï¼šæ‹†è§£å‘½ä»¤
            prompt_cd = cd_few_shot + 'Qï¼šâ€œ%sâ€ A:' % data['commands']
            response_cd = get_completion_content(prompt_cd, strip=True, temperature=0)
            # æ‹†è§£å‘½ä»¤ç»“æœ
            cd_result = extract_phrases(response_cd)
            # é˜¶æ®µäºŒï¼šçŸ­å‘½ä»¤ç¿»è¯‘
            cm_few_shot_temp = cm_few_shot
            sub_qs = cd_result
            for qs in sub_qs:
                cm_few_shot_temp += 'Q:â€œ%sâ€ Aï¼š' % qs
                response_cm = get_completion_content(cm_few_shot_temp, strip=True, temperature=0)
                cm_few_shot_temp += response_cm
            # å¯¹åŸå§‹é—®é¢˜æé—®
            prompt_cm = cm_few_shot_temp + 'Qï¼šâ€œ%sâ€ A:' % data['commands']
            response_cm = get_completion_content(prompt_cm, strip=True, temperature=0)
            # å°†ç»“æœä¿å­˜åœ¨dataframeçš„å¯¹åº”ä½ç½®
            data_frame['actions_predict'][i] = transform_expression(response_cm)

            if data_frame['actions_predict'][i] != data_frame['actions'][i]:
                print(data['commands'])
                print(response_cm)
                print(F"{data_frame['actions'][i]}")
                print(F"{data_frame['actions_predict'][i]}")
                print("-" * 80)

        return data_frame

    scan_test = scan_test.select(range(10), keep_in_memory=True)

    final_data_frame = scan_predict(scan_test)
    print(final_data_frame["commands"].to_list())
    print(final_data_frame["actions"].to_list())
    print(final_data_frame["actions_predict"].to_list())

    # noinspection PyUnresolvedReferences
    # 0.6
    print((final_data_frame['actions'] == final_data_frame['actions_predict']).mean())

    assert_equal(transform_expression("is (â€œTURN RIGHTâ€ * 2) * 3 + â€œTURN LEFTâ€ * 2."),
                 "I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_LEFT I_TURN_LEFT")

    assert_equal(transform_expression("is (â€œTURN RIGHTâ€ + â€œWALKâ€) * 2 + (â€œTURN RIGHTâ€ + â€œRUNâ€) * 2."),
                 "I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN")

    assert_equal(
        transform_expression("is (â€œTURN RIGHTâ€ + â€œWALKâ€) * 2 + (â€œTURN RIGHTâ€                    + â€œRUNâ€) * 2."),
        "I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN")

    assert_equal(
        transform_expression("is (â€œTURN RIGHTâ€ + â€œWALKâ€) * 3 + (â€œTURN RIGHTâ€ * 2 + â€œJUMPâ€)."),
        "I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_JUMP")

    assert_equal(
        transform_expression("is (â€œTURN RIGHTâ€ + â€œLOOKâ€) * 4 * 2 + â€œTURN LEFTâ€ * 3."),
        "I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT")


@func_timer(arg=True)
def main():
    # check_gpu(True)

    # check_mul()
    # check_mean_op()
    # check_std_op()
    # other_simple()
    # check_batch_norm()
    # check_layer_norm()
    # check_instance_norm()
    # check_group_norm()
    # check_weight_norm()
    # check_half()

    # check_chatglm3()
    # check_bge_zh()
    # check_bge_reranker()

    check_scan_dataset()


if __name__ == '__main__':
    main()
